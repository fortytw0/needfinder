<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Disempowered by Data: Nonprofits, Social Enterprises, and the Consequences of Data-Driven Work</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Chris</forename><surname>Bopp</surname></persName>
							<email>chris.bopp@colorado.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ellie</forename><surname>Harmon</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Amy</forename><surname>Voida</surname></persName>
							<email>amy.voida@colorado.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">ATLAS Institute University of Colorado Boulder</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Dept. of Information Science</orgName>
								<orgName type="institution">University of Colorado Boulder</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Dept. of Information Science</orgName>
								<orgName type="institution">University of Colorado</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="laboratory">Culture CHI 2017</orgName>
								<address>
									<addrLine>May 6-11, May 6-11, May 6-11</addrLine>
									<postCode>2017, 2017, 2017, 2017, 2017</postCode>
									<settlement>Denver, Denver, Denver</settlement>
									<region>CO, CO, CO</region>
									<country>USA Data Culture CHI, USA Data Culture CHI, USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Disempowered by Data: Nonprofits, Social Enterprises, and the Consequences of Data-Driven Work</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3025453.3025694</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-07-22T05:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Accountability</term>
					<term>Data</term>
					<term>Monitoring and Evaluation</term>
					<term>Metrics</term>
					<term>Mission-Driven</term>
					<term>Nonprofit Organization</term>
					<term>Social Enterprise H.5.3. [Information Interfaces and Presentation]: Group and Organization Interfaces-Computer-Supported Cooperative Work</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Organizations across many sectors are under intense pressure to become data-driven. Yet, for mission-driven organizations, the path to becoming and value of being datadriven is not always clear. We present results from an interview-based study of the role of data in the monitoring and evaluation practices of mission-driven organizations. Instead of leading to productive and empowering data-driven decision making, monitoring and evaluation work is characterized by the erosion of autonomy, data drift, and data fragmentation. Together, these consequences of monitoring and evaluation practices play into a cycle of increasing disempowerment for the mission-driven organization. These findings suggest that the design of information systems should work towards empowering organizations in ways that make sense for their unique data needs and those of their constituents.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>INTRODUCTION</head><p>In the move toward rationalization and quantification in organizations <ref type="bibr" target="#b22">[24]</ref>, the increasing prevalence of information systems designed to support the collection, management, and analysis of data has coincided with expectations that organizations should be more "data-driven"-using increasingly larger aggregations of data to enable more productive and empowered decisions. Previous research in the management of information systems has suggested that, in for-profit contexts, data-driven decision making leads to improvements in performance, output, and productivity <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref>. In the nonprofit context, data-driven decision making has been shown to improve "the effectiveness of management decisions" <ref type="bibr" target="#b19">[21]</ref> (see also <ref type="bibr" target="#b16">[17]</ref>). Yet scholarship about data and its impacts on organizations in HCI and adjacent fields has raised critical concerns about this "march toward quantification" <ref type="bibr" target="#b18">[19]</ref>-concerns about the ways in which the quantification of data changes assumptions about the meaning of knowledge and about how people "should" engage with information, concerns about the biases inherent in and the decontextualization of big data, and concerns about the new digital divides created by big data <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b26">28,</ref><ref type="bibr" target="#b30">32]</ref>.</p><p>Recent empirical research has also raised significant concerns about how "cultures of data" are enacted in organizations <ref type="bibr" target="#b33">[36]</ref>. This research has identified significant disconnects between the support provided by collaborative computing systems and the organizational practices that are developing in response to calls for organizations to become more data-driven. In addition, questions remain about how work practices and organizational identity are shaped by the expectations and demands of being data-driven <ref type="bibr" target="#b26">[28,</ref><ref type="bibr" target="#b27">29,</ref><ref type="bibr" target="#b28">30]</ref>.</p><p>In this research, we expand on this nascent but growing body of empirical work by examining the enactment-and consequences-of monitoring and evaluation (M&amp;E) in mission-driven organizations. Encompassing nonprofit organizations and social enterprises, mission-driven organizations differ from traditional for-profit corporations in that organizational goals are rooted in social impact, rather than solely in profit-based bottom lines.</p><p>Research about the uptake of data-driven practices in the mission-driven context is critical as recent investigations have raised concerns over the efficacy of data practices in mission-driven organizations. <ref type="bibr">Maxwell et al.</ref> found that in social enterprise organizations, "data are often collected but less often analyzed" <ref type="bibr" target="#b19">[21]</ref>. And although individuals in these organizations believed in the potential of data-driven decision making, they reported "less confidence in their organization's ability to do so" <ref type="bibr" target="#b19">[21]</ref>.</p><p>In this paper, we present findings from an empirical study of the use of data in 13 mission-driven organizations. Drawing on interviews with 19 M&amp;E professionals, we find critical consequences in how data practices are emerging in these organizations. The mission-driven organizations that participated in this research are not empowered by data. Instead, they are investing time, sacrificing expertise, and responding to largely external demands for data collection and reporting at the expense of the mission and operation of the organization. We identify three negative consequences of current data practices-erosion of autonomy, data drift, and data fragmentation-which are mutually reinforcing and lead to a cycle of increasing disempowerment . This cycle of disempowerment results in organizations having less control over their own data practices-preventing the meaningful use of data and discouraging the organization from redesigning data practices to better meet their needs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>RELATED WORK Data-Driven Practices</head><p>Researchers have identified many benefits of using technology for data-driven practices, including the optimization of production and manufacturing, reductions in customer attrition, reductions in data redundancy, facilitation of new genres of questions by end-users, increased profitability, and the creation of competitive advantage <ref type="bibr" target="#b13">[14,</ref><ref type="bibr" target="#b24">26,</ref><ref type="bibr" target="#b37">40]</ref>. When these tools are successfully leveraged for datadriven decision making, these practices are found to improve performance, productivity, and effectiveness <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b16">17</ref>].</p><p>Yet, previous research has also raised concerns about the biases of big data leading to new digital divides between data-haves and have-nots and between individuals and organizations that do and do not have computational literacies <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b12">13,</ref><ref type="bibr">20]</ref>. Manovich suggests that big data has created new inequalities among three categories of people and organizations: "those who create data (both consciously and by leaving digital footprints), those who have the means to collect it, and those who have expertise to analyze it." <ref type="bibr">[20]</ref> boyd and Crawford suggest that two digital divides fall out of these inequalities: one related to who does and does not have access to big data and a second related to who does and does not have the ability to utilize this data <ref type="bibr" target="#b2">[3]</ref>. Concerns about the uneven uptake of big data become even more critical as the purview of data-driven practices are expanding beyond the private sector. As King asserts:</p><p>The march of quantification, made possible by enormous new sources of data, will sweep through academia, business and government. There is no area that is going to be untouched (quoted in <ref type="bibr" target="#b18">[19]</ref>; see also <ref type="bibr" target="#b4">[5,</ref><ref type="bibr" target="#b12">13]</ref>).</p><p>It becomes increasingly important, then, to understand the ways in which data-driven practices are taken up or attempted in a diversity of organizational contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data in the Nonprofit Sector</head><p>Nearly all research exploring the role of technology in the nonprofit sector highlights the extraordinary constraints in resources and expertise that shape the way systems are and are not used (e.g., <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b34">37]</ref>). Information management, in particular, is a challenge for these organizations. Voida et al. have characterized the patchwork assemblages of information systems in the nonprofit sector as "homebrew databases" <ref type="bibr" target="#b34">[37]</ref>. Working within the myriad of constraints in these organizations, individual knowledge workers creatively appropriate disparate paper tools, personal information management systems, and-sometimesenterprise or custom databases to satisfice their data practices. But these "homebrew databases" are plagued with significant version control issues, redundant data entry, a lack of scalability, siloed and/or inaccessible data, an unproductive churn through the adoption and use of different tools, and, ultimately, an abandonment of data. These challenges are not solved in even the leading edge organizations in the sector. Verma and Voida's case study of one such organization's adoption of a business intelligence system also found pervasive challenges in data warehousing <ref type="bibr" target="#b33">[36]</ref>. Much of the organization's data was siloed in systems for which there was no import mechanism; some data was kept in spreadsheets and had to be manually updated daily; and some data was not digitized at all. All of these issues make engaging in data analysis a nearly intractable problem. Perhaps it is unsurprising, then, that a survey of the capacity for data-driven decision making in social enterprise organizations found that while organizations are collecting a large quantity of data, they are not adept or confident about analyzing or using that data <ref type="bibr" target="#b19">[21]</ref>.</p><p>Supporting information management in the nonprofit sector is particularly important as these organizations are under increasing pressure to provide impact and performance data to funders <ref type="bibr" target="#b10">[11]</ref>. Yet, Snibbe warns of the costs: "Nonprofits are often collecting heaps of dubious data, at great cost to themselves and ultimately to the people they serve" <ref type="bibr" target="#b32">[34]</ref>. Indeed, research in philanthropic studies cautions that many of the performance metrics used in nonprofit organizations fail to account for critical aspects of nonprofit work and, in fact, might be impeding performance <ref type="bibr" target="#b0">[1]</ref>.</p><p>Understanding the role of data in the work of mission-driven organizations will be critical to better supporting and empowering these organizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>METHODS Participants</head><p>We recruited 19 participants (referenced by an anonymous participant number, P1-P19) from 13 mission-driven organizations, all of whom were responsible for some aspect of the monitoring and evaluation (M&amp;E) work in their organization. M&amp;E professionals typically serve as the central points of expertise regarding data in their organization, often responsible for operationalizing and carrying out requests for data-whether originating inside or outside the organization. As such, these individuals offer a uniquely broad perspective about how data is taken up and used-and the implications of that use-across the organization. We recruited participants initially through snowball sampling, starting with M&amp;E professionals who participated in a community professional development event.</p><p>As our research unfolded, we engaged in theoretical sampling, strategically recruiting from additional organizations to obtain diversity on two dimensions: type of organization and annual revenue.</p><p>We sampled from three types of mission-driven organizations to create maximum variation:</p><p>1. Direct service nonprofit organizations provide a variety of services to clients (n=9 participants from 8 organizations); 2. Indirect service nonprofit organizations provide services to other nonprofit organizations, including research services and funding (n=9 participants from 4 organizations); and 3. Social enterprises are mission-driven, for-profit organizations or programs within nonprofit organizations (n=1 participant from 1 for-profit social enterprise, plus n=8 participants already included above from 6 nonprofit organizations who manage social enterprise programs).</p><p>We also sampled across a range of organizations' annual revenue. Because data practices are often prescribed by funders, we consider a range of annual revenues to signify a range of experiences with data practices. Organizations sampled ranged in annual revenue from $100K to $75M. Within these annual revenue figures we, once again, used available data to sample across predominant revenue sources: government grants, membership dues, fundraising events, program service revenue, and sale of inventory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Collection</head><p>We collected data through semi-structured interviews using an interview protocol that focused on three areas of inquiry:</p><p>(1) the nature of the participant's work within and/or alongside other mission-driven organizations, (2) the role of data and related technologies in the participants' work, and (3) the organizations' approaches to impact measurement including the types of data collected and the information systems leveraged. The first author conducted all interviews and adapted the interview protocol based on grounded theory's principle of constant comparison to gather "additional data samples that are chosen to test the theory at its weakest point" <ref type="bibr" target="#b23">[25]</ref>. One interview question, for example began broadly as 'How and why do you collect data on your organization's programs?' and evolved into a request, for each type of data, for the participant to 'tell [us] more about who the audience is and how that audience shaped the process.' This evolution was driven by accounts of power and influence offered by early study participants and was designed to better understand how external audiences were or were not involved in the day-to-day operational decisions of data collection and at what level of specificity.</p><p>Interviews lasted on average 56 minutes. The majority of the interviews were conducted within a one month period, with additional interviews conducted several months later after preliminary data analysis. We audiotaped and transcribed each interview to aid in analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Analysis</head><p>We took an inductive approach to data analysis (following <ref type="bibr" target="#b5">[6]</ref>), grounded in coding and memoing techniques. We identified emergent themes such as evaluative approaches, organizational constraints, and technical capacity through open coding. We printed, cut up, and clustered the coded transcripts to develop axial codes that surfaced themes about the relationship between organizations' internal capacities, externally imposed constraints, and data complexity.</p><p>We interleaved the second stage of analysis with additional data collection, using our axial codes to "interrogate the open codes, leading to more data collection and more open coding" <ref type="bibr" target="#b23">[25]</ref>. We then engaged in several iterations of affinity diagramming to identify cross-cutting categories that allowed us to make sense of participants' experiences and understandings of M&amp;E work in mission-driven organizations. We tested each at its weakest point through memos and discussions among researchers, frequently returning to the transcripts as reference. This multi-stage analytic process resulted in the identification of three key consequences of monitoring and evaluation. In subsequent theoretical integration, we explored the interrelationships among these consequences, leading us to propose a cycle of disempowerment for mission-driven organizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodological Limitations</head><p>Grounded theory-and all research methods-include many trade-offs in the kinds of evidence they generate and the kinds of conclusions and theory building they facilitate. An interview-based grounded theory approach is well suited to this research as we sought to understand the practices, experiences, and implications of data in mission-driven organizations. This approach offers opportunities for what Lincoln and Guba <ref type="bibr" target="#b17">[18]</ref> refer to as "transferability"-the evidence-based argument that analytical insights are applicable beyond the specific individuals studied. This affordance of qualitative methods is enabled by strategies such as constant comparison rather than being rooted in ideals of statistical generalizability or bias-free objectivity <ref type="bibr" target="#b17">[18]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Research Context: Monitoring &amp; Evaluation in Mission Driven Organizations</head><p>Mission-driven organizations are entities, both large and small, for-profit and not-for-profit, that aim to have a particular impact on society as described by their organizational mission. Generally, this mission is geared toward having an effect on one or more critical issues facing society, such as health or education. For the purpose of this study, organizations were considered mission-driven if they were either a traditional nonprofit organization or a social enterprise that placed the importance of social impact at an equal or greater level than profit.</p><p>The hub of data collection and use within mission driven organizations is the monitoring and evaluation (M&amp;E) department or, more likely, a singular M&amp;E professional who may also have several other job responsibilities. The individual(s) responsible for M&amp;E oversee the on-going monitoring of program activities against targeted outputs and outcomes. They also may conduct more comprehensive retrospective evaluations that examine the program's operation and assess progress towards intended short-term and long-term outcomes. This work often involves orienting to an organizational "theory of change," a model that (a) represents how a social intervention intends to use resources to perform programmatic activities and ultimately achieve the desired social impact, and (b) suggests specific metrics that the organization should be using to measure impact.</p><p>The unique mission-driven context shapes organizations' relationships to data, impacts how that data can ultimately be put to use, and influences to what ends and for whom it can serve. To situate the findings of this work, we first provide some background on four key characteristics of the missiondriven context: limited resources, grant-driven business models, social impact measurement, and reliance on external experts. Each characteristic is well-established in nonprofit management but where appropriate, we augment our characterization with specific references to participants in this study to illustrate more concretely how these characteristics influence data practices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limited Resources</head><p>The experiences of participants in this research confirm prior findings that nonprofits have limited financial and labor resources (e.g., <ref type="bibr" target="#b20">[22,</ref><ref type="bibr" target="#b34">37]</ref>). These limitations influence data practices from collection to analysis to reporting. Participants were particularly attuned to the limitations of time as a resource, and framed many of their frustrations in terms of having to make difficult tradeoffs as a result. Often, organizations restrict the time spent on data practices to that which is obligated by external funders. So while significant time is devoted to collecting data, analyzing that data beyond the production of reports for external funders is rare.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Grant-Driven Business Model</head><p>The organizations in this research were all, to varying degrees, reliant on grants made by external funding agencies to carry out their work. This means that funders have significant sway over organizations, which we see manifesting through prescriptions about what data to collect, how to report on it and how to interpret it. Organizations with funding from multiple sources had to negotiate compounding-and sometimes conflicting-requirements for data collection, management, and reporting. This can be problematic because it amplifies an existing challenge that arises from a misalignment of goals between funding bodies and the organizations themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social Impact Measurement</head><p>Mission-driven organizations try to intervene in complex, large-scale social issues that make both data collection and analysis difficult. Any change caused by the work of the organization is intertwined with-and likely indistinguishable from-the variety of other social changes happening concurrently: ranging from changes in government programs, to local economic shifts, to even more localized changes within the lives of families and individuals served by organizations. Organizational "impact" is not easily disentangled or isolated in ways that may be attributed causally to a particular program.</p><p>Complicating the difficulties of establishing causality, social impact is something that cannot be achieved overnight-it takes time. This means that data collection must be longitudinal in order to be most useful. Yet, knowing what data to collect at the start of a program is often impossible. Consequently, datasets collected by organizations are often incomplete-beginning with one set of metrics, and shifting over time to include more or simply different metrics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reliance on External Experts</head><p>Similar to the findings of Erete et al that described nonprofits' reliance on external experts for "open data" work <ref type="bibr" target="#b7">[8]</ref>, we found that M&amp;E data practices are also generally reliant on external experts. For the organizations in this study, external experts included: professional evaluators, researchers, graduate student interns, data scientists, regional coordinators, and technology consultants. M&amp;E professionals have expectations about the differing abilities of each group, with volunteer data scientists providing "game changing" assistance and interns providing hit-ormiss help. Yet, in the case of smaller, more resourceconstrained organizations, unpaid interns are the only realistic option. Organizations with more financial resources were more likely to have a dedicated "data analyst" on staff, however, even in these cases professional consultants are still hired on a temporary basis. Despite differing levels of knowledge and experience, our participants generally felt that all of these experts have the necessary expertise to be able to work with the intricacies of their data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>FINDINGS</head><p>We find that mission-driven organizations' monitoring and evaluation (M&amp;E) practices result in three unforeseen and negative consequences that are mutually reinforcing and lead to a cycle of increasing disempowerment for the organization. These consequences are: erosion of autonomy, data drift, and data fragmentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Erosion of Autonomy</head><p>All participants described experiencing an erosion of autonomy-including individual and organizational autonomy-over data practices due to the influence of external actors, including funding bodies, boards, ratings agencies, and information technologies. This array of actors exerts influence, impinging upon organizations' autonomy in making decisions about choosing metrics, compiling and using data, and prioritizing data work. As organizations move towards computational systems of measurement, they are also encountering information systems that prioritize quantitative over qualitative forms of data. As P10 explained about her organization's database: "We would need to have people answer qualitative questions in a quantitative way. So, 'how did this make you feel on a scale of 1 to 10?'" (P10)</p><p>Even at the funder level, information systems served to steer staff members towards quantitative data that can more easily be accessed and queried. This was explained by a staff member at a community foundation:</p><p>Any When broader social impacts are valued, report preparation timelines can prohibit longer term evaluations as granting agencies operate on short-term cycles (and thereby encourage surface level evaluation) rather than asking for or rewarding in-depth and longitudinal evaluation. Moreover, participants reported challenges in putting reports to use internally which had been prepared for the primary consumption of external stakeholders. For P10, it is challenging to resist the option of "just taking the report and putting it on the shelf" (P10). Even though a report might contain potentially useful data about operations, leveraging the report in ways that might inform internal practices would require additional time that staff do not have.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Prioritizing Data Work</head><p>The many data collection requirements and the use of data by external actors to evaluate and rate mission-driven organizations contribute to eroding organizations' autonomy over their own processes. This occurs at the most mundane and micromanaging kind of level: how to prioritize staff time. Staff members in this study reported a lack of time to accomplish their many tasks which often resulted in a prioritization of data work for funders over that which might be done for the organization. One participant explained:</p><p>Data Culture CHI 2017, May 6-11, 2017, Denver, CO, USA "Taking all of that data, entering it into something that makes it make sense, and figuring out how to use it is never a priority when there are fires to put out every day" (P8). Despite these fires, P8 finds time to collect and report on indicators that the funders want.</p><p>The kinds of rigorous evaluations that participants report would allow organizations to examine their own programs in terms of long-term causal outcomes are not supported within the rubric of most grants, the data demands of ratings agencies, or the information systems designed for tracking and analyzing only limited kinds of metrics. Funding for additional data work is harder to find in the mission-driven environment, which is increasingly dominated by directed funding earmarked for specific programs. Initiatives to build organizational capacity and infrastructure for data workoften referred to as "administrative overhead"-weighs against an organization's perceived effectiveness and efficiency in carrying out their mission.</p><p>When data collection must conform to frameworks and blueprints dictated by funders, organizations are left juggling everyone's needs except their own. The accounts of data work reflected by participants suggests that organizations are operating within a cacophony of data strategies. Regardless of who is setting the direction and what their motivation is, choices about what data to collect and report are partially driven by whomever happens to be providing direction. In this diverse ecosystem of data stakeholders, it is unclear that there is ever a single, overarching plan. What is clear, however, is that the organizations, themselves, have relatively little autonomy in setting or even providing input into that overarching plan-which lays a foundation for organizational disempowerment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Drift</head><p>The nonprofit sector refers to the move away from an organization's mission over time as "mission drift" <ref type="bibr" target="#b21">[23]</ref>. Mission drift has severely negative connotations as organizations are involuntarily and unknowingly pulled away from their original mission toward a new one. In our research, we see a similar shift at the level of data. Through data drift, organizations change the kind of metrics that they collect and manage over time as their organizational identity, as represented by data, evolves. Despite the possibility that an approach to M&amp;E may not be a good match for the organization, an eroding autonomy can prevent them from putting their data trajectory back on course. As misguided data is used in evaluation and funding decisions, the next round of data collection requirements are likely to be even further from the organization's intended direction.</p><p>For the participants in this study, external influences cause data drift at multiple stages of the organization's workflow: from initial, orienting theories of change to final reporting. For example, one participant (P11) described how the organization's theory of change was developed not from rigorous research or impact measurement, but rather based on the funder's objectives by "scoping and identifying"</p><p>where their project had the most demonstrable impact. In this instance, the funder was comparatively hands-off, yet still indirectly manipulated the way that staff viewed their program's impact. Theories of change influence choices of what indicators to track, and defining change rooted in funders' objectives leads to shifts in data collection towards the funder's priorities, all the while neglecting metrics more squarely related to the organization's own mission.</p><p>In another instance, one executive director (P8) explained that she sees her organization as helping individuals escape poverty. However, one of their two primary funders is particularly interested in their work in terms of its environmental impact-because that is the funder's mission.</p><p>From the nonprofit's perspective, they feel that their program's environmental impact is "nothing" compared to other renewable energy projects. However, the funder is "very interested in those environmental indicators, and so we end up doing a lot of weird environmental that we don't typically focus on" (P8). Thus, data drift is perpetuated in this organization because of their ambivalence about pushing back on a "strong" funder. P8 continues by describing how funders shape data collection decisions:</p><p>We find ourselves kind of hustling to do M&amp;E in a way that might not necessarily always make sense for us. But we need it for a report, and we need these numbers and even if it's something that we've never thought about collecting before, it's like, well, figure out how to collect it because so and so says we need it. (P8) P8 goes on to describe how grant-based funding can impact the mission of the organization over time: </p><formula xml:id="formula_0">[</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Locational Fragmentation</head><p>Locational fragmentation occurs when different data are in different systems. For two participants, locational fragmentation resulted from a lack of funding that prevented them from accessing a single, centralized enterprise-level data management system. Instead, in both of these cases, participants' leveraged multiple, free cloud services for storing data. As P11 explained, data management is particularly difficult "across a team… who don't have a lot of money to invest in cloud services besides Dropbox and Google" (P11).</p><p>Such cases of locational fragmentation were a frequent source of confusion (see also <ref type="bibr" target="#b36">[39]</ref>) at another organization:</p><p>[There is not] one place where we can have everything, it's like OK well you have Google Drive, and some people use Dropbox and some people use our database… it's really confusing to be like well where was that data stored?... [I received] an invitation for Dropbox stuff a couple days ago. It's like ahh, I forgot we were using that for stuff, for some reason, I don't know why we were-probably ran out of room on Google Drive so they started using something else. (P7)</p><p>In addition to this locational fragmentation that occurs within individual organizations, locational fragmentation also occurs across organizational boundaries. All participants in this research discussed sharing data with external parties and relying on others to share relevant data in return. Yet, this sharing of data across organizations was not always easy to negotiate and relied on both trust and equitable power dynamics. As P8, explained, there was a relevant dataset that existed within another organization. P8's organization could not access it quite yet because they are waiting until they "have a slightly stronger relationship" (P8).</p><p>When one organization possessed some level of power over another organization, the exchange of data can be mandated, thereby mitigating locational fragmentation for the organization with power but contributing to a cycle of disempowerment for the organization without it. The organization that P1 works for explains:</p><p>We can't really require them to do [any data entry]. The [participants in another program] are required because we're actually providing them consultants for free. (P1)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Logical Fragmentation</head><p>Complicating the distributed data storage locations, data was also logically fragmented-data sets discussed by participants did not complement each another in a systematic way. This fragmentation was observed in disparate data sets whose motivations for collection were determined through isolated processes by unique individuals or groups.</p><p>One M&amp;E intern discussed the changes in organizational context that led to the logical fragmentation of their data:</p><p>They had the head of the region… implementing just plain spreadsheets… I started redoing that entire thing… No one had really tackled that piece before. So, I think that they were suffering from kind of poor structure. And they were trying to grow. No one was thinking about putting systems in place from the start. (P9)</p><p>In a different organization, staff turnover led to difficulty integrating a new dataset with two previously existing datasets. At the time of the interview, the participant was looking for a graduate student intern to "see where the compatibilities are… [to] see if we could kind of merge these data sets so we have something to work with" (P12).</p><p>Within the same organization, a graduate student working on a class project failed to collect data that would have been useful to the organization because that data was not interesting to her as a student. As P12 explained:</p><p>[The student is] also testing the water… but it's only testing for bacteria, things that would cause diarrhea, and I'm like, you need more comprehensive [tests] if you're gonna test the water. They're doing major industrial agriculture for export (sugar cane), and I suspect they're putting lots of crap in the water. (P12)</p><p>While organizations rely on external experts to make sense of their fragmented data sets, those same experts can also contribute to the proliferation of yet more data sets that may not logically be aligned with the organization's mission, needs, or previously existing data sets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Longitudinal Fragmentation</head><p>Finally, data is also fragmented along a temporal dimension-with data not consistently collected or organized in ways that enable longitudinal data collection and analysis. This fragmentation is most critical for the longitudinal tracking of interventions, a key component of mission-driven work. One participant (P8) discussed determining what data to track one year into the program:</p><p>It would be really beneficial to sit down with maybe some of our best partners… and really be thoughtful about what is the point of this? And look back at the survey data that we have collected from teachers and students to see, maybe what are the big things that emerge from this first year? And then if the best thing that the students say is that I could continue coming to school, OK, maybe that becomes the outcome that we're tracking for this next year. (P8)</p><p>In an information system designed by outside consultants for one organization, longitudinal fragmentation stemmed from a design decision to skip the common practice of assigning unique identifiers to individual people. As a result, the Data Culture CHI 2017, May 6-11, 2017, Denver, CO, USA organization could not use their data to track individual changes over time. As one staff member reflected, "it was then, like, useless for data that had been going on for years" (P6). As a workaround, the organization hired a full time staff member to do manual linking of records:</p><p>The only way they could get all of the pieces of data that they needed and connect them was to completely dump two separate SQL databases and then take Excel and try to merge them based on the email address. (P1)</p><p>Due to the importance of the data and the enviable ability to hire a full-time staff member, this particular organization was able to work through the data fragmentation issue. Most other mission-driven organizations are not. With all forms of fragmentation, participants reported numerous impediments to actually being able to use their data, rendering yet another foundation for disempowerment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CYCLE OF DISEMPOWERMENT</head><p>In a complicated ecosystem of multiple stakeholders and shifting needs that are intertwined with evolving political landscapes, data offers mission-driven organizations a promise that they can cut through the complexity, make sense of constituent needs, and track their work's impact against organizational goals. Data offers mission-driven organizations a promise of empowerment. However, what we find instead in the organizations in this study are data practices that erode autonomy, precipitate data drift, and that fragment and undermine the infrastructuring of data. These three consequences of M&amp;E practices further exacerbate each other, creating a cycle of disempowerment [Figure <ref type="figure" target="#fig_0">1</ref>].</p><p>Autonomy of the organizations in this study is impinged upon from the start by external stakeholders-especially, but not limited to, funding agencies-whose ideas about what measurable impacts are deemed valuable implicitly or explicitly shape data practices through prescriptions of what metrics organizations should track, what information systems (owned by whom) should be used to collect M&amp;E data, and how such data should be reported. Data analysis is conducted by outsiders and consultants, disconnected from the organizational mission and from the organizations' longterm vision of social impact. Data and reports are compiled in the systems of ever evolving rosters of funders, often outside the control of the organizations themselves. Taken together, these data practices eroded organizational autonomy, dictating how already over-worked staff should allocate their limited time for data practices, leading to data drift and data fragmentation.</p><p>This erosion of autonomy contributes directly to data driftthe shifting of metrics and data collection foci in response to externally re-framed missions and priorities, moving the organization towards a mission that is both undefined and unknowable. Data drift, in turn, contributes towards an even greater erosion of organizational autonomy, as the data the organizations are left to work with moves them farther and farther away from their core mission and expertise.</p><p>The erosion of organizational autonomy also contributes to data fragmentation-where issues of power dynamics, a reliance on external expertise and frequent stakeholder turnover lead to a proliferation of disconnected data sets. And yet, the more fragmented the data becomes, the more reliant organizations become on external expertise to fix the problem, further undermining organizational autonomy.</p><p>Data fragmentation and data drift are also mutually reinforcing. As the data that is collected changes over time, data drift contributes to both longitudinal and logical fragmentation by introducing data sets that are dissimilar to previously collected data. As new types of data are collected-especially if mandated by new funders-data drift also leads to locational fragmentation, as data is collected in or moved into new and different funder systems.</p><p>Looking back the other way, data fragmentation may also lead to data drift, as different outside experts logically fragment data by periodically shifting focus from one set of metrics to another, resulting in a changing organizational identity as represented by their data. As the data makes less sense due to its fragmented state, the organization loses the ability to systematically understand the differences between their current and prior data environments.</p><p>These challenges compound and loop back on each other to reinforce a cycle of disempowerment overlaid on M&amp;E practices that are, themselves, in a near-continual state of flux. This cycle results in these organizations having an everdecreasing role in designing their data strategy, executing their own vision, and making meaning of the data that they spend much of their constrained time collecting.</p><p>Data Driven for Whom?</p><p>The cycle of disempowerment sheds new insights into the enactment and consequences of current implementations of data-driven decision making. Organizations are under great pressure to adopt data-driven decision making strategies (e.g., <ref type="bibr" target="#b10">[11]</ref>). And there is some evidence, especially from the private sector, to suggest that data-driven decision making can be impactful <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref>. Yet, there are many concerns about the potential of data-driven practices in the mission-driven space, with various scholars raising possible explanations for the challenges observed: that organizations may not be adept or confident enough to use data effectively <ref type="bibr" target="#b19">[21]</ref> and that metricization is not appropriate for the mission-driven nature of organizations in this sector <ref type="bibr" target="#b0">[1]</ref>.</p><p>What the cycle of disempowerment foregrounds is that each of these explanations fall short of explaining why data-driven processes are not working. The M&amp;E professionals in mission-driven organizations are quite articulate about what kinds of data could be useful in evaluating their programs; they are invested in the work of trying to better understand how to measure impact in some of the most complex and thorny situations. Most individuals we interviewed believe that data could be useful.</p><p>Yet, we find that the achievement of a data-driven culture is currently an impossibility-beyond the problems introduced by any particular analytics tool that thwarts the actionable use of data <ref type="bibr" target="#b33">[36]</ref>-rooted in a more pernicious set of power relations among stakeholders. Here we find that data tools and practices are not constituting relations that newly empower organizations. Rather, data tools and practices are re-entrenching existing social relations, and making them harder to work around. Relationships with funders, for example, are being reified and reinforced through the adoption of their systems for data management-leading to increased fragmentation-and their metrics of impact and success-leading to data drift.</p><p>This research raises the question of "data-driven for whom?"</p><p>The acute political imbalance that disempowers the organization and its own expertise suggests broader implications about what may be happening more or less invisibly in so-called successful exemplars of data practices (e.g., <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b15">16]</ref>). If data practices serve those who make decisions about what data to collect and how to collect it, and definitions of success shift to align with the metrics that are measured, the positive outcomes of data-driven decision making risk being self-reinforcing. Researchers are beginning to key in on the fact that certain metrics are being over-reified in ways that re-define what constitutes success, especially in health settings <ref type="bibr" target="#b25">[27,</ref><ref type="bibr" target="#b26">28]</ref>. As the construction of health becomes tightly bound up in particular metrics-e.g., heart rate, blood pressure-then interventions in response to changes in those metrics will always appear to result in better health outcomes. Yet, if health was understood in other terms, then acting on the data that these metrics offerstriving to keep heart rate or blood pressure within a certain target range while ignoring other effects-may not, in fact, produce positive outcomes for patients.</p><p>Given the cycle of disempowerment in mission-driven organizations, we are concerned that their data drift might move organizations towards increasing alignment with metrics about the health of their programs and services that stand to be similarly self-reinforcing-that organizations will appear to be more 'successful' over time as they abandon and re-shape their mission to the terms of the data at hand. This is the pernicious consequence of data drift, that it changes the potential futures that the organization might have. It also changes the potential futures for those clients, constituents, and beneficiaries served by the organization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Disempowered at Whose Expense?</head><p>What is strikingly absent from the data in this research are discussions about the role of client, constituent, and beneficiary feedback in the evaluation work of missiondriven organizations. This absence is particularly striking because the preponderance of mission-driven organizations provide direct products and services to individuals who are, themselves, already marginalized. There is ample evidence in the HCI literature about adoption challenges that derive from inequalities between who does the work and who benefits <ref type="bibr" target="#b8">[9]</ref>, and this likely plays a role. However, our research suggests that the non-use of tools that would support constituent data collection is not simply a lack of caring. Our research suggests that the disempowerment of clients, constituents, and beneficiaries-through not having a voice in the M&amp;E practices of mission-driven organizations-is likely a result of the disempowerment of the mission-driven organizations, themselves: staff pressured to navigate a complicated web of actors that perpetuate a cacophony of data demands, drawing them away from the of their mission as embodied by and through constituents. As M&amp;E work becomes further institutionalized and as metrics for evaluation stand to become standardized in the infrastructures of organizations and their funders, this is the time for calling out the disempowerment of clients, constituents, and beneficiaries at the hands of externally prescribed data practices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Designing to Disrupt the Cycle of Disempowerment</head><p>In the early 1800s, statisticians from the French Bureau de Statistique undertook one of the first comprehensive national censuses, sending questionnaires to each départment <ref type="bibr" target="#b29">[31]</ref>. Yet the Bureau "quickly learned that no single set of categories could be adequate" and asked local authorities to supplement the national census categories with locallydefined categories. But we also see a critical role for researchers and designers in designing new data systems that help individuals and organizations work around imperfect and incomplete data. The design of information systems used in the missiondriven sector nearly always lock organizations into fixed schemas and demand a complete year-on-year set of data. Nearly all M&amp;E professionals who participated in this research believed that imperfect or incomplete data was generally useless for developing a longitudinal or comprehensive analysis of social impact. But whether the data collected and managed evolved through data drift or through evolving understandings of what metrics were important to capture, nearly all organizations in this study reported changes to their data over time. And surely there is a broader design space worth exploring for supporting evidenced-based research about social impact without over proscribing the mathematization of 'data' or requiring perfect statistical inputs. What would it look like to build data systems from a sociological or historical perspective, for example? What would it look like to build data systems that drew on tools of interpretivist traditions that not require psychological or mathematical ideals of explanation to enable M&amp;E professionals be able to learn things useful about the work of their organization?</p><p>A Note About Our Use of Disempowerment</p><p>Although our analysis of data from interviews with M&amp;E professionals suggests that these organizations are currently caught in a cycle of disempowerment, we do not see any evidence that these organizations should be relegated to a permanently marginalized standing with respect to data. And indeed, scholarship in community-based research warns against labeling communities as "damaged," as these labels stand to further contribute to marginalization and disempowerment <ref type="bibr">[35]</ref>. We do not intend to suggest that mission-driven organizations or other stakeholders discussed in this paper are damaged. Indeed, the M&amp;E professionals who participated in this research have significant expertise and it is essential to find ways that this expertise can be given the weight it deserves. Our intent, then, is to draw attention to the cycle so that we are better able to move beyond it.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CONCLUSION</head><p>In the context of monitoring and evaluation, where the role of data stands to be most tightly aligned with the mission of the organization and the passion of its employees, data practices are all-too-often experienced as busy work. For the participants in this research, data practices are predominantly experienced as a production for others that might happen at scale, but that is disconnected from any localized meaning or value and isolated from the complexities of the social situations these organizations operate within.</p><p>Mission-driven organizations serve critical social roles. However, the disempowerment of organizations in this study suggests that the cards are stacked against the very organizations that our communities rely upon. As staff get caught up in the demands of data practices, autonomy is eroded, data is fragmented, and the organization begins to change through data drift. These consequences come together to result in organizations that are neither empowered nor equipped to think and plan for the long term, despite our communities' needs for such strategic planning.</p><p>In this research, we have made the following contributions:</p><p>1. Provided an empirical account of the data practices of monitoring and evaluation professionals in mission-driven organizations; 2. Identified three negative consequences of current monitoring and evaluation practices: erosion of autonomy, data drift, and data fragmentation; and 3. Identified relationships among these consequences, demonstrating how they collectively reinforce a cycle of disempowerment for the mission-driven organization.</p><p>There is promise for the role of data in the monitoring and evaluation work of mission-driven organizations. Yet, this study of data practices demonstrates that this empowering use of data is currently thwarted. Now-at this opportune cusp when new practices are starting to collide with the newto-data-driven-decision-making value orientations of the mission-driven sector-is the time for intervening in ways that might support and empower mission-driven organizations in their use of data.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Cycle of Disempowerment. The influence of external actors on data practices erode organizational autonomy and precipitate data drift-the altering of metrics in response to shifting requirements-and data fragmentation-the dispersal of data in non-coherent systems and schemas. These mutuallyreinforcing consequences further erode autonomy leading to a cycle of disempowerment.</figDesc><graphic url="image-3.png" coords="8,82.57,61.69,183.84,114.72" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>reporting…[on] the difference we made in the community…is outside of any formal IT system. It's coming in probably on a dozen different channels, with a dozen different formats and it's not centralized. So, if someone were to say I need to measure our impact, [the IT systems] wouldn't be very much help. [Using the database], I could tell them where the money went…[but] if you want to know the stories…about what difference we made, you need to go talk to [a program staff member] because I don't have anything I can touch that gets to that. (P16)In addition to these constraints on what data to collect and what kinds of data are considered valuable, participants' accounts suggests that decisions about how to use data were further sites of eroded autonomy. There is a key distinction between the evaluation work required by funders and a more rigorous evaluation that would more closely benefit the mission of the organization. Often, evaluation work required by grants, referred to as "implementation evaluation" by P15, is not intended to understand how a program has caused a change in society, instead it is intended to determine if the grant dollars were spent in the agreed upon manner.</figDesc><table /><note>Funders are interested in building evaluation in around the specific objectives of that project… It's more of an implementation research question that funders have … Really rigorous evaluation of what works … that's the type of evaluation that it's harder to get a funder to say 'Oh yeah, I'll do that.' For instance, we have a couple projects where… we have a comparison group that we're working with that isn't getting the intervention. That type of project is expensive, and funders have to have the vision to see that what we'll learn from that might have a lot of later potential impact if we know if the intervention works. (P15)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>May 6-11, 2017, Denver, CO, USA on</head><label></label><figDesc>this topic at CHI and CSCW, it remains a thorny problem for researchers to figure out how to address in new ways<ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b25">27,</ref><ref type="bibr" target="#b35">38,</ref><ref type="bibr" target="#b33">36]</ref>. Through our study of the work practices of M&amp;E professionals, we see quite distinctly the negative organizational outcomes of these tensions being resolvedas is currently-without sufficient local input. Any disruption of the cycle of disempowerment is likely to require granting some autonomy in data practices to organizations. And yet, disrupting the cycle would require disrupting entrenched relationships among funders, organizations, ratings agencies, and others, as power is constituted through these relationships. But what researchers can do is tell stories about data practices and their presumably unintended consequences on organizations. Researchers can convene groups of stakeholders for participatory design workshops to engage in dialogue about data and undertake collaborative processes of commensuration.</figDesc><table><row><cell>Data Culture</cell><cell>CHI 2017,</cell></row><row><cell></cell><cell>As Porter writes, drawing on Bourget's</cell></row><row><cell></cell><cell>earlier work, "'recognizing the existence of a diverse, local</cell></row><row><cell></cell><cell>reality, irreducible to the categories of a national accounting'</cell></row><row><cell></cell><cell>was a damaging concession" to the viability of a purely</cell></row><row><cell></cell><cell>nationally framed census ([31] quoting Bourguet).</cell></row></table><note>The tensions between uniform metrics and the metrics that derive from and reflect local experience, then, are not a new problem. Yet as evidenced by the recent surge in scholarship</note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>We thank all the individuals who graciously participated in this study. We also thank Leysia Palen, Marisa Cohn, and our anonymous reviewers for their feedback on this research. This material is based upon work supported by the National Science Foundation under Grant Number 1602660. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0" />			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">C Programs Aren&apos;t Everything. Stanford Social Innovation Review</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="42" to="47" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Sorting things out: Classification and its consequences</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Bowker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Star</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<publisher>MIT press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Critical questions for big data: Provocations for a cultural, technological, and scholarly phenomenon. Information, communication &amp; society</title>
		<author>
			<persName><forename type="first">D</forename><surname>Boyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Crawford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="662" to="679" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Strength in numbers: How does data-driven decision making affect firm performance?</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Hitt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
	<note>Available at SSRN 1819486</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">The Big Data Boom is the Innovation Story of Our Time. The Atlantic</title>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mcafee</surname></persName>
		</author>
		<ptr target="http://www.theatlantic.com/business/archive/2011/11/the-big-data-boom-is-the-innovation-story-of-our-time/248215/" />
		<imprint>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Basics of qualitative research: Techniques and procedures for developing grounded theory</title>
		<author>
			<persName><forename type="first">J</forename><surname>Corbin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Strauss</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<pubPlace>Sage</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">E-government intermediaries and the challenges of access and trust</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dombrowski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazmanian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Transactions on Computer-Human Interaction</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Storytelling with Data: Examining the Use of Data by Non-Profit Organizations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Erete</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Ryou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">M</forename><surname>Fassett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Duda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing</title>
				<meeting>the 19th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="1273" to="1283" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Groupware and social dynamics: Eight challenges for developers</title>
		<author>
			<persName><forename type="first">J</forename><surname>Grudin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="92" to="105" />
			<date type="published" when="1994">1994</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Stories of the Smartphone in Everyday Discourse: Conflict, Tension &amp; Instability</title>
		<author>
			<persName><forename type="first">E</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazmanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="1051" to="1060" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Building the connection between policy and evidence. Using Evidence to Improve Social Policy and Practice</title>
		<author>
			<persName><forename type="first">R</forename><surname>Haskins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Baron</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page">25</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The organizational divide</title>
		<author>
			<persName><forename type="first">J</forename><surname>Kirschenbaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kunamneni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bridging the digital divide: Technology, community, and public policy</title>
				<editor>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Servon</surname></persName>
		</editor>
		<meeting><address><addrLine>Malden, MA</addrLine></address></meeting>
		<imprint>
			<publisher>Blackwell Publishing</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="177" to="198" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Big Data, new epistemologies and paradigm shifts</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kitchin</surname></persName>
		</author>
		<idno type="DOI">10.1177/2053951714528481</idno>
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2014">2014</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Emerging trends in business analytics</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohavi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rothleder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Simoudis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications of the ACM</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="45" to="48" />
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">e-Government services for faith-based organizations: Bridging the organizational divide</title>
		<author>
			<persName><forename type="first">L</forename><surname>Kvasny</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Government Information Quarterly</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="66" to="73" />
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Big data, analytics and the path from insights to value</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lavalle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Lesser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Shockley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Hopkins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kruschwitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT Sloan management review</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">21</biblScope>
			<date type="published" when="2011">2011</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Does performance measurement improve strategic decision making? Findings from a national survey of nonprofit social service agencies. Nonprofit and Voluntary Sector Quarterly</title>
		<author>
			<persName><forename type="first">K</forename><surname>Leroux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Wright</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Lincoln</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename><surname>Guba</surname></persName>
		</author>
		<title level="m">Naturalistic inquiry</title>
				<meeting><address><addrLine>Sage</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1985">1985</date>
			<biblScope unit="volume">75</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Trending: the promises and challenges of big social data</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lohr</surname></persName>
		</author>
		<ptr target="http://manovich.net/content/04-projects/065-trending-the-promises-and-the-challenges-of-big-social-data/64-article-2011.pdf" />
	</analytic>
	<monogr>
		<title level="m">The age of big data. The New York Times Online at</title>
				<editor>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Gold</surname></persName>
		</editor>
		<meeting><address><addrLine>Minneapolis, MN</addrLine></address></meeting>
		<imprint>
			<publisher>The University of Minnesota Press</publisher>
			<date type="published" when="2011">2012. February 11. 2011</date>
		</imprint>
	</monogr>
	<note>Debates in the Digital Humanities</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Data and Decision Making Same Organization, Different Perceptions; Different Organizations, Different Perceptions</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Maxwell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Rotz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Garcia</surname></persName>
		</author>
		<idno type="DOI">10.1177/1098214015623634</idno>
	</analytic>
	<monogr>
		<title level="j">American Journal of Evaluation</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="463" to="485" />
			<date type="published" when="2016">2016</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Managing technology use and learning in nonprofit community organizations: methodological challenges and opportunities</title>
		<author>
			<persName><forename type="first">C</forename><surname>Merkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Farooq</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Ganoe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">B</forename><surname>Rosson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Carroll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2007 symposium on Computer human interaction for the management of information technology</title>
				<meeting>the 2007 symposium on Computer human interaction for the management of information technology<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<date type="published" when="2007">2007</date>
			<biblScope unit="volume">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Managing for value: Organizational strategy in for-profit, nonprofit, and governmental organizations. Nonprofit and Voluntary Sector Quarterly</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Moore</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="183" to="208" />
		</imprint>
	</monogr>
	<note>suppl 1</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Images of organization</title>
		<author>
			<persName><forename type="first">G</forename><surname>Morgan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Gregory</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Roach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Sage Publications</publisher>
			<pubPlace>Thousand Oaks, Calif</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Curiosity, Creativity, and Surprise as Analytic Tools: Grounded Theory Method</title>
		<author>
			<persName><forename type="first">M</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Ways of Knowing in HCI</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2014">2014</date>
			<biblScope unit="page" from="25" to="48" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Profit from customer data by identifying strategic opportunities and adopting Data Culture CHI</title>
		<author>
			<persName><forename type="first">G</forename><surname>Piccoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Watson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">the &apos;born digital&apos; approach</title>
				<meeting><address><addrLine>Denver, CO, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008. 2017. May 6-11, 2017</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="113" to="122" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The politics of measurement and action</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Pine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Liboiron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</title>
				<meeting>the 33rd Annual ACM Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="3147" to="3156" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Emerging Insights on Building Infrastructure for Data-Driven Transparency and Accountability of Organizations</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Pine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mazmanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the iConference</title>
				<meeting>the iConference</meeting>
		<imprint>
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">The audit society: Rituals of verification</title>
		<author>
			<persName><forename type="first">M</forename><surname>Power</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997">1997</date>
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Will auditors take over the world? Program, technique and the verification of everything. Accounting</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizations and Society</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="307" to="312" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Trust in numbers: The pursuit of objectivity in science and public life</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Porter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1995">1995</date>
			<publisher>Princeton University Press</publisher>
			<biblScope unit="page" from="35" to="37" />
			<pubPlace>Princeton, N.J</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<author>
			<persName><forename type="first">A</forename><surname>Punathambekar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Kavada</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Debating Big Data. Media</title>
				<imprint>
			<date type="published" when="2015">2015</date>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="1076" to="1077" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Small, minority-based nonprofits in the information age</title>
		<author>
			<persName><forename type="first">J</forename><surname>Schneider</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nonprofit Management &amp; Leadership</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="383" to="399" />
			<date type="published" when="2003">2003</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Drowning in data. Stanford Social Innovation Review</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Snibbe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Educational Review</title>
		<editor>35. Tuck, E.</editor>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="409" to="428" />
			<date type="published" when="2006-06-05">2006. June, 5, 2007. 2009</date>
		</imprint>
	</monogr>
	<note>Suspending damage: A letter to communities</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On being actionable: Mythologies of business intelligence and disconnects in drill downs</title>
		<author>
			<persName><forename type="first">N</forename><surname>Verma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Voida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 19th International Conference on Supporting Groupwork</title>
				<meeting>the 19th International Conference on Supporting Groupwork</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="325" to="334" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Homebrew databases: Complexities of everyday information management in nonprofit organizations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Voida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Al-Ani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011">2011</date>
			<biblScope unit="page" from="915" to="924" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Competing Currencies: Designing for Politics in Units of Measurement</title>
		<author>
			<persName><forename type="first">A</forename><surname>Voida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Harmon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Weller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thornsbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Casale</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vance</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Adams</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Grimley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Neeley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Goodyear</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 20th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing</title>
				<meeting>the 20th ACM Conference on Computer-Supported Cooperative Work &amp; Social Computing</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
	<note>To appear in</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Turbulence in the clouds: challenges of cloud-based information work</title>
		<author>
			<persName><forename type="first">A</forename><surname>Voida</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Olson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Olson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI Conference on Human Factors in Computing Systems</title>
				<meeting>the SIGCHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2013">2013</date>
			<biblScope unit="page" from="2273" to="2282" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The current state of business intelligence</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Watson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Wixom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Computer</title>
		<imprint>
			<biblScope unit="page" from="96" to="99" />
			<date type="published" when="2007-09">2007. September</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
