<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">&quot;It Matches My Worldview&quot;: Examining Perceptions and Attitudes Around Fake Videos</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Srujana</forename><surname>Kamath</surname></persName>
							<email>srujana.kamath@gmail.com</email>
							<idno type="ORCID">0000-0003-3004-7099</idno>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Annie</forename><surname>Sidotam</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vivian</forename><surname>Jiang</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Alexa</forename><surname>Batino</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aditya</forename><surname>Vashistha</surname></persName>
							<email>adityav@cornell.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Farhana</forename><surname>Shahid</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Cornell University Researcher</orgName>
								<address>
									<region>United, India</region>
									<country key="IN">India</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">&quot;It Matches My Worldview&quot;: Examining Perceptions and Attitudes Around Fake Videos</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3491102.3517646</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-07-22T05:02+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>techniques (e.g.</term>
					<term>photoshop</term>
					<term>lookalikes</term>
					<term>slowing down video frames</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>for generating more engagement and revenues on social media [28,    We present a qualitative study with 36 diverse social media users in 41]. India, the focus of our study, is one of the largest markets India to critically examine how low-resource communities engage with steeper consumption of video ads and other video sharing with fake videos, including cheapfakes and AI-generated deepfakes. services [102]. Around 97% of Indians, who are connected to the We find that most users are unaware of digitally manipulated fake Internet, watch videos online [89]. The availability of affordable videos and perceive videos to be fake only when they present in-smartphones and cheap mobile data along with the emergence accurate information. Few users who know about doctored videos of high-speed 4G network have made videos more popular and expect them to be of poor quality and know nothing about so-accessible to the masses in India-particularly to low-literate social phisticated deepfakes. Moreover, most users lack the skills and media users who are able to consume videos easily compared to willingness to spot fake videos and some were oblivious to the risks textual content [73].</p><p>and harms of fake videos. Even when users know a video to be However, this has proven to be a double-edged sword as many fake, they prefer to take no action and sometimes willingly share social media users tend to trust content in videos more <ref type="bibr" target="#b73">[93]</ref>. Fake fake videos that favor their worldview. Drawing on our findings, videos often exploit the human tendency of "Seeing is Believing" [10, we discuss design recommendations for social media platforms to 81] to skew information and perceptions, which often lead to incurb the spread of fake videos. creased levels of social schism and political polarization. For example, doctored videos and old videos used out-of-context have led to</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>CCS CONCEPTS</head><p>civic unrest and lynchings in India [45, 70]. These risks and harms have been more pronounced during the COVID-19 pandemic, where • Human-centered computing → Empirical studies in HCI.</p><p>fake videos spreading false health advice and anti-vaccine propa-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>KEYWORDS</head><p>ganda have led to increased hospitalizations and deaths, resulting in overburdened health systems [87]. Fake videos, Misinformation, India, Global South, ICTD, HCI4D</p><p>Traditionally, people have used common video editing tools and</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>appear intoxicated <ref type="bibr">[63]</ref>. However, among the arsenal of fake videos, AI-generated deepfake videos are considered to be the most harm-Social media platforms have seen an unprecedented growth in users ful, as they are becoming increasingly common and convincing. based in the Global South <ref type="bibr">[94]</ref>. In parallel, videos have also seen the Deepfakes closely resemble the original videos and may trick unfastest growth among all formats and are the major driving force trained human eyes to consider them as real <ref type="bibr" target="#b68">[90]</ref>. Journalists frame Despite the multifaceted threats of fake videos at large, most re-• A range of design recommendations that could mitigate the search to date heavily focuses on deepfake videos in the contexts of spread of fake videos on social media. Global North. For example, scholars have examined human accuracy in spotting deepfake videos <ref type="bibr">[17,</ref><ref type="bibr" target="#b59">61]</ref>, the harms they cause to individuals and society <ref type="bibr" target="#b14">[34,</ref><ref type="bibr">35,</ref><ref type="bibr" target="#b50">55,</ref><ref type="bibr" target="#b55">58,</ref><ref type="bibr" target="#b67">68,</ref><ref type="bibr" target="#b89">104]</ref>, and people's concerns</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>around the discovery and propagation of deepfakes <ref type="bibr">[3,</ref><ref type="bibr" target="#b1">4,</ref><ref type="bibr" target="#b23">18,</ref><ref type="bibr">30,</ref><ref type="bibr">111]</ref>.</p><p>Videos are becoming the dominant modality through which mis-However, despite large differences between new social media users information and fake news propagate on social media <ref type="bibr" target="#b42">[28,</ref><ref type="bibr">67]</ref>. By in the Global South and mainstream users in the Global North (e.g., tapping into video's popularity and virality, false narratives and prothe US), little work has been done to understand how emerging paganda get quickly amplified on platforms like YouTube <ref type="bibr" target="#b39">[47,</ref><ref type="bibr" target="#b84">101]</ref> social media users in the Global South engage with fake videos <ref type="bibr">[9]</ref> and TikTok <ref type="bibr">[113]</ref>, posing a serious threat to new social media users, and deepfakes <ref type="bibr" target="#b81">[99]</ref>.</p><p>most of whom are emerging in the Global South. To fill this critical gap, we conducted semi-structured interviews Despite the high risks of misinformation in the Global South, with 36 diverse social media users from rural and urban India, who most of the existing work to date has focused on misinformation in vary in terms of literacy, digital skills, and social media experience.</p><p>the Global North, including its prevalence <ref type="bibr" target="#b24">[40,</ref><ref type="bibr">53]</ref>, diffusion [7, 92], We sought to understand: RQ1: How do regular social media users and people's interactions with it <ref type="bibr" target="#b34">[25,</ref><ref type="bibr" target="#b37">26,</ref><ref type="bibr">59</ref>]. For example, scholars perceive and interact with fake videos? RQ2: How do they evaluate have examined factors that shape people' perceptions of informathe risks and harms of fake videos and what they consider necessary tion credibility, such as trust on the news source, interpersonal to curb its spread? trust in one's social network, and perceived homogeneity of the We used video probes (one real and three deepfake videos) to news content <ref type="bibr" target="#b22">[39,</ref><ref type="bibr" target="#b87">103]</ref>. A recent study notes that users' perceived guide our interviews and to elicit spontaneous responses from value of information to spark conversation and their desire for our participants and observe if they could identify the fake videos self-expression and socialization fuel the sharing of misinformation and if so, how. Our analysis revealed several alarming findings among the users based in the Global North <ref type="bibr" target="#b37">[26]</ref>. Besides, partisan on how social media users perceive and engage with fake videos bias <ref type="bibr" target="#b70">[91]</ref> and users' tendency to share content based on homogeneand what their associated mental models and threat models are.</p><p>ity <ref type="bibr" target="#b10">[11]</ref> reinforce confirmation bias and lead to the propagation of Our participants had varying perceptions of what they consider as misinformation and rumors. fake videos. Several participants were unaware that videos can be Prior studies show that people's intention to share misinformadoctored or edited, and most knew nothing about deepfakes. A few tion relates to their demographics and individual characteristics, participants, who were aware of digital manipulations of videos, such as age, gender, ideology, and biases <ref type="bibr" target="#b6">[8,</ref><ref type="bibr" target="#b26">20,</ref><ref type="bibr" target="#b62">64]</ref>. However, most expected these videos to be of poor quality and easily recognizable.</p><p>of the work so far focuses on users based in the Global North, result-In fact, most participants' understanding of fake videos was only ing in growing concerns around the extent to which the findings limited to inaccurate or false information presented in video format.</p><p>from the Global North generalize to misinformation and fake news In addition, most participants lacked the necessary skills, awareness, in other cultures and contexts <ref type="bibr" target="#b60">[62,</ref><ref type="bibr">79]</ref>. This has prompted several and willingness to identify fake videos and assess authenticity. Even scholars to study socially and culturally diverse social media users when participants knew a video to be fake, they rarely reported it in the Global South and how they interact with and propagate misand, sometimes willingly shared it. While some participants felt that information and fake news. We now situate our research in a body fake videos could do little or no harm, many described how these of related work examining misinformation and fake videos in the videos are polarizing and divisive. The participants also expressed Global South. diverse opinions in describing the role individuals, social media platforms, and governments should play to contain the spread of fake videos.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Misinformation in the Global South</head><p>Drawing on these findings, we synthesize key takeaways for</p><p>The politically charged environment in the Global South is a breed-HCI and social computing researchers interested in understanding ing ground for the proliferation of misinformation, fake news, and the misinformation landscape in low-income settings in the Global rumors <ref type="bibr">[37,</ref><ref type="bibr">86]</ref>. A recent study by Jakesch et al. <ref type="bibr" target="#b48">[52]</ref> shows how South. We discuss several design recommendations to foster mean-Indian political parties orchestrated and centrally organized their ingful dialogue and civil discourse on social media, for example, supporters on WhatsApp and Twitter to engineer social media by designing online educational and training programs to inform trends during elections. Recent work from Akbar et al. <ref type="bibr" target="#b2">[5]</ref> describe mental and threat models of new users about the emergent risks of how the COVID-19 pandemic led to a plethora of misinformation fake videos, using automated and explainable AI-based credibility in India, partly owing to its existing polarized and divisive inforindicators to label fake videos, and making the reporting feature mation environment. They observe that tweets from politicians more transparent and accessible. In summary, our work makes the tapped into communal prejudices and affective responses of the following contributions: mass, and ignited hatred and coordinated attack against particular religious groups. Several scholars have noted that the fact-checking • A qualitative study that critically examines how diverse so-resources in the Global South are too scarce to keep up with the wild cial media users in India identify and interact with fake pace of misinformation. For example, recent work from Haque et al. videos, explicating their engagement and propagation prac-</p><p>[44] about the existing fact-checking practices in Bangladesh shows tices and their perceptions around the risks and harms of that journalists believed fact-checking to be the responsibility of fake videos.</p><p>third-party fact-checkers rather than that of news media. On the other hand, voluntary fact-checkers reported facing various diffi-critically examine the diversity in social media users' perceptions culties in verifying online news due to limited resources and sparse of and interactions with fake videos in low-resource settings in the infrastructural support. In such muddy information environment, Global South. people often adopt different informal methods to assess information credibility. Recent work from Chandra and Pal <ref type="bibr">[22]</ref> shows that different stakeholders in a marketplace in India leveraged their</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>community bonds and collective knowledge to make sense of the We conducted an in-depth qualitative study with social media users rumors to interpret unfamiliar and ambiguous situations. Similarly, in urban and rural India from July to August 2021. To recruit urwork from Sultana and Fussell <ref type="bibr" target="#b77">[97]</ref> describes that rural villagers in ban participants, we reached out to our personal networks and Bangladesh relied on their religious faith, local beliefs and myths, used snowball sampling to have people from different demographand social justice sensibilities to fact-check COVID-related mis-ics ranging from low to middle income, digitally novice to literinformation. This line of work demonstrates that socio-cultural ate social media users. To recruit rural participants, we partnered values, local beliefs, and informal offline communication not only with a grassroots organization focusing on rural development with shape people's perceptions of misinformation but also influence significant presence in several regions in India. An organization collective fact-checking practices that often differ from professional staff member approached their primary contacts in the villages, fact-checking methods that prioritize authenticity over anything.</p><p>explained to them the purpose of our study, and gave us the contact These studies prompted us to dig deeper and investigate how di-information of those who were interested in speaking with us. All verse social media users in India perceive and engage with fake our interactions with the participants took place online to ensure videos considering their rapid propagation and harmful impact on safety of our participants due to the ongoing COVID-19 pandemic. the society <ref type="bibr" target="#b79">[98]</ref>. We now present scholarly work that looks into</p><p>Our study protocol comprised two phases. In the first phase, we sent different aspects of people's engagement with fake videos.</p><p>four videos to the participants via WhatsApp a few hours before the interview and asked them to watch the videos before our interview.</p><p>In the second phase, we conducted a semi-structured interview</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Engagement with Fake Videos</head><p>either via phone or Zoom calls as preferred by the participants. When it comes to how people interact with fake videos, one of Following the interview, we compensated each participant with the key questions is: can people detect them? Prior studies show INR 200 (∼USD 2.70). Our study was approved by the Institutional that even experienced social media users struggle to identify fake Review Board (IRB) at Cornell University. videos <ref type="bibr">[16]</ref>. As AI-generated deepfakes and cheapfakes become Sending Video Probes. HCI researchers have advocated using more common and convincing, several scholars have investigated cultural probes, artifacts, and technology probes to understand how people and machines can detect fake videos. Research shows the needs of the underserved communities and the complexities that most people lack the ability to spot high-quality deepfake of their everyday lives <ref type="bibr">[50,</ref><ref type="bibr" target="#b85">110]</ref>. These probes help collect "inspivideos and are only able to detect the low-quality ones to some rational data" that not only stimulate the design process but also extent <ref type="bibr">[17,</ref><ref type="bibr" target="#b59">61]</ref>. Apart from video quality, prior knowledge, familiar-elicit responses that provide a glimpse of the workflows, processes, ity with the subject, and visual cues (e.g., face, hair, eye, skin tone) aspirations. For example, Okolo et al. <ref type="bibr" target="#b49">[77]</ref> used video probes to help people in detecting deepfake videos <ref type="bibr" target="#b27">[43,</ref><ref type="bibr" target="#b51">56,</ref><ref type="bibr" target="#b81">99]</ref>. For example, explore the knowledge and perceptions of AI among low-income people are usually better at recognizing deepfake videos of known community health workers in India who had limited or no prior politicians or celebrities than the ones of unknown people <ref type="bibr" target="#b51">[56]</ref>. In experience with AI. Drawing on this prior work, we carefully cufact, the susceptibility to deepfake videos is amplified by the general rated a set of one real and three deepfake videos, and used them as lack of awareness around fake videos. A survey among students exploration artifacts to elicit people's understanding of and expein a public southeastern U.S. university revealed that almost half riences with fake videos generally and deepfakes specifically. We of the students were not aware of deepfake technology <ref type="bibr">[30]</ref>. Even chose to use video probes since we were unsure if our participants though many considered this technology to be harmful, some also have knowledge of and experiences with deepfakes in particular. found it amusing <ref type="bibr">[30]</ref>.</p><p>All the videos were of same length (∼10 seconds) and showed a Almost all the research discussed thus far investigates deepfake person of Indian origin speaking in Hindi. Among the three deepvideos in the context of Global North. In contrast, there is little fake videos, two were prepared using lip-sync and another using work that examines how social media users in the Global South face swapping deepfake technologies. Using lip-sync, a person's lip engage and deal with different types of fake videos and how users in movements are modified to match a new audio <ref type="bibr">[2]</ref>. Face-swapping low-income, rural settings engage with deepfake videos specifically.</p><p>transfers a source face to the destination while preserving destina-The work that is closest to ours is from Tahir et al. <ref type="bibr" target="#b81">[99]</ref> in which tion's facial expressions and movements <ref type="bibr" target="#b52">[80]</ref>. We opted to create the researchers conducted a user study with university students deepfake videos ourselves since we could not find good quality in Pakistan to examine how they detect deepfakes and designed a deepfake videos of people of Indian origin in Hindi. The three deeptraining program to improve their skills. Our work contributes to fake videos featured Indian cricketer Sachin Tendulkar (lip-synced), this line of work by engaging diverse social media users in rural Indian actor Pankaj Tripathi (lip-synced), and a television news and urban India to examine: (1) How do they perceive and interact anchor (face swapped). To understand if participants could differenwith fake videos, and (2) How do they evaluate the risks and harms tiate between fake and authentic videos, we also added a real video of fake videos and what they consider necessary to curb its spread.</p><p>featuring a popular Indian actor, Shah Rukh Khan. We avoided To our knowledge, ours is one of the earliest exploratory work to using any politically or religiously polarizing content so as to not bias our participants. We intentionally kept the videos brief (only including teachers, engineers, health workers, social workers, jour-10 seconds of duration) and used neutral, non-informative audio so nalists, and consultants, among others. Only four participants had a that participants could focus more on visual cues rather than the technology related background (e.g., CS student, engineer, software audio content. developer). Two urban participants were new smartphone users Conducting Semi-Structured Interviews. After the participants (with less than one year of experience) and the rest were using confirmed watching the videos, we conducted semi-structured in-smartphones for over five years. terviews with them. The majority of the interviews were conducted On the other hand, all rural participants were recruited from in Hindi and a few in English, following the preferences of the different villages in North India. About half of them had less than participants. At first, we read an informed consent script to the 12 years of formal schooling. We interviewed housewives, farmers, participants and requested their verbal consent. When agreed, the social workers, teachers, students, shopkeepers, private job holders, participants were asked to summarize their thoughts about the and unemployed folks. More than half of them used a smartphone videos we sent them. We then discussed their opinions about the for less than 5 years and about one-fourth were new to social videos before digging deeper into their existing knowledge of fake media with less than a year of experience. All our participants used videos, specifically deepfakes and cheapfakes. Our subsequent ques-WhatsApp, YouTube, and Facebook, with an exception of urban tions sought an in-depth understanding of how they perceive fake participants who also used Twitter, Reddit, and TikTok. videos, their knowledge about current technologies to create fake Positionality. All authors except two are from countries in the videos of varying qualities, their interactions with perceived fake Global South. Among them three are from India and have lived videos, how they evaluate the benefits and harms of fake videos, experiences of interacting with the kinds of fake videos many of our and the measures they consider necessary to tackle the onslaught participants referred to. Even though the authors have several years of fake videos. At the end of the interview, we debriefed our partici-of experience conducting fieldwork with low-income communities pants which videos were fake and which one was real. We requested in India, they acknowledge that they themselves are not low-income them not to share the videos with others. Since we had no way to and have not lived in rural regions for extended periods of time. confirm whether the participants would delete the videos or not</p><p>Their relative privilege provides them with certain advantages that share those with others, we intentionally chose neutral content most participants in this study do not hold. However, the authors' for all our videos to avoid any potential risks or harms. After each past engagements with urban and rural communities helped elicit interview, we revised our questions to add new probes, stopping in-depth responses from the participants and build a nuanced unwhen participants' responses reached saturation. Each interview derstanding of the underlying socio-cultural norms that impact lasted approximately 40 minutes, and was audio-recorded with the participants' engagement with fake videos. All authors view HCI consent of the participants.</p><p>research from an emancipatory action research mindset, which led Data Collection and Analysis. In total, we collected around 24 them to examine how people from socially and culturally diverse hours of audio recordings from the interviews. Audio recordings backgrounds experience and interact with fake videos online and were translated into English and transcribed. We then used induc-how this knowledge might inform design recommendations that tive thematic analysis [42] that allows key themes to emerge from could potentially curb the spread of fake videos in India. the raw data through repeated examination and comparison. At first, two authors individually coded the same interview and then</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">FINDINGS</head><p>came together to discuss discrepancies. We avoided using any pre-We begin by exploring participants' knowledge of and experiences supposed codes and instead let the codes emerge from our data. We with fake videos, including their encounters with deepfake and continued to code separately and came together after each interview cheapfake videos (Section 4.1). We then discuss how the participants until we had reached intercoder reliability and codebook stabilizadeal with fake videos (Section 4.2), before diving deeper into the tion. Following this, the authors separately coded the remaining potential benefits and harms of fake videos (Section 4.3), and their transcripts. Throughout the analysis, we held multiple discussions opinions on measures they consider important to prevent the spread to iteratively refine the codes and reconcile disagreements through of fake videos (Section 4.4). While describing our findings, we refer peer-debriefing <ref type="bibr" target="#b44">[31]</ref> to ensure that our themes comprehensively to our participants by pseudonyms. represent the data. We also conducted member checks <ref type="bibr" target="#b16">[14]</ref> to ensure that participants' subjective meanings, actions, and social contexts</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Perceptions of and Experiences with Fake</head><p>were authentically represented. Multiple passes through the data Videos resulted in a total of 90 codes (e.g., out-of-context fake videos, fake</p><p>The probes that we shared with our participants helped us explore videos are the most harmful, fake videos incite violence) and four their opinions on fake videos. Most participants did not observe high-level themes (e.g., experiences with fake videos, perceived any audio-visual inconsistencies in the video probes. Only a few of harms of fake videos).</p><p>them noticed some of the videos to be fake, without our probing. Participant Demographics. Table <ref type="table" target="#tab_0">1</ref> lists the participants' demo-Even when we informed the participants that some of the shared graphics. We interviewed 15 urban and 21 rural participants aged videos were fake, they struggled to point out which ones were fake between 18-65 years. The urban participants were from major and which was real. All participants except one failed to correctly cities in Gujarat, Karnataka, Telangana, Maharashtra, and Andhra identify all the videos. About one-third of the participants believed Pradesh. Majority of the urban participants (N=14) had at least a all four videos to be real. Nearly one-fourth of the participants bachelor's degree. They came from a wide range of professions, incorrectly classified the real video as fake. When we sought opinions from Some participants felt that such out-of-context fake videos which our participants about what they consider to be "fake" videos, they are in unfamiliar language or feature unfamiliar people are the most offered us a wide range of perspectives. For many of our participants, difficult to verify. A few participants expressed that fake videos fake videos contained "obviously fake and scripted content. " When with misleading narratives that are inline with one's political or asked for examples of fake videos, they often mentioned videos religious beliefs are also difficult to spot, suggesting that people are of astrological predictions, TikTok memes, pornographic videos, susceptible to fake videos that affirm their political or communal and prank videos, among others. Some rural participants had no biases. This finding is inline with prior studies that report how idea about the existence of fake videos and thought videos could people are likely to consider those news sources as reliable that hardly be tampered with. Most of the new social media users in support their political affiliations and biases <ref type="bibr" target="#b48">[52,</ref><ref type="bibr" target="#b71">71,</ref><ref type="bibr" target="#b72">72]</ref>. our sample often tended to believe almost anything they see online, A few participants added that they would also consider defamahad limited knowledge about fake videos, and believed videos to tory videos as fake. They pointed that monetary gain, blackmailing, be a "window of reality." Some of them felt that they could never revenge, and political and business rivalry might lead to the circureceive fake videos as they are only connected to their "trustworthy lation of such fake videos. Additionally, several rural participants family and friends" on social media, assuming that fake videos are (N=9) reported coming across a pattern of fake videos that misleadshared only by malicious actors and adversaries.</p><p>ingly claimed "If you do X, Y will happen. " Most of these videos had a religious undertone and a few even featured monetary schemes "Apart from my personal contacts, no one knows my trying to financially scam low-literate rural users. Tarun explained: number. Also I am not part of any external WhatsApp group. So, I never receive any fake videos." (Krittika, "I came across this fake video that said, 'this is where the Rural, Female, 40 years) Goddess was born. Share this video with 15 people and you will be blessed. Otherwise, you will be the harbinger Like Krittika, many participants tended to blindly trust content of bad luck. '" (Tarun, Rural, Male, 22 years) shared by their personal contacts. Some participants believed the nature of WhatsApp groups (e.g., family groups, interest-based 4.1.3 Digitally Modified Fake Videos. More than half of our pargroups, public groups, work-related groups) to influence whether ticipants (N=23) defined fake videos as those with "digital modthey can expect to be exposed to fake videos in that group. For exifications." When we asked them how these videos are digitally ample, Smita, a 35-year-old teacher in rural region, believed that she modified, they reported that the audio or faces in videos are often would never see a fake video on WhatsApp and Facebook because replaced and sometimes multiple videos are added together or some she only participates in education-related groups and discussions.</p><p>words/scenes are edited out of the video to propagate a false narrative. They expected these videos to be of poor quality (e.g., having 4.1.2 Misleading and Out-of-Context Fake Videos. About one-fourth blurred or distorted facial features or asynchronous lip movements) of our participants highlighted how they considered fake videos as and easily discernible. those that spread suspicious or unverified information and rumors.</p><p>More than three-fourths of our participants were unaware of For example, Apoorva, one of the urban participants, gave the examdeepfake videos. Only four participants reported having some prior ple of an anti-vaccine video as a fake video in which it was shown knowledge about deepfake videos, out of which two were unaware that "a boy died after taking COVID vaccine." Almost one-third of of the term "deepfake" but could recall encountering some instances the participants perceived videos to be fake when they depicted of deepfakes when we explained the term to them. Two particireal incidents but were presented out-of-context with misleading pants understood deepfakes to be videos produced using a technarrative either to exaggerate an event or provoke people. Ashish nique which helps replace an individual's face or other features shared an example to illustrate this point:</p><p>(e.g., clothes, speech) in a way that the edited video looks similar "A couple of years ago, the JNU student movement to the original. One participant defined deepfake to be "computerstirred the whole country. There was a video where generated" and associated it with "Google's Deep Dream"-a tool that protesting JNU students were chanting, 'we want free-enables creation of artistic visual content through Human-AI coldom. ' This was turned into a propaganda saying 'they laboration. When we prompted the participants to give examples of want freedom from the country', whereas, the students deepfake videos that they might have encountered earlier, Anushka, actually implied they wanted freedom from poverty, un-a 27-year-old urban woman, recounted an Instagram video with employment, and as such. We see these kinds of videos AI-generated human figures that looked so close to real humans almost everyday. " (Ashish, Urban, Male, 27 years) that she struggled to differentiate between real and fake figures. A few participants added that they had heard that deepfake technol-If they are saying something very controversial then ogy is used to create pornographic content, as is widely reported in probably I try to assess if the information is correct or the popular press <ref type="bibr" target="#b25">[19]</ref>. Others struggled to give a concrete example, not. Otherwise, I just watch. " (Aditi, Urban, Female, 34 suggesting that even those who know about deepfakes have limited years) ability to spot them. In contrast, many participants could recall Participants reported that focusing on audio might help them examples of cheapfake videos that they encountered previously.</p><p>detect those instances of fake videos in which a celebrity's voice is For instance, one of the participants shared that his friend showed replaced with a different audio. This reaffirms that for many users him a cheapfake video, where a cartoon with a human face was like Aditi, perceptions of fake videos hardly stretch beyond audio dancing around. Adarsh, a 30-year-old rural man, shared how he manipulation and suspicious information presented in the video, let was able to detect a video to be fake because "speaker's lips were alone considering the possibility of AI-generated deepfakes. A more not synchronizing with the audio. " However, unlike Adarsh, many suitable approach could be to pay attention to both audio and visual rural participants trusted even such obviously inferior cheapfake cues, especially to recognize high-quality deepfakes. A couple of videos, attributing glitches, pixelated frames, and audio mismatch participants commented that watching a real video of the same to poor network connectivity.</p><p>subject would help them recognize corresponding deepfake videos, Taken together, participants had varying perceptions of what where the face has been swapped. This is inline with findings from comprises fake videos, ranging from lack of awareness about the ex-Khodabakhsh et al. <ref type="bibr" target="#b53">[57]</ref> which show that the participants who istence of fake videos to superficial knowledge about sophisticated saw the actual biometric reference video of the person targeted in deepfakes. This suggests that not only users are likely to interact deepfakes were found to be better at spotting the deepfake videos. with fake videos differently, but also they have varying suscepti-A few participants reported that when they doubt a video to bility to fake videos. For example, the participants who considered be suspicious, they go through the comments to see if others also false information presented in video format as fake videos, did not considered the video to be fake. On digging deeper, some particiconsider the possibility that videos could be digitally manipulated, pants mentioned that this strategy often resulted in more confusion, making them more susceptible to digitally modified fake videos.</p><p>particularly when comments call out the same video as both fake and credible, making it hard to decide what to believe. In such cases, 4.1.4 Identifying Fake Videos. After hearing participants' percepthe participants relied on the credibility of the source from where tions of fake videos, our interviewers explained deepfake videos to the video came to assess information credibility. Even though the them. After learning about these technologies, some participants majority (86%) of the urban participants were using smartphones (20%) felt that they lacked the skills, capabilities, and experience for many years, only one-fourth of them were proactive about spotto detect sophisticated fake videos. They all pointed that due to ting fake videos and seeking correct information, indicating that advancing technologies they would hardly be able to detect any longer experience with technology does not necessarily translate subtle cues from such "well-made" fake videos. Besides, some parinto healthy information behaviors. On the contrary, none of the ticipants mentioned that most of the time they consume videos rural participants relied on online resources to assess the credibility "passively rather than engaging with them actively" in the sense of videos they found suspicious. They felt that they lacked digital that they pay more attention to whether the content matches their skills that could be helpful to spot fake videos. worldview instead of considering whether the video itself is manipulated, used out-of-context, or contains misinformation. They reported that when they have some expertise or prior knowledge</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Interaction with Fake Videos</head><p>about the topic depicted in fake videos then they might be able to Following participants' varying perceptions of fake videos, we spot them better. queried how they tended to respond when they suspected a video When we asked participants to share their thought process on to be fake. Our participants described various actions they took on how they assess the credibility of a video, about one-third of them resuch occasions. ported never using any technological tools or fact-checking sites. In-Most of the participants reported that stead, they relied on their intuition. In fact, most of our participants 4.2.1 Ignoring Fake Videos. they simply ignore the videos they doubt as fake, particularly when knew nothing about fact-checking, including how fact-checkers the videos are in an unknown language, forwarded multiple times verify information and where to find such resources. Although on WhatsApp, sent by a person who routinely shares fake videos, or one-fourth of our participants mentioned that they carefully look when the topics do not align with their interests. Some commented for visual cues and re-watch the videos multiple times when they that they don't care much about fake videos on social media and find something suspicious, many others mentioned that they do hardly pay any attention while watching them. Ashish further not pay attention to visual cues and are not actively thinking about unpacked this indifference: "spotting fake signs." This is in contrast with observations from a prior research study <ref type="bibr" target="#b81">[99]</ref>, where people mentioned relying on visual "When I come across a fake video, my reaction is it's cues to spot fake videos. The participants in our study reported just another source of wrong information. So, I prefer that they focus more on the voice, audio content, and context of the to do nothing about it because I have never been very information rather than relying solely on the visual inconsistencies.</p><p>active in these matters and what's the point anyways. " Aditi explained how she often ignore visual cues:</p><p>(Ashish, Urban, Male, 27 years)</p><p>"Most of the time I don't really pay attention to visual Some participants felt that there are a lot of fake videos online clues. I just hear what the person is saying in the video.</p><p>and given the abundance of such videos, they considered it best to not waste any time on them "because people keep sharing such often sent them fake videos and so, they asked these friends stuff. " Aditi elaborated:</p><p>to share videos only after vetting the content. They added that they prefer to engage in these discussions as there are chances "Even if I do come across fake videos, I don't really might be sharing fake videos without being aware of them. spend my time looking at it, thinking about it, or even Although these online and offline discussions have the potential wondering why people do that. It's just a waste of my to inform people, many participants reported how they were less time. And I think most of the people also know it's fake.</p><p>inclined to do so out of the fear of hurting other's feelings and to I just ignore it. " (Aditi, Urban, Female, 34 years) avoid any backlash. Participants like Aditi did not take any action even after doubting videos to be fake simply because they assumed other people would Reporting Fake Videos. When we probed our participants know the videos were fake or thought that propagation of fake whether they tended to report fake videos, we received mixed videos could not be prevented. Such passive attitudes could lead to responses. More than half of our participants were reluctant to the tragedy of the commons and result in an increased consumption report fake videos and offered various reasons for their unwillingof fake videos often with undesirable consequences.</p><p>ness. A majority of them considered reporting to be as of them had prior experience where reported videos were not 4.2.2 Deleting and Blocking. A few participants (particularly Whatfrom the platform, and no actions were taken against the users) deleted the videos they perceived to be fake. The particusers who shared the fake videos. This is inline with findings from ipants offered different for why they opted to delete videos prior studies that discuss how people didn't receive the expected perceived as fake. Some of them only wanted to keep useful outcome after reporting abusive content and thus concluded that videos on their devices, a few worried about accidentally sharing doesn't work <ref type="bibr">[76,</ref><ref type="bibr">105]</ref>. A couple of participants felt that such videos with others, and some who shared their devices with social media platforms take many days to take action on flagged family members were concerned that their family members might videos and since these videos spread "so fast that reporting them exposed to such videos. In line with the scholarship on shared have zero practical impact. " A few expressed their frustration, saying phone use in the Global South <ref type="bibr" target="#b1">[4,</ref><ref type="bibr" target="#b80">106]</ref>, these findings offer how that on social media people can choose to share whatever they like shared devices among family members could lead to inadvertent if it is fake and hence, they preferred to not take the trouble sharing of fake videos. Srikant described: to report anything. In addition, some participants were unaware "My kids often use my phones. So I delete anything unhow to go about reporting a video and what would follow if necessary. Because if the kid ends up sharing something they tried to do something. A few participants avoided reporting in my absence and I find it later when others comment because they were unsure about what kinds of explanations and or react, that would be embarrassing. People might wonevidence they would be asked to provide: der why I shared such thing. That's why I don't keep somebody reports a video, I'm not sure what happens videos on my phone. " (Srikant, Rural, Male, 40 years)</p><p>How is it dealt with? I think there should be more A few participants reported that they blocked personal contacts transparency around that, for example, if I reported a on WhatsApp who routinely shared fake videos with them. One they need to tell me how they would follow up participant left a local WhatsApp group where fake videos with me on what happened and what action they will routinely circulated. This shows that when it comes to dealing take. " Rural, Male, 30 years) with fake videos, many people simply opt to get rid of it on their a few participants admitted reporting videos they perceived end. Though these measures protect the individuals from being to be fake. Often such videos contained polarizing content, harassto fake videos, they do not necessarily stop fake videos ment, pornography, and vulgar language. A handful of participants spreading. also shared that they reported social media accounts and YouTube 4.2.3 Leaving Comments and Discussion. Even though many par-channels that they knew were spreading fake videos containing ticipants mentioned that they do their best to not engage with fake communal or political propaganda. The participants stressed the videos, a few participants felt that it was their "moral and civil necessity to adopt a community-based approach to pointing out duty" to do more. They reported leaving comments on videos they potential fake videos so that the platforms could block such videos perceive as fake to make others aware of it. Aditi described:</p><p>and take actions against the offenders. They expected immediate removal or censoring of reported content as well as sanc-"If I encounter a fake video, I would leave a comment tions on users and accounts spreading fake videos, ranging from saying that it was not authentic, how other people temporarily banning them to suspending them indefinitely. But were indiscriminately forwarding it, and just share my such expectations were rarely met. This shows that even though thoughts about it. " Urban, Female, 34 years) social media platforms provide the option to report potentially fake A couple of participants found it helpful to discuss videos they content, this feature is often underutilized owing to lack of proper find suspicious with family and friends. Three women mentioned knowledge about its underlying and what ensues after that they often show suspicious videos to their husbands or brothreporting. ers who have more "digital and worldly experience" to get their This shows that male family members played a key 4.2.5 Sharing Fake Videos. We found that participants were split role in forming and shaping female family members' opinions of in their attitudes toward sharing videos they found to be suspifake videos. A few participants mentioned they had some friends, cious. Many participants were comfortable sharing fake videos, for example, cheapfakes created for entertainment. This in-videos turn people against each other and thus hinder societal cluded funny cheapfakes of politicians and actors or user-generated progress. Vikram described the harms of fake videos: cheapfakes using popular applications like Adobe After Effects <ref type="bibr">[1]</ref> usually have strong opinions on caste, religion, WOMBO <ref type="bibr">[109]</ref>. participants expressed that they fine nationalism, and communal issues. Whenever they watch sharing fake videos when the broader message in the video aligns some fake videos on the Internet spreading wrong inwith their beliefs and perspectives, highlighting how that was a formation on these sensitive topics, it might hurt their sufficient reason for sharing. This is consistent with the findings sentiment and provoke them to hate, bash, and even from prior studies conducted both within the Global South <ref type="bibr">[100]</ref> cause physical harm to other groups of people having and the Global North [69] which report that people are willing to different opinions. " (Vikram, Urban, Male, 22 years) share fake news that aligns with their preexisting beliefs. Smita Participants like Vikram felt that political parties reap the greatdescribed:</p><p>benefit by creating fake videos and do so to increase their fol-"If my worldview matches with a video, I will definitely lower base, defame the opposition, and advance their propaganda. it even if it's fake. Whatever they are saying, Around one-fourth of the participants mentioned that sharing fake whatever views they hold doesn't matter. If I like it, often lead to "misinformation cascades" as people keep forthen I will share it. " (Smita, Rural, Female, 35 years) warding these videos without much thought, often resulting in These participants were oblivious of the harm that might arise panic and mistrust within the society. Aditi elaborated: sharing fake videos and some harbored beliefs that videos "People can be easily misled and manipulated by fake could do no harm. On the other hand, some participants claimed as they do not know how to spot them. It's danthat they would not share fake videos with others even if the videos gerous for people to simply forward fake videos without support their communal and political beliefs. They felt that sharing much inspection and soon it results into a chain of misinfake videos could not only harm other people but also ruin their formation -as one person forwards the video to another social image. They emphasized that just because they believe in and it goes on and on. " Urban, Female, 34 years) something that "doesn't necessarily mean other people should follow 4.3.2 Harms to Individuals. A few people who knew about deep-" fakes considered them to be a huge blow to individual's privacy. Taken together, these findings show that users not only engage Anushka, a 27-year-old woman living in a city, felt that her identity, with videos they doubt as fake differently but also their perceptions face, and persona could be easily stolen to show her speaking and the potential harms of fake videos vary, which we explore next doing things she never did. She felt that this kind of more detail.</p><p>identity theft without one's consent could be misused to spread misinformation and to sway the opinions of targeted groups. Several female par-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Harms of Propagating Fake Videos</head><p>ticipants like Anushka were also concerned with how fake videos Many participants (N=16) considered videos to be the most harmoften used to harass women. They described incidents where ful among all modalities through which misinformation and fake women's images were used to create fake pornographic videos and spread. They believed that the effect of visual experiences the resultant trauma and mental harassment the women had to go lasts longer than that of reading textual information which also Purva described how she learnt about deepfake pornodemands more cognitive load. Some participants pointed that many graphic videos: low-literate social media users who are new to online information "I saw a news on how a woman committed suicide afenvironments consume videos heavily and prefer to engage with ter a video showing her intimate moments went viral. audio-visual content more than textual content. They felt that these Later, it was revealed that the video was fake. Someone users are the most susceptible to the risks and harms of fake videos put woman's face to another woman's body in a pornosince they might lack the skills to assess the credibility of videos.</p><p>graphic content. The woman felt so humiliated that she Societal Harm. When we probed our participants about their ended her life. " (Purva, Urban, Female, 45 years) thoughts on how fake videos could cause harm, about one-third of A few participants mentioned how some people inadvertently them felt that fake videos lead to violence, communal tension, and hurt themselves while trying to imitate actions from computer-They also emphasized how fake videos are weaponized to generated movie scenes. Abdul, a 19-year-old rural resident, repolitical vendetta and seed religious hatred. Ridhima shared:</p><p>one such example where a boy in his neighborhood tried to replicate a stunt from an action movie and badly injured himself. "There are many fake videos on sensitive topics. These few participants also noted how fake videos caused health-related are dangerous and lead to protests and riots. Many peoharms to them and their family members when they followed false ple do not have any clear understanding of the things health advice during the COVID-19 pandemic. They also gave exon the ground. They believe these fake videos, assume of how anti-vaccine fake videos provoked many people to that they can't be tampered, and share them widely.</p><p>decline the vaccine for coronavirus. of these further exacerbate the situation. " Urban, Female, 32 years) 4.3.3 No harm. Most of the participants who were new to social Some participants labelled fake videos to be a "danger to democ-media and some rural residents struggled to articulate the harms of felt that they undermine freedom of speech, violate hu-fake videos. Some of them felt that fake videos are harmless. These man rights, and set the ground for communal hatred. They felt that participants had different mental models than experienced users and believed only staged videos to be fake. They explained how sharand this might lead to some changes. " (Pratiksha, Rural, ing funny cheapfakes, memes, and advertisements could entertain Female, 41 years) other people and bring monetary gains to content creators. Given Several participants acknowledged the importance of embedding the appetite for entertaining cheapfake two participants felt these interventions and educational programs in the socio-cultural that new businesses could benefit financially by launching comfabric of the society. Describing Indian society as strongly patriarmercial applications for creating entertaining and funny cheapfake chal, Sanjay suggested that the heads of the households in rural videos, without reflecting much on how such applications could be areas could be trained so that they can inform their family memrepurposed for nefarious means. Abdul commented: bers about safe information behaviors. Participants also noted that "These prank and funny fake videos are all means to the educational programs should respect different cultural, reliearn money. Because if subscribers increase, then likes gious, and regional sensitivities while providing examples of fake and comments will increase. And you will get more videos and discussing their harms. They highlighted the need to " (Abdul, Rural, Male, 19 years) have recurring training sessions and the importance of long-term engagement with such training programs: Overall, these findings suggest that many participants, with an exception of new users in rural regions, were aware of the risks "It is not the case that if you teach me today, tomorrow and harms of fake videos and how these videos can be misused to will receive a fake video and immediately identify it. I create a polarized and divisive society. don't think this can happen in one go, but only by repeating it multiple times people might retain the knowledge</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Mitigating the Spread of Fake Videos</head><p>and understand the implications better. " (Pratiksha, Rural, Female, 41 years) As many participants pointed out the potential harms of fake videos, listed several measures that could be adopted by individuals, 4.4.2 Role of Social Media Platforms. Our participants offered sevgovernments, and social media platforms to counteract the spread eral suggestions that social media platforms can take to curb the fake videos.</p><p>of fake videos. However, not many understood the underpinof social media and lacked awareness of the existing features 4.4.1 Raising Awareness. A majority of the participants suggested curb the spread of fake videos. For example, a couple of particiraising awareness as a first step to mitigate the spread of fake videos.</p><p>pants suggested that the platforms should use community feedback Many of them emphasized the need of "collective teaching" to edlabel fake videos. Some of them did know about the reporting ucate the public on the harms of fake videos and ways to assess feature, but suggested to make those more visible like the and credibility. They recommended using social media, newspapers, comment button." Some participants recommended the platforms TV programs, paper pamphlets, and video demonstrations to raise prevent the upload of potential fake videos by detecting them in awareness. They emphasized the need to create infographics-based real time, not knowing the technical challenges that it presents as training materials that are easy to grasp than long, text-heavy eduwell as associated difficulties in labeling videos that have partly true cational articles. A few participants also suggested creating educaand partly misleading information. A few participants proposed tional videos that explain to users various techniques to spot digital labeling of fake videos by forcing users to answer manipulations. They also advised to engage non-governmental ora few questions about the authenticity of the video which they ganizations, social workers, teachers, bureaucrats, and celebrities attempt to share. to promote awareness. Vikram commented:</p><p>A handful of participants demanded that once verified, the platmust instantly remove all instances of fake videos in order to "If social media influencers post a two-minute video prevent users from watching and sharing them. A few participants on how to spot fake videos, it would instantly spread (Vikram, added that fake videos thrive on the reactions they receive online. like wildfire among their large follower base. " Urban, Male, 22 years) Thus, they proposed to disable reactions, comments, and sharing of videos that are flagged by users or platforms. They also suggested the threats to civil liberties and democratic institutions, the platforms must notify all users who may have been exposed some participants strongly suggested to start discussing the harms a fake video and remind those to not share fake videos who have of fake videos in schools and colleges to build "information-aware, done so in the past. digitally-skilled" future generations. They emphasized the imporknowing how the platforms operate under the hood, a few tance of extending digital literacy programs to older adults, who participants demanded the platforms to be more transparent about often have limited technology know-how and are usually more how they deal with reported videos. Along with the number of susceptible to fake videos. A few participants drew attention to comments and reactions to the video, they suggested to display the the existing digital divide between urban and rural residents and of times a video is reported to increase transparency. A advocated for creating programs specifically for social media users of participants believed that fake videos are often shared by in rural regions. Pratiksha elaborated: unverified accounts with small follower base which social media "Urban residents are usually more aware. But in the platforms should cut loose. This suggests that users thought videos villages if meetings are arranged, people are brought verified accounts with large follower base are not likely to together, and shown videos on what fake videos are, fake. Even in several prior studies it was observed that sender's they look like, and what to do when one receives and follower-base largely influence how people perceive fake videos, then they might inform others around them credibility of online news <ref type="bibr">[23,</ref><ref type="bibr" target="#b20">38,</ref><ref type="bibr">96]</ref> 4.4.3 Role of the Government and the Public. Many "Whatever people say against the government, it is their held the accountable for the propagation of fake right. But when political parties come to power, they videos and believed that could play a greater role in controlling try to censor things according to their own interests. Be the spread. They suggested to create regulatory bodies and develop it any government or any party, the power to control top-down policies to penalize those who spread fake videos. Some people's freedom expression should not be in their of them felt that media platforms are public spaces and should hands. I personally think the government should not be come under the scrutiny of government regulatory bodies. A few responsible for preventing fake videos. " (Deepak, Urban, urban participants cited how Twitter had to comply to new Internet Male, years) regulations in India and agreed to remove or censor content based on the country's new IT law <ref type="bibr">[49]</ref>. A few suggested to enforce strict Taken together, our participants had mixed feelings on to what laws against publishing fake videos, punishing the offenders (e.g., extent the propagation of fake videos could be controlled and what imprisonment, confiscating property), and banning applications the appropriate ways approach that. However, they agreed that allow the creation of such content. They also advised to enlist it should not be a single endeavor from a particular group. cybercrime divisions to trace the sources that spread fake videos.</p><p>Rather, individuals, local and national governments, and social Some participants expressed that everyone should be proactive media platforms should work together to deal with the menace of about dealing with fake videos. They advised actionable measures videos. that individuals can take when they doubt something as fake, such as reporting potentially fake content, commenting on fake videos to inform the public, talking to friends and family about fake videos,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>DISCUSSION</head><p>and educating people about the necessity of consuming information Our work qualitatively examines how diverse social media users from reliable sources. They also called for action to scrutinize one's in India perceive and engage with fake videos. The increased disown activity on social media and carefully think before sharing semination of misinformation via fake videos in the Global South, on social media.</p><p>in India, makes our work a timely and relevant study. Through a qualitative study of 36 social media users in rural and 4.4.4 A Feeling of Despair: Nothing will Stop Fake Videos. Despite India, we explored diverse ways in which people perceive all the enthusiasm and suggestions regarding what can be done to videos, including deepfake and cheapfake videos. We observed the propagation of fake videos, some participants believed people's susceptibility to fake videos is usually shaped by their there is no way to curb the spread of fake videos. Several varying perceptions of such content. Notably, we found that many participants critically reflected on the merits and limitations of these participants did not have a deep understanding of the technological measures. They expressed that creating awareness or developing advancements and prevalence of fake videos, believing that such about fake videos will not necessarily stop people from videos would be easier to detect due to obvious audio-visual inconcreating, consuming, or sharing fake videos. They described how sistencies or they would not come across any fake video simply due to advancing technologies and accessible tools, high quality because they interact only with their friends and family online. fake videos could be generated so easily that training alone might</p><p>We further unpacked how people interact with fake videos and not help people. They also thought that social media platforms could observed several alarming practices, such as passive consumption very little to detect fake videos due to the massive scale of videos and sharing of fake videos that align with one's beliefs, and a genare uploaded every day. Besides, they believed controlling the eral indifference towards reporting fake videos. We examined their spread of fake videos might not directly align with the corporate perceived threat models around fake videos and found that peointerests of social media platforms. Anand explained: ple generally considered videos to be more harmful than other modalities of misinformation (i.e., text, image). They also labelled "The people who built social media applications care videos as a great threat to both the individuals and the somore about drawing users to their platform to generciety. Finally, we probed participants' views on how to curb the ate more revenues rather than stopping fake videos."</p><p>of fake videos and the roles they expect individuals, society, (Anand, Rural, Male, 21 years) governments, and social media platforms to play. The participants also expressed similar worries about govern-Overall, our findings suggest that most social media users are initiatives to prevent fake videos and felt that the governments to deal with fake videos, have varying perceptions lack the infrastructure, knowledge, and policies to counteract the of what qualifies as fake, and engage with such videos differently, onslaught of fake videos, especially deepfakes. They highlighted suggesting that there is no one-size-fits-all approach to combat the how the implementation of some of these measures could result in spread of fake videos. Based on our findings, we now discuss design surveillance and restrictions on the freedom of speech. A recommendations for social media platforms to mitigate the risks participants also believed that the governments lack the will to and harms of fake videos. adopt these measures, because as political parties, they themselves Building. Many participants suggested using short-form have "created and spread fake videos to serve their political agendas. "</p><p>videos and infographics to educate users about what fake videos are They also felt that mainstream news channels are working hand in how to spot them. They recommended these formats to maxiwith the governments to polarize the public. Deepak noted mize user engagement with training resources. The participants' these measures can give the governments power to erode the observations are in line with research findings that show how videos foundations of democracy: drive more engagement than text-based content <ref type="bibr" target="#b42">[28,</ref><ref type="bibr">67]</ref>. Scholars have also used similar strategies in the past, for example, to edu-uncertainty along with predicted labels might help address this cate people about privacy risks via videos [95] that have resulted in issue. However, since videos can be consumed easily without rehigher adoption of security features <ref type="bibr" target="#b3">[6]</ref>. Recently, Facebook quiring any added digital or literacy skills, novel approaches are designed an infographic in consultation with its fact-checking part-needed to visually convey such information. One approach could ners to educate its users on fake news <ref type="bibr">[48]</ref>. However, more work is be use colored backgrounds for displaying different types of fake needed to bring forth the training and educational For ex-videos fabricated, edited, missing context) <ref type="bibr" target="#b66">[88]</ref> or to signify ample, since many social media platforms exhibit advertisements to the confidence level when predicting fake videos. This could be parusers, similar to sponsored content, short-form training videos and ticularly useful for low-literate users who might otherwise face difinfographics could be intermixed in users' news feed. Since many ficulties in understanding prediction accuracy. Work from Bhuiyan participants made a point of educating people routinely, repeated et al. <ref type="bibr" target="#b15">[13]</ref> shows that use of such colored backgrounds for tweets exposure to such short-form videos in one's newsfeed be from reliable, questionable, and unreliable sources improved users' helpful for users to be reminded of healthy information practices.</p><p>recognition of content from questionable sources. A routine exposure might lead to behavioral change eventually</p><p>Online Training for Crowd-based Credibility Ratings. An apas is shown in prior studies in which regular exposure to social proach to address the various issues of AI-based fact-checking and media-based health education was deemed effective in improving detection of digitally manipulated videos is to leverage human asusers' health-related behaviors <ref type="bibr" target="#b58">[60,</ref><ref type="bibr" target="#b63">65,</ref><ref type="bibr">83]</ref>. However, more work sistance for designing crowdsourced credibility indicators as they is needed to design training materials that appeal to a wide array shown to be as effective as professional fact-checkers [78]. Our of users with different skills, cultures, literacy levels, backgrounds, participants also suggested asking social media users about the and prior beliefs.</p><p>of videos while they are watching them. However, our Explainable-AI based Credibility Indicators. Apart from train-findings show that many social media users struggle to spot fake ing people to spot fake videos, our participants suggested that videos, so a crowdsourced approach would be ineffective withmedia platforms should proactively detect and label fake out proper capacity building. One way to handle this is to offer videos. Given the large volumes of data that the platforms amass, voluntary online training to social media users for recognizing a few participants recommended that the platforms could use AI videos. Prior studies have experimented with a range of techadvances to identify instances of fake videos that are running ram-niques to build users' capacity to spot digitally manipulated fake pant and use credibility indicators to label videos that are either videos. This includes displaying actual biometric reference videos digitally manipulated or contain misleading information. Recent along with fake ones <ref type="bibr" target="#b51">[56]</ref>, introducing different deepfake generation advances in GAN-and CNN-based technologies have made it pos-</p><p>techniques with examples and pointers to generated artifacts <ref type="bibr" target="#b51">[56]</ref>, to detect deepfakes using various measures, such as visual highlighting inconsistent areas in fake videos with explanatory heartbeat rhythms <ref type="bibr" target="#b61">[85]</ref>, affective cues from perceived audio-visual <ref type="bibr" target="#b81">[99]</ref>, and offering mock tests with or without feedback [66], emotions <ref type="bibr" target="#b74">[74]</ref>, and audio-visual dissonance <ref type="bibr" target="#b43">[29]</ref>. Scholars have among others. Platforms could use these tactics to train social mealso used linguistic, acoustic, and user engagement features for dia users to effectively spot and report a wide array of deepfake detection of misinformation in YouTube videos <ref type="bibr" target="#b36">[46]</ref>. videos. In addition, to not overburden the users with identifying the prior work shows that AI-based credibility indicator is fake videos themselves, the platforms could also utilize linguistic least effective in reducing people's trust in fake news <ref type="bibr" target="#b86">[112]</ref>.</p><p>cues from user comments to assess the veracity of the content [54] To alleviate users' distrust from AI-based predictions of fake label the videos accordingly. Moreover, due to prevalent socionews, one approach could be to design explainable AI-based credi-cultural norms, participants' perceptions of what comprises "fake" bility indicators, which have been shown to be useful in helping videos may differ from what qualifies as fake videos according to share more credible news and report more fake news [75].</p><p>platform's policy. To accommodate socially and culturally diverse However, more work is needed to make AI-based credibility indica-viewpoints, platforms should recruit a diverse pool of fact-checkers explainable to low-literate, digitally novice social media users, and partner with local news agencies to evolve the understanding many of who access information in languages other than English.</p><p>of fake videos. A recent Google report shows that nearly 70% of Indians access Reflective Sharing. Our participants suggested that platforms content in their local languages <ref type="bibr" target="#b13">[12]</ref>. To make AI's explashould disable reactions, comments, and sharing options on factnations more acceptable and understandable to these users, not fake videos since many people use them as a proxy to only the credibility indicators and underlying AI algorithms should judge the content's credibility <ref type="bibr" target="#b19">[15,</ref><ref type="bibr" target="#b18">36]</ref>. Since fact-checking videos be compatible with local language content, but they also need to takes time, our participants also recommended to place sharing accessibly convey the information about features that guided its restrictions on all videos to minimize the risks and harms of fake decision to users who might have limited to no digital literacy and videos. While these measures might seem draconian and imprac-English-language skills. tical, WhatsApp did adopt similar measures to curb the spread current AI-based fake news detection systems have of COVID-related misinformation <ref type="bibr">[84]</ref>. Although such measures high false negative as the underlying algorithms are often inept reduce the spread of misinformation, it might also hurt the in capturing socio-cultural nuances present in the content and users' spread of authentic news, helpful advice, or harmless memes. In-[107]. In addition, a recent study from Saltz et al. <ref type="bibr" target="#b66">[88]</ref> stead, the platforms could nudge the users when they try sharing that false positives in case of auto-labeling visual misinformaa video and ask them whether they think the video is real or fake tion further erode users' trust in credibility indicators. Reporting why. Such lightweight interventions while sharing have been found to be effective in reducing the propagation of fake <ref type="bibr" target="#b46">[51]</ref>. take disciplinary action on them (e.g., temporarily or permanently querying the users about the authenticity of videos and suspending them, or reducing their privileges temporarily). More their reasons behind might discourage them from sharing is needed to design, implement, and evaluate new sets of videos that they find suspicious. In addition, when users try to share features that enable group admins of private and public WhatsApp videos, the platforms could open a pop-up that reminds them to groups to contain the spread of fake videos. Taken together, these be conscientious and thoughtful of their online activities and to recommendations could enable social media platforms to be more hurt other's sentiment by sharing communally or politically pragmatic in curbing the spread of fake videos and creating an videos. This might help reduce the sharing of fake videos environment conducive to civil discourse. as many research studies show that such reminders could motivate users to change their behaviors [27, 82].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>and Transparent Reporting Feature. Our participants interviews with 36 diverse social media users from rural reported videos. Many participants were confused about and urban India, we examined how they perceive and interact with how reporting worked, pointing to the lack of transparency in videos, how they evaluate the risks and harms of fake videos, the underlying workflows and processes. To make this feature what they consider necessary to curb its spread. We found that more usable and useful, platforms should clearly communicate how the users had varying perceptions of what they consider as fake process the reported posts and follow-up with what actions videos. Most of them passively consumed videos and lacked the willhave taken (or lack thereof) on the flagged videos. Merely ingness and skills to spot fake videos. Several users were unaware mentioning that no action was taken because the content did not videos can be doctored or edited, and most knew nothing about violate the platform's policy might not be helpful to most users deepfakes. A few participants, who were aware of digital manipulawho seldom read or could comprehend the platform's policy. Hence, of videos, expected these videos to be easily discernible. Even the platforms should be careful in accessibly communicating their participants knew a video to be fake, they rarely reported responses with proper rationale to ensure that those flagging videos it and sometimes willingly shared it for entertainment or when it do not feel disgruntled as did some of our participants. To encourage supported their worldviews. Many participants described how fake users to report videos they perceive to be fake, platforms may are polarizing and divisive and expressed diverse opinions find it valuable to turn to social influence. Prior work shows that in how individuals, social media platforms, and governments could simply showing people how many of their friends used security contend with the harms of fake videos. Based on our findings, we features is effective in making them adopt those measures <ref type="bibr" target="#b47">[32,</ref><ref type="bibr" target="#b12">33]</ref>.</p><p>discussed the potential of short-form training videos, transparent addition to displaying how many times a video is reported, as our processes, Human-AI credibility indicators, and reflective participants suggested, the platforms could also mention how many sharing in containing the spread of fake videos. of their friends reported a particular video, which might motivate people to report more videos.</p><p>Although almost all platforms enable users to report privately messages between two users, our participants expressed </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Demographics of the participants.</figDesc><table><row><cell>Demographics</cell><cell>Urban</cell><cell>Rural</cell></row><row><cell>Gender</cell><cell>Female: 7, Male: 8</cell><cell>Female: 11, Male: 10</cell></row><row><cell>Age (years)</cell><cell cols="2">Min: 19, Max: 65, Avg: 35, SD: 14 Min: 18, Max: 45, Avg: 28, SD: 9</cell></row><row><cell>Education level</cell><cell cols="2">Middle school: 1, Bachelors: 9, Middle school:1, High school: 3,</cell></row><row><cell></cell><cell>Masters: 5</cell><cell>Bachelors: 12, Masters: 2</cell></row><row><cell>Smartphone use</cell><cell>1 yr: 2, &gt;5 yr: 13</cell><cell>1 yr: 3, 2-4yr: 8, &gt;5yr: 4</cell></row><row><cell>4.1.1 Perceptions of Fakeness.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>2021. Adobe After Effects. Retrieved 2021-09-08 from https://www. hesitation in reporting possibly fake videos that were shared with adobe.com/products/aftereffects.html Shruti Agarwal, Tarek El-Gaaly, Hany Farid, and Ser-Nam Lim. 2020. Detecting them privately, thinking that the sender might get to know who re-Deep-Fake Videos from Appearance and Behavior. CoRR abs/2004.14491 (2020),</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">"It Matches My Worldview": Examining Perceptions and Attitudes Around Fake Videos CHI '22, April 29-May 5, 2022, Orleans, LA, USA</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Navigating the maze: Deepfakes, cognitive ability, and the platforms keep the reporters&apos; identity and other metadata confisocial media news skepticism</title>
	</analytic>
	<monogr>
		<title level="j">New Media &amp; Society</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
	<note>Saifuddin Ahmed. 2021.</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Who inadvertently shares deepfakes? Analyzing the should offer clear information on how the reporting of privately of political interest, cognitive ability, and social network size</title>
		<author>
			<persName><forename type="first">Saifuddin</forename><surname>Ahmed</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tele.2020.101508</idno>
		<ptr target="https://doi.org/10.1016/j.tele.2020.101508" />
	</analytic>
	<monogr>
		<title level="j">Telematics</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page">101508</biblScope>
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>shared content is handled. In addition, some users confessed they Informatics</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Misinformation as a Window into Prejudice: COVID-19 (e.g., Facebook, Instagram, and Twitter) hide the reporting and the Information Environment in India</title>
		<author>
			<persName><forename type="first">Anmol</forename><surname>Syeda Zainab Akbar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Divyanshu</forename><surname>Panda</surname></persName>
		</author>
		<author>
			<persName><surname>Kukreti</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Interaction</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="1" to="28" />
			<date type="published" when="2021">2021. 2021</date>
		</imprint>
	</monogr>
	<note>Azhagu Meena, and did not know how to flag content. This might be because most plat-Joyojeet Pal</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">A novice social media users to locate this option. Hence, the platforms Study on Designing Video Tutorials for Promoting Security Features: A Case Study in the Context of Two-Factor Authentication (2FA)</title>
		<author>
			<persName><forename type="first">Yusuf</forename><surname>Albayram</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Maifi Hasan Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Fagan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">should consider making this feature more visible and making the</title>
	</analytic>
	<monogr>
		<title level="j">International Journal of Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="927" to="942" />
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Misinformation Dissemination on the Web</title>
		<author>
			<persName><forename type="first">Jussara</forename><surname>Almeida</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Our participants were alarmed by the rampant sharing of fake Proceedings of The 2019 World Wide Web Conference</title>
				<meeting><address><addrLine>Francisco, USA; New York, NY, USA, 740</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>WWW &apos;19). for Computing Machinery. videos on WhatsApp, attributing the absence of fact-checking fea</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A Closer Look at the Selfthe posts on WhatsApp, but also the dynamics vary between Correcting Crowd: Examining Corrections in Online Rumors</title>
		<author>
			<persName><forename type="first">Ahmer</forename><surname>Arif</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><forename type="middle">A</forename><surname>Stanek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elodie</forename><forename type="middle">S</forename><surname>Fichet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of 2017 ACM Conference on Computer Supported Cooperative Work and Social and privately shared information and such nuances should</title>
				<meeting>2017 ACM Conference on Computer Supported Cooperative Work and Social and privately shared information and such nuances should<address><addrLine>Portland, Oregon, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>CSCW</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="155" to="168" />
		</imprint>
	</monogr>
	<note>&apos;17). Association for Computing taken into consideration while designing interventions. Some Machinery</note>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Nihal Passanha, and Mukti of our participants shared how they were forced to leave What</title>
		<author>
			<persName><forename type="first">Shakuntala</forename><surname>Banaji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramnath</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anushi</forename><surname>Agarwal</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">WhatsApp vigilantes: An exploration of citizen reception sApp groups to avoid receiving fake videos. The platform may and circulation of WhatsApp misinformation linked to mob violence in India. , offer users the option to hide messages from specific group mem-62 pages</title>
		<author>
			<persName><forename type="first">Sadhana</forename><surname>Pravin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">bers and report them to the group admins who can then decide to Seeing Is Believing: An Introduction to Visual Communication</title>
		<author>
			<persName><forename type="first">Arthur Asa</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989">1989</date>
			<publisher>Mayfield Publishing Company</publisher>
			<pubPlace>1240 Villa Street, Mountain View, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">CCS &apos;14). Association nostopoulos, Antonio Scala, Guido Caldarelli, and Walter Quattrociocchi</title>
		<author>
			<persName><forename type="first">Alessandro</forename><surname>Bessi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabio</forename><surname>Petroni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michela</forename><forename type="middle">Del</forename><surname>Vicario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fabiana</forename><surname>Zollo</surname></persName>
		</author>
		<idno type="DOI">10.1145/2660267.2660271</idno>
		<ptr target="https://doi.org/10" />
	</analytic>
	<monogr>
		<title level="m">Aris Anagand Communications Security</title>
				<meeting><address><addrLine>Scottsdale, Arizona, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1145">2015. 1145/2660267.2660271</date>
			<biblScope unit="page" from="739" to="749" />
		</imprint>
	</monogr>
	<note>Proceedings</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m">of the 24th International Conference on World Wide Web</title>
				<meeting><address><addrLine>Florence, Italy</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Role of Social Influence in Security Feature Adoption</title>
		<author>
			<persName><forename type="first">Sauvik</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">A</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">I</forename><surname>Dabbish</surname></persName>
		</author>
		<author>
			<persName><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings the 18th 355-356. ACM Conference on Computer Supported Work &amp; Social Computing</title>
				<meeting>the 18th 355-356. ACM Conference on Computer Supported Work &amp; Social Computing<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2015">2015</date>
		</imprint>
	</monogr>
	<note>The &apos;15 Companion)</note>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Association for Computing Machinery, in content that&apos;s not in English</title>
		<author>
			<persName><forename type="first">Ananya</forename><surname>Bhattacharya</surname></persName>
		</author>
		<idno type="DOI">10.1145/2675133.2675225</idno>
		<ptr target="https://doi.org/10.1145/2675133.2675225" />
		<imprint>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="1416" to="1426" />
			<pubPlace>Vancouver, BC, Canada; New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>India&apos;s internet users have faith. Retrieved 2021-09-07 from</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Anticipating and addressing content-thats-not-in-english-study-says/ the ethical implications of deepfakes in the context elections</title>
		<author>
			<persName><forename type="first">Nicholas</forename><surname>Diakopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deborah</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New Media &amp;</title>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">NudgeCred: Supporting News Credibility Assessment on Social Media [35] Dobber, Nadia Metoui, Damian Trilling, Natali Helberger, and Claes de Through Nudges</title>
		<author>
			<persName><forename type="first">Md</forename><surname>Bhuiyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Horning</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sang</forename><forename type="middle">Won</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanushree</forename><surname>Mitra</surname></persName>
		</author>
		<idno type="DOI">10.1177/1940161220944364</idno>
		<ptr target="https://doi" />
	</analytic>
	<monogr>
		<title level="j">The International Journal of Press/Politics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="69" to="91" />
			<date type="published" when="2021-10">2021. oct 2021. 2021</date>
		</imprint>
	</monogr>
	<note>Proc. ACM Hum.-Comput. Interact.</note>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Linda</forename><surname>Birt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzanne</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debbie</forename><surname>Cavers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christine</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fiona</forename><surname>Walter</surname></persName>
		</author>
		<idno type="DOI">10.1177/1940161220944364</idno>
		<ptr target="https://doi.org/10.1177/1940161220944364" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Member Checking: A Tool to Enhance Trustworthiness or Merely a Nod</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Edson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Tandoc</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oscar</forename><surname>Ling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Westlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Debbie</forename><surname>Duffy</surname></persName>
		</author>
		<author>
			<persName><surname>Goh</surname></persName>
		</author>
		<title level="m">to Validation? Qualitative Health Research</title>
				<editor>
			<persName><forename type="first">Wei</forename><surname>Lim Zheng</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2016">2016. 2018</date>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="1802" to="1811" />
		</imprint>
	</monogr>
	<note>Audiences&apos; acts of authentication in the age of fake</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Politics of Fake News: How WhatsApp Became a Potent of Health Information on Facebook</title>
		<author>
			<persName><forename type="first">Porismita</forename><surname>Borah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xizhu</forename><surname>Xiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Propaganda Tool in India. Media Watch</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="399" to="411" />
			<date type="published" when="2018">2018. 2018. 2018. 2018. 2018</date>
		</imprint>
	</monogr>
	<note>Journal of Health Communication</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Investigating How People (Don&apos;t) Investigate</title>
		<author>
			<persName><forename type="first">Savanna</forename><surname>Geeng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Franziska Roesner ; Joel</forename><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Breakstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amie</forename><surname>Wineburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jill</forename><surname>Rapaport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marshall</forename><surname>Carle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Twitter</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings Garland, and Anna Saavedra. 2019. Students&apos; civic online reasoning: A national of the 2020 CHI Conference on Human Factors in Computing Systems. portrait. , 49 pages. for Computing Machinery</title>
				<meeting>Garland, and Anna Saavedra. 2019. Students&apos; civic online reasoning: A national of the 2020 CHI Conference on Human Factors in Computing Systems. portrait. , 49 pages. for Computing Machinery<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
	<note>Fake News on Face</note>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Joel</forename><surname>Breakstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sam</forename><surname>Wineburg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amie</forename><surname>Rapaport</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jill</forename><surname>Carle</surname></persName>
		</author>
		<imprint>
			<pubPlace>Marshall</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Effect of Network Characteristics Garland, and Anna Saavedra. 2021. Students&apos; Civic Online Reasoning: A National on Online Identity Management Practices</title>
		<author>
			<persName><forename type="first">Natalie</forename><surname>Gerhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Sidorova</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computer Information Portrait. Educational Researcher</title>
		<imprint>
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="229" to="237" />
			<date type="published" when="2017">2017. 2021. 2017</date>
		</imprint>
	</monogr>
	<note>Systems</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<author>
			<persName><forename type="first">Catherine</forename><forename type="middle">Francis</forename><surname>Brooks</surname></persName>
		</author>
		<title level="m">Popular discourse around deepfakes and the</title>
				<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">In interdisciplinary challenge of fake video distribution</title>
		<author>
			<persName><forename type="first">Amira</forename><surname>Ghenai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Behavior, Proceedings of the 2017 International Conference on Digital Health</title>
				<meeting><address><addrLine>London; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017. 2021</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="159" to="163" />
		</imprint>
	</monogr>
	<note>Kingdom) (DH &apos;17)</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">How Google&apos;s $150 billion advertising business works</title>
		<author>
			<persName><forename type="first">Matt</forename><surname>Burgess</surname></persName>
		</author>
		<ptr target="https://www.cnbc.com/2021/05/18/" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Deepfake porn is now mainstream</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Selection and how-does-google-make-money-advertising-business-breakdown-.html transmission processes for information in the emerging media environment: Greg Guest, Kathleen M. MacQueen, and Emily E. Namey. 2012. thematic Psychological motives and message characteristics</title>
		<author>
			<persName><forename type="first">Hyun</forename><forename type="middle">Suk</forename><surname>Joseph N Cappella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dolores</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><surname>Albarracín</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Media psychology</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="396" to="424" />
			<date type="published" when="2015">2015. 2015</date>
		</imprint>
	</monogr>
	<note>3 analysis. SAGE</note>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Komal</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Chugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramanathan</forename><surname>Dhall</surname></persName>
		</author>
		<author>
			<persName><surname>Subramanian</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">What happens when I report something to Face-The Eyes Know It: The eyes know it: FakeET-An Eye-tracking Database book? Does the person I report get notified? Retrieved 2021-09-08 from to Understand Deepfake Perception-An Eye-Tracking Database to Understand</title>
		<ptr target="https://www.facebook.com/help/1037960630447342" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Rumors and Collective Sensemaking: Multimodal Interaction (Virtual Event, Netherlands) (ICMI &apos;20). Association for Managing Ambiguity in an Informal Marketplace. Association for Computing Computing Machinery</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 International Conference on Chandra and Joyojeet Pal</title>
				<meeting>the 2020 International Conference on Chandra and Joyojeet Pal<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="519" to="527" />
		</imprint>
	</monogr>
	<note>Deepfake Perception</note>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName><surname>Machinery</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Combating Misinformation of Social Media Resources Named after a Crisis Event</title>
		<author>
			<persName><forename type="first">Mohammad</forename><surname>Md Mahfuzul Haque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ahmed</forename><surname>Yousuf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pratyasha</forename><surname>Shatil Alam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Apoorva</forename><surname>Saha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amanda</forename><forename type="middle">Lee</forename><surname>Chauhan</surname></persName>
		</author>
		<author>
			<persName><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Bangladesh: Roles and Responsibilities as Perceived by Journalists, Fact-Interact. 4, CSCW1, Article 044 (2020), 23 pages. Checkers, and Users. Proc. ACM Hum.-Comput</title>
				<imprint>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
	<note>Trustworthiness Perceptions Syed Ishtiaque Ahmed, and Naeemul Hassan. Interact. 4, CSCW2, Article 130</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Exploring Internet Security 2020)</title>
		<author>
			<persName><forename type="first">Jay</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Paik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kelly</forename><surname>Mccabe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014">2014</date>
			<biblScope unit="volume">32</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<author>
			<persName><forename type="first">Practices</forename><surname>Perceptions</surname></persName>
		</author>
		<author>
			<persName><surname>In Urban</surname></persName>
		</author>
		<author>
			<persName><surname>Ghana</surname></persName>
		</author>
		<ptr target="https://www.thehindu.com/news/national/other-" />
		<title level="m">10th Symposium On Usable Privacy The Hindu. 2021. A week after election results, violence continues in Bengal. and Security (SOUPS 2014). USENIX Association</title>
				<meeting><address><addrLine>Menlo Park, CA</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="129" to="142" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Misinformation? What of It?&apos;: states/west-bengal-violence-barrage-of-fake-videos-posts-surface-on-social-Motivations and Individual Differences in Misinformation Sharing on Social media</title>
		<author>
			<persName><forename type="first">Xinran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><surname>Sei-Ching</surname></persName>
		</author>
		<ptr target="/article34513532.ece" />
		<imprint>
			<date type="published" when="2013">Joanna Sin. 2013</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><surname>Media</surname></persName>
		</author>
		<title level="m">Proceedings of the 76th ASIS&amp;T Annual Meeting: Beyond</title>
				<meeting>the 76th ASIS&amp;T Annual Meeting: Beyond<address><addrLine>the Cloud</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automatic Detection of Misinformation in Online Medical Videos</title>
		<author>
			<persName><forename type="first">Veronica</forename><surname>Hou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stacy</forename><surname>Perez-Rosas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rada</forename><surname>Loeb</surname></persName>
		</author>
		<author>
			<persName><surname>Mihalcea</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">-American Society for Information Science, USA, Article 104, 4 pages. ternational Conference on Multimodal Interaction China) (ICMI &apos;19)</title>
				<meeting><address><addrLine>Montreal, Quebec, Canada</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Towards Rethinking Information Boundaries</note>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Xinran</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">-Ching Joanna</forename><surname>Sei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yin-Leng</forename><surname>Sin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Chei Sian</forename><surname>Theng</surname></persName>
		</author>
		<author>
			<persName><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015">2015</date>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="235" to="243" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Why Do Social Media Users Share Misinformation</title>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 15th</title>
				<meeting>the 15th</meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Eslam</forename><surname>Hussein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Prerna</forename><surname>Juneja</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tanushree</forename><surname>Mitra</surname></persName>
		</author>
		<title level="m">Measuring Mis</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">USA) information in Video Search Platforms: An Audit Study on YouTube</title>
	</analytic>
	<monogr>
		<title level="m">ACM/IEEE-CS Joint Conference on Digital Libraries</title>
				<meeting><address><addrLine>Knoxville, Tennessee; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Hum.-Comput</publisher>
			<date type="published" when="2020-05">May 2020</date>
			<biblScope unit="page" from="111" to="114" />
		</imprint>
	</monogr>
	<note>Interact. 4, CSCW1, Article 048. 27 pages</note>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Facebook Launches New Education Cam-019-03755-2 paign to Help People Detect Fake News</title>
		<author>
			<persName><surname>Chivers</surname></persName>
		</author>
		<idno>Hutchinson. 2020</idno>
		<ptr target="https://www.nature.com/articles/d41586" />
		<imprint>
			<date type="published" when="2019">2019</date>
			<biblScope unit="page" from="2021" to="2029" />
		</imprint>
	</monogr>
	<note>What&apos;s next for psychology&apos;s embattled field of social priming</note>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">Twitter Agrees to New Indian Government Regcare-about-malware-and-what-to-do-about-it-now/?</title>
		<author>
			<persName><forename type="first">Amit</forename><surname>Chowdhry</surname></persName>
		</author>
		<ptr target="https://www.forbes.com/sites/splunk/2021/09/01/why-you-should-still-Hutchinson.2021" />
		<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
	<note>Study: Relevant Video Content Drives. sh=6357ab965394 Despite Concerns About the Impacts on User Speech. Retrieved</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">to-Not Made for Each Other-Audio-Visual Dissonance-Based Deepfake Detection new-indian-government-regulations-despite-concerns-about/603057/ Localization</title>
		<author>
			<persName><forename type="first">Komal</forename><surname>Chugh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Parul</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abhinav</forename><surname>Dhall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ramanathan</forename><surname>Subramanian ; Hilary Hutchinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wendy</forename><surname>Mackay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bo</forename><surname>Westerlund</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benjamin</forename><forename type="middle">B</forename><surname>Bederson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allison</forename><surname>Druin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Catherine</forename><surname>Plaisant</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michel</forename><surname>Beaudouin-Lafon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stéphane</forename><surname>Conversy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Justin</forename><forename type="middle">D</forename><surname>Cochran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stuart</forename><forename type="middle">A</forename><surname>Napshin</surname></persName>
		</author>
		<idno type="DOI">10.1089/cyber.2020.0100</idno>
		<idno type="PMID">33760667</idno>
		<ptr target="https://doi.org/10.1089/cyber.2020.0100" />
	</analytic>
	<monogr>
		<title level="m">SIGCHI Conference on Human Factors in Computing Systems (Ft. Lauderdale</title>
				<meeting><address><addrLine>New York, NY, USA; Florida, USA; New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2003">2021. 2003. 2021</date>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="164" to="172" />
		</imprint>
	</monogr>
	<note>Techcerns, and Platform Accountability. Behavior, and Social nology Probes: Inspiring Design for and with Families</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Determining Validity in Qualitative USA</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">W</forename><surname>Creswell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dana</forename><forename type="middle">L</forename><surname>Miller</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000">2000</date>
			<biblScope unit="page" from="17" to="24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Theory Into Practice</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="124" to="130" />
			<date type="published" when="2000">2000</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Farnaz</forename><surname>Jahanbakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amy</forename><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adam</forename><forename type="middle">J</forename><surname>Berinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Pennycook</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Exploring Lightweight Interventions Increasing Security Sensitivity With Social Proof: A Large-Scale Experimental at Posting Time to Reduce the Sharing of Misinformation on Social Media</title>
		<author>
			<persName><forename type="first">Sauvik</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><forename type="middle">A</forename><surname>Kramer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jason</forename><forename type="middle">I</forename><surname>Dabbish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hong ; David</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">R</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Confirmation. In Proceedings of the</title>
				<meeting>Confirmation. In eedings of the</meeting>
		<imprint>
			<date type="published" when="2014">2014. 2021. 2014</date>
		</imprint>
	</monogr>
	<note>Interact. 5, CSCW1, Article 18 (2021. 42 pages</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Young peoples&apos; rates of reporting online harass-The Role of Source, Headline and Expressive Responding in Political News and abuse are &apos;shockingly low</title>
		<author>
			<persName><forename type="first">Maurice</forename><surname>Jakesch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Moran</forename><surname>Koren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anna</forename><surname>Evtushenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mor</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName><surname>News</surname></persName>
		</author>
		<ptr target="https://www.ucl.ac.uk/news/" />
	</analytic>
	<monogr>
		<title level="m">Companion Proonline-harassment-and-abuse-are-shockingly-low ceedings of The 2019 World Wide Web Conference</title>
				<meeting><address><addrLine>San Francisco, USA</addrLine></address></meeting>
		<imprint>
			<publisher>WWW</publisher>
			<date type="published" when="2018">2021. January 2. 2018. 2021/dec/young-peoples-rates-reporting-Jasser. 2019</date>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
	<note>Dynamics of Misinformation Cascades</note>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">It Cannot Do All of My Work&quot;: Community Health Worker Perceptions of Jiang and Christo Wilson</title>
		<author>
			<persName><forename type="first">T</forename><surname>Chinasa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Srujana</forename><surname>Okolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nicola</forename><surname>Kamath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Aditya</forename><surname>Dell</surname></persName>
		</author>
		<author>
			<persName><surname>Vashistha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the and Fact-Checking: Evidence from User Comments on Social Media. Proc. ACM 2021 CHI Conference on Human Factors in Computing Systems. Association for Hum</title>
				<meeting>the and Fact-Checking: Evidence from User Comments on Social Media. Proc. ACM 2021 CHI Conference on Human Factors in Computing Systems. Association for Hum<address><addrLine>New York, NY, USA; New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2018-11">2018. nov 2018</date>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="33" to="36" />
		</imprint>
	</monogr>
	<note>Linguistic Signals under Misinformation AI-Enabled Mobile Health Applications in Rural India. 23 pages. Computing Machinery. Article 701, 20 pages</note>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Artificial Intelligence in Digital Media: The Era of [78] Hazard Owen</title>
		<author>
			<persName><forename type="first">Stamatis</forename><surname>Karnouskos</surname></persName>
		</author>
		<idno type="DOI">10.1109/TTS.2020.3001312</idno>
		<ptr target="https://doi.org/10.1109/TTS.2020.3001312fromhttps://www.niemanlab.org/2020/10/crowds-of-regular-people-are-as" />
	</analytic>
	<monogr>
		<title level="j">Transactions on Technology and Society</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="138" to="147" />
			<date type="published" when="2020">2020. 2020. 2020</date>
		</imprint>
	</monogr>
	<note>Crowds of regular people are as good at moderating Deepfakes. news on Facebook as professional fact-checkers. Retrieved 2021-09</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Sub-Evaluation of Media Consumer Vulnerability to Fake Audiovisual Con-Pennycook and David G. Rand. 2021. The Psychology of Fake News. tent</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Khodabakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghavendra</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Busch</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2021.02.007</idno>
		<ptr target="https://doi.org/10.1109/QoMEX.2019.8743316" />
	</analytic>
	<monogr>
		<title level="m">2019 Eleventh International Conference on Quality of Multimedia Expe-Trends in Cognitive Sciences</title>
				<meeting><address><addrLine>Gjøvik, Norway</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019-05">2019. May 2021</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Daiheng</forename><surname>Perov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nikolay</forename><surname>Gao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kunlin</forename><surname>Chervoniy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sugasa</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Marangonda</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Sheng Zhang, jective Evaluation of Media Consumer Vulnerability to Fake Audiovisual Con-Pingyu Wu, Bo Zhou, and Weiming Zhang</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Khodabakhsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raghavendra</forename><surname>Ramachandra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christoph</forename><surname>Busch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Mr</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carl</forename><forename type="middle">Shift</forename><surname>Dpfks</surname></persName>
		</author>
		<author>
			<persName><surname>Facenheim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Luis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jian</forename><surname>Jiang</surname></persName>
		</author>
		<idno type="DOI">10.1109/QoMEX.2019.8743316</idno>
		<ptr target="https://doi.org/10.1109/QoMEX.2019.10pages" />
	</analytic>
	<monogr>
		<title level="m">2019 Eleventh International Conference on Quality of Multimedia Experiflexible and extensible face swapping framework. CoRR abs/2005.05535 (2020), ence (QoMEX)</title>
				<meeting><address><addrLine>Manhattan, NY</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE</publisher>
			<date type="published" when="2019">2019. 2020</date>
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
	<note>DeepFaceLab: A simple</note>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Seeing and Believing: The Influence of Television</title>
		<author>
			<persName><forename type="first">Greg</forename><surname>Philo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002</date>
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Linda</forename><forename type="middle">W</forename><surname>Kietzmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ian</forename><forename type="middle">P</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Tim</forename><forename type="middle">C</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><surname>Kietzmann</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203136560</idno>
		<ptr target="https://doi.org/10.4324/9780203136560" />
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Deepfakes: Trick or treat?</title>
		<idno type="DOI">10.1016/j.bushor.2019.11.006</idno>
		<ptr target="https" />
	</analytic>
	<monogr>
		<title level="m">ARTIFICIAL INTELLIGENCE AND MACHINE Silva, and Aaron Springer. 2017. Implementation Intention and Reminder Effects Behavior Change in a Mobile Health System: A Predictive Cognitive Model</title>
				<editor>
			<persName><forename type="first">//Doi. Peter</forename><surname>Pirolli</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Shiwali</forename><surname>Mohan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Anusha</forename><surname>Venkatakrishnan</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Les</forename><surname>Nelson</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Michael</forename></persName>
		</editor>
		<imprint>
			<date type="published" when="2020">2020</date>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="135" to="146" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">e397. of Possible Solutions Regarding User Acceptance and Effectiveness</title>
		<author>
			<persName><forename type="first">Jan</forename><surname>Kirchner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Reuter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Use of Wearable Technology and Social Media to Improve Physical Activity</title>
				<meeting><address><addrLine>Barr-Anderson, Beth Lewis, Mark Pereira, and Zan Gao</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017-10">2020. 2017. Oct. 2020</date>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page">27</biblScope>
		</imprint>
	</monogr>
	<note>Proc. ACM [83] Pope, Daheia</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Harnessing Social Media for Health Promotion and Dietary Behaviors among College Students: A 12-Week Randomized Pilot and Behavior Change</title>
		<author>
			<persName><forename type="first">Holly</forename><surname>Korda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Zena</forename><surname>Itani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Study. International Journal of Environmental Research and Public Health</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2013">2013. 2013</date>
		</imprint>
	</monogr>
	<note>Health Promotion Practice</note>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">WhatsApp says its forwarding limits have cut //arxiv.org/abs/2009.03155 the spread of viral messages by 70 percent</title>
		<author>
			<persName><forename type="first">Pavel</forename><surname>Korshunov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sébastien</forename><surname>Marcel</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2009.03155https:JonPorter.2020</idno>
		<imprint>
			<date type="published" when="2009">2020. Sep 2019. 2009.03155 (2020</date>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="2021" to="2029" />
		</imprint>
	</monogr>
	<note>3579. vs. machines. CoRR abs/</note>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">The focus of misinformation debates shifts south</title>
		<author>
			<persName><forename type="first">Nieman</forename><surname>Lab</surname></persName>
		</author>
		<ptr target="https://www.theverge.com/2020/4/27/21238082/whatsapp-forward-https://www.niemanlab.org/2018/12/the-focus-of-misinformation-debates-message-limits-viral-misinformation-declineshifts-south/" />
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Exposing DeepFakes with Attentional Visual Make It Worse. Retrieved 2022-02-17 from https://www.boomlive.in/india-is-Heartbeat Rhythms. for Computing Machinery</title>
		<author>
			<persName><forename type="first">Qing</forename><surname>Qi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felix</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xiaofei</forename><surname>Juefei-Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lei</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wei</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yang</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Labelo</forename><surname>Liu</surname></persName>
		</author>
		<ptr target="teeming-with-cheapfakes-deepfakes-could-make-it-worse/4318-4327" />
		<imprint>
			<date type="published" when="2019">2019. 2020</date>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>India Is Teeming With &apos;Cheapfakes&apos;, Deepfakes Could Jianjun Zhao</note>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title level="m" type="main">Share News in Messaging, Social, and Public Networks. Association for Computing Fabrício Benevenuto. 2020. A Dataset of Fact-Checked Images Shared Machinery</title>
		<author>
			<persName><forename type="first">Frank</forename><forename type="middle">R</forename><surname>Lottridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Bentley ; Julio</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philipe</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kiran</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jussara</forename><forename type="middle">M</forename><surname>Garimella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><surname>Almeida</surname></persName>
		</author>
		<author>
			<persName><surname>Eckles</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="page" from="1" to="13" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
	<note>Let&apos;s Hate Together: How People. on WhatsApp During the Brazilian and Indian Elections. Proceedings of the</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Yu</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ming</forename><surname>Hao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengzhen</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fengjuan</forename><surname>Shi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yuanmao</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AAAI Conference on Web and Social Media</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="903" to="908" />
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Application of a social media platform as a patient [87] Niranjan Sahoo. 2020. How fake news is complicating India&apos;s war against reminder in the treatment of Helicobacter pylori</title>
		<author>
			<persName><forename type="first">Weigang</forename><surname>Chen</surname></persName>
		</author>
		<idno>COVID-19. Retrieved 2021-09-08</idno>
		<ptr target="https://www.orfonline.org/expert-e12682.speak/how-fake-news-complicating-india-war-against-covid19-66052/" />
	</analytic>
	<monogr>
		<title level="j">Helicobacter</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<date type="published" when="2020">2020. 2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Brandon</forename><surname>Mader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">S</forename><surname>Banks</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hany</forename><surname>Farid</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Identifying Computer</title>
		<imprint>
			<date type="published" when="2017">2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Encounters with Generated Portraits: The Importance of Training and Incentives</title>
		<author>
			<persName><forename type="first">Claire</forename><forename type="middle">R</forename><surname>Saltz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Claire</forename><surname>Leibowicz</surname></persName>
		</author>
		<author>
			<persName><surname>Wardle</surname></persName>
		</author>
		<ptr target="https://www.singlegrain.com/video-Systems.forComputingMachinery" />
	</analytic>
	<monogr>
		<title level="m">Mahoney. 2020. Just the Stats: Why Should You Leverage Video Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Retrieved 2021-09-06 from</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2017">2021. 2017</date>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="1062" to="1076" />
		</imprint>
	</monogr>
	<note>Study to Inform Ecosystem Approaches to Misinformation Interventions. Article marketing/just-stats-science-video-engagement/ 340, 6 pages</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Determining authenticity of 2020. Digital and Social Media Landscape in India. Retrieved 2021-09-08 video evidence in the age of artificial intelligence and in the wake of Deepfake from https://sannams4.com/digital-and-social-media-landscape-in-india</title>
		<author>
			<persName><forename type="first">Marie-Helen</forename><surname>Maras</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><surname>Alexandrou</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Evidence &amp; Proof</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="255" to="262" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Why do people share fake news? A sociotechnical model goes to die</title>
		<author>
			<persName><surname>Schwartz</surname></persName>
		</author>
		<ptr target="https://www.theguardian.com/ofmediaeffects" />
	</analytic>
	<monogr>
		<title level="j">Georgetown Law Technology Review</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="474" to="512" />
			<date type="published" when="2018">2018. 2018. 2018</date>
		</imprint>
	</monogr>
	<note>You thought fake news was bad? Deep fakes are where E Marwick. Retrieved 2021-09-08 from</note>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">Coronavirus: The human cost of fake news in India</title>
		<author>
			<persName><forename type="first">Shruti</forename><surname>Menon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">during the 2012 US presidential election: Rumor diffusion and 53165436 correction</title>
		<author>
			<persName><forename type="first">Jieun</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lian</forename><surname>Jian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kevin</forename><surname>Driscoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">François</forename><surname>Bar</surname></persName>
		</author>
		<ptr target="https://www.bbc.com/news/world-asia-india-ingonTwitter" />
	</analytic>
	<monogr>
		<title level="j">New Media &amp; Society</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="1214" to="1235" />
			<date type="published" when="2017-01-08">2017. January 8, 2021. 2017</date>
		</imprint>
	</monogr>
	<note>Political rumor</note>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Online Misinformation: From the Heuristic Approaches to Credibility Evaluation Online. of Communica-Deceiver to the Victim</title>
		<author>
			<persName><forename type="first">J</forename><surname>Metzger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Flanagin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ryan</forename><forename type="middle">B</forename><surname>Medders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ference on Advances in Social Networks Analysis and Mining</title>
				<meeting><address><addrLine>Vancouver, British</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2010">2010. 2019. 2019. 08 2010</date>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="413" to="439" />
		</imprint>
	</monogr>
	<note>Proceedings of the</note>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Association for Computing Machinery, New political affiliation and beliefs about sources of &quot;fake news</title>
		<author>
			<persName><forename type="first">B</forename><surname>Michael</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brooke</forename><forename type="middle">O</forename><surname>Breaux</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Principles and Implications</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="847" to="850" />
			<date type="published" when="2021">2021. 2021</date>
			<publisher>York</publisher>
		</imprint>
	</monogr>
	<note>The relationship between Columbia, Canada) (ASONAM &apos;19). 15 pages. Issue 1</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Short-Form Video Dominates Social Media In India. Reprogram for first time internet users in India</title>
		<author>
			<persName><forename type="first">Manish</forename><surname>Singh</surname></persName>
		</author>
		<ptr target="https://www.forbes.com/sites/anandamitra/2020/06/23/fromhttps://social.techcrunch.com/2019/07/03/reliance-jio-facebook-digital-tiktok-short-form-video-dominates-social-media-in-india/?sh=30b9e49c6803literacy-udaan-india/" />
		<imprint>
			<date type="published" when="2019">2019. 2020. January 7, 2021 trieved 2021-09</date>
		</imprint>
	</monogr>
	<note>Reliance Jio partners with Facebook to launch literacy Ananda Mitra</note>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Aniket Bera, and Dinesh Statista. 2021. Social media users in India</title>
		<author>
			<persName><forename type="first">Trisha</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Uttaran</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rohan</forename><surname>Chandra</surname></persName>
		</author>
		<idno>2021-09-09 from https: Manocha. 2020</idno>
		<ptr target="Method//www.statista.com/forecasts/1145422/social-media-users-in-india" />
		<imprint/>
	</monogr>
	<note>Emotions Don&apos;t Lie: An Audio-Visual Deepfake Detection</note>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Learning through USA, 2823-2832. Uncovering Approaches to Educating People about Facebook Privacy</title>
		<author>
			<persName><forename type="first">Alexa</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><forename type="middle">Makoto</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xinru</forename><surname>Page ; Shiva Pentyala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mengnan</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yi</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nic</forename><surname>Lupfer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sina Mohseni, Fan Yang</title>
				<meeting><address><addrLine>New York, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
	<note>Using Affective Cues. Xia 5 pages</note>
</biblStruct>

<biblStruct xml:id="b76">
	<analytic>
		<title level="a" type="main">Tom Prevent Overtrust in Fake News Detection</title>
		<author>
			<persName><forename type="first">Shuiwang</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eric</forename><surname>Ji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Ragan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dan</forename><surname>Sterrett</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jennifer</forename><surname>Malato</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Liz</forename><surname>Benz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Trevor</forename><surname>Kantor</surname></persName>
		</author>
		<author>
			<persName><surname>Tompson</surname></persName>
		</author>
		<idno type="DOI">10.1177/2056305120903408</idno>
		<idno type="arXiv">arXiv:2007.12358</idno>
		<ptr target="https://doi.org/801.10.1177/2056305120903408arXiv:https://doi.org/10.1177/2056305120903408" />
	</analytic>
	<monogr>
		<title level="m">Who Shared It?: Deciding What News to Trust on Social Media. Digital Journalism</title>
				<editor>
			<persName><forename type="first">Jeff</forename><surname>Ir] Rosenstiel</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">Kevin</forename><surname>Sonderman</surname></persName>
		</editor>
		<editor>
			<persName><surname>Loker</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2019-07">2020. 2019. July 2019. 2020</date>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">783</biblScope>
		</imprint>
	</monogr>
	<note>Machine Learning Explanations</note>
</biblStruct>

<biblStruct xml:id="b77">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">R</forename><surname>Sultana</surname></persName>
		</author>
		<author>
			<persName><surname>Fussell</surname></persName>
		</author>
		<editor>Dissemination, Situated Fact-Aditya Abhinav Garg, Richard Anderson, and Agha Ali Raza</editor>
		<imprint>
			<date type="published" when="2019">2021. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Social Effects of Misinformation among Rural Bangladeshi Vil-Threats, Abuses, Flirting, and Blackmail: Gender Inequity in Social Media Voice lagers During the COVID-19 Pandemic</title>
		<author>
			<persName><surname>Checking</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2019 CHI Conference on Human Factors in Com-CSCW2</title>
				<meeting>the 2019 CHI Conference on Human Factors in Com-CSCW2<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2021-10">oct 2021</date>
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
	<note>34 pages. puting Systems. for Computing Machinery</note>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Seeing Is Believing: Is Modality More Powerful in Spreading Fake News via Online Messaging</title>
		<author>
			<persName><forename type="first">Shyam</forename><surname>Sundar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maria</forename><forename type="middle">D</forename><surname>Molina</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eugene</forename><surname>Cho</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021">2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<monogr>
		<title level="m" type="main">Deprivation, distance and connectivity: The adaptation of , 29 pages. mobile phone use to a life in Wesbank</title>
		<author>
			<persName><forename type="first">Fie</forename><surname>Velghe</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Rashid</forename><surname>Tahir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brishna</forename><surname>Batool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hira</forename><surname>Jamshed</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mahnoor</forename><surname>Jameel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mubashir</forename><surname>Anwar</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.dcm.2012.09.004</idno>
		<ptr target="https://doi.org/10.1016/Ahmed,MuhammadAdeelZaffar,andMuhammadFareedZaffar.2021.j.dcm.2012.09.004" />
	</analytic>
	<monogr>
		<title level="j">Africa. Discourse, Context &amp; Media</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="203" to="216" />
			<date type="published" when="2012">2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title level="m" type="main">Why AI isn&apos;t going to solve Facebook&apos;s fake news probof the 2021 CHI Conference on Human Factors in Computing Syslem</title>
		<ptr target="https://www.theverge.com/2018/4/5/17202886/tems.forComputingMachinery" />
		<editor>James Vincent</editor>
		<imprint>
			<date type="published" when="2018">2018</date>
			<biblScope unit="volume">174</biblScope>
			<pubPlace>New York, NY, USA, Article</pubPlace>
		</imprint>
	</monogr>
	<note>Seeing is Believing: Exploring Perceptual Differences in DeepFake Videos. Retrieved 2021-09-08 from</note>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Deepfakes, Gender, and the Challenges of AI-Altered Video:. Open Information</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wagner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ashley</forename><surname>Blewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">;</forename><surname>Talwar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Amandeep</forename><surname>Dhir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Puneet</forename><surname>Kaur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nida</forename><surname>Zafar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Melfi</forename><surname>Alrasheedy</surname></persName>
		</author>
		<idno type="DOI">10.1515/opis-2019-0003</idno>
		<idno>wombo. 2021</idno>
	</analytic>
	<monogr>
		<title level="j">Associations between the dark side Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="72" to="82" />
			<date type="published" when="2019">2019. 2019. 2019. 2019</date>
		</imprint>
	</monogr>
	<note>Ai lip sync app. Retrieved 2021-09-08 from https: Consumer Services</note>
</biblStruct>

<biblStruct xml:id="b84">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Lu</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kayo</forename><surname>Fujimoto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Muhammad</forename><forename type="middle">Tuan</forename><surname>Amith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rachel</forename><surname>Cunningham</surname></persName>
		</author>
		<imprint>
			<pubPlace>Re</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Down the Rabbit Hole&quot; of Vaccine Misinformation on YouTube: Network 2019 on Computer Supported Cooperative Work and Social Computing (Austin, Exposure Study</title>
		<author>
			<persName><forename type="first">Susan</forename><surname>Wyche</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; A</forename><surname>Costantini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Felicia</forename><surname>York</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Grace</forename><surname>Xiong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Julie</forename><forename type="middle">A</forename><surname>Boom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cui</forename><surname>Tao</surname></persName>
		</author>
		<idno>2021-09-08</idno>
		<ptr target="in-consumption-of-video-ads-report-11582024457022.html" />
	</analytic>
	<monogr>
		<title level="m">Using Cultural Probes New Contexts: Exploring the becca</title>
				<meeting><address><addrLine>New York, NY, Saumya Tewari</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2019">2019. 2021. 2020. 2021</date>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="36" to="51" />
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
	<note>sixth-largest-market-Deepfakes and social media regulation</note>
</biblStruct>

<biblStruct xml:id="b86">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Otari</forename><surname>Yaqub</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morgan</forename><forename type="middle">L</forename><surname>Kakhidze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nasir</forename><surname>Brockman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sameer</forename><surname>Memon</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title level="m" type="main">Epistemology in 2020. Effects of Credibility Indicators on Social Media News Sharing Intent. the Era of Fake News: An Exploration of Information Verification Behaviors</title>
		<author>
			<persName><forename type="first">Russell</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Natalie</forename><surname>Gerhart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arash</forename><surname>Negahban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
			<publisher>Association for Computing Machinery</publisher>
			<biblScope unit="page" from="1" to="14" />
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<analytic>
	</analytic>
	<monogr>
		<title level="m">Brandy Zadrozny. 2021. On TikTok, audio gives new virality to misinformation</title>
		<title level="s">among Social Networking Site Users. SIGMIS Database</title>
		<imprint>
			<date type="published" when="2018-07">jul 2018</date>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="78" to="97" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Deepfakes and Disinformation: Retrieved 2021-09-09 from</title>
		<author>
			<persName><forename type="first">Cristian</forename><surname>Vaccari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename><surname>Chadwick</surname></persName>
		</author>
		<ptr target="https://www.nbcnews.com/tech/tech-news/tiktok" />
	</analytic>
	<monogr>
		<title level="m">-Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, audio-gives-new-virality-misinformation-rcna1393</title>
				<imprint>
			<date type="published" when="2020">2020</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
