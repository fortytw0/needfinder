<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Design is Worth a Thousand Words: The Efect of Digital Interaction Design on Picture-Prompted Reminiscence</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Benett</forename><surname>Axtell</surname></persName>
							<email>benett.axtell@mail.utoronto.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology, University ICCIT</orgName>
								<orgName type="institution" key="instit1">TAGlab</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto Toronto of Toronto</orgName>
								<address>
									<settlement>Toronto, Mississauga, Mississauga</settlement>
									<country>Canada, Canada, Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology, University ICCIT</orgName>
								<orgName type="institution" key="instit1">TAGlab</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto Toronto of Toronto</orgName>
								<address>
									<settlement>Toronto, Mississauga, Mississauga</settlement>
									<country>Canada, Canada, Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Raheleh</forename><surname>Saryazdi</surname></persName>
							<email>raheleh.saryazdi@mail.utoronto.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology, University ICCIT</orgName>
								<orgName type="institution" key="instit1">TAGlab</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto Toronto of Toronto</orgName>
								<address>
									<settlement>Toronto, Mississauga, Mississauga</settlement>
									<country>Canada, Canada, Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology, University ICCIT</orgName>
								<orgName type="institution" key="instit1">TAGlab</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto Toronto of Toronto</orgName>
								<address>
									<settlement>Toronto, Mississauga, Mississauga</settlement>
									<country>Canada, Canada, Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Cosmin</forename><forename type="middle">2022</forename><surname>Munteanu</surname></persName>
							<email>cosmin.munteanu@utoronto.ca</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology, University ICCIT</orgName>
								<orgName type="institution" key="instit1">TAGlab</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto Toronto of Toronto</orgName>
								<address>
									<settlement>Toronto, Mississauga, Mississauga</settlement>
									<country>Canada, Canada, Canada</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology, University ICCIT</orgName>
								<orgName type="institution" key="instit1">TAGlab</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto Toronto of Toronto</orgName>
								<address>
									<settlement>Toronto, Mississauga, Mississauga</settlement>
									<country>Canada, Canada, Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><surname>Design</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology, University ICCIT</orgName>
								<orgName type="institution" key="instit1">TAGlab</orgName>
								<orgName type="institution" key="instit2">University of Toronto</orgName>
								<orgName type="institution" key="instit3">University of Toronto Toronto of Toronto</orgName>
								<address>
									<settlement>Toronto, Mississauga, Mississauga</settlement>
									<country>Canada, Canada, Canada</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Design is Worth a Thousand Words: The Efect of Digital Interaction Design on Picture-Prompted Reminiscence</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1145/3491102.3517692</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.7.1" ident="GROBID" when="2022-07-22T05:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Digital picture interactions</term>
					<term>digital storytelling</term>
					<term>reminiscence</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Interactions with our personal and family pictures are essential to continued social reminiscence, leading to long-term benefts, including reduced social isolation. Previous research has identifed how designs of digital picture tools fall short of physical options specifcally in terms of reminiscence. However, the relative prompting abilities of diferent digital interactions, including the types of memories prompted like external facts or person-centred memories, have not yet been explored. To investigate this, we present a controlled study of the memories prompted by three digital picture interactions (slideshow, gallery, and tabletop) on personal touchscreen devices. We fnd diferences in how these tools and the interactions they support prompt reminiscence. In particular, gallery views prompt signifcantly fewer memories than either the tabletop or slideshow. Slideshows prompt signifcantly more external, factual memories, but not more person-centred memories, which are key to reminiscence. This has implications for the overall social usability of digital picture interactions.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">INTRODUCTION</head><p>Our interactions with personal and family pictures are important. They provide one of the major starting points for developing our personal narratives and for our socialization through reminiscence, or storytelling. Pictures, in both digital and physical (i.e., paperbased) settings, are known to be one of the strongest prompts for memories <ref type="bibr" target="#b25">[25,</ref><ref type="bibr" target="#b37">37]</ref>. Physical pictures, and our interactions with them, have been a main method of family socialization for over a century, and continue to be a common and treasured activity <ref type="bibr" target="#b31">[31]</ref>. However, socially browsing and sharing memories from digital pictures is not feasible to the same extent as with physical pictures <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>How we engage with pictures generally, both digital and physical, has been well-researched. Past work has identifed some of the benefts of interactions with physical pictures, including ease of access and strength as a memory prompt <ref type="bibr" target="#b11">[12,</ref><ref type="bibr" target="#b37">37]</ref>. It has also identifed some limitations of commonly available digital tools, such as limited user control and limited context between one picture and the larger collection, including the related memories <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8]</ref>. Generally, digital picture interactions bring little of what is familiar and efective about physical interactions to the digital space <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8]</ref>. Personal pictures and personal photography have been majority digital since 2004 <ref type="bibr" target="#b36">[36]</ref>, but available digital picture tools do not yet create a space for casual and collaborative social interactions, especially around storytelling, as physical pictures do <ref type="bibr" target="#b7">[8]</ref>. These previous qualitative works have identifed shortcomings of available picture settings, including highlighting the diferences between the physical and various digital interactions (e.g., lack of tangibility, navigating volume of pictures, ease of metadata search). These diferences are described as being limiting factors to reminiscence. In this paper, we explore the relative prompting ability of diferent digital settings in order to understand whether these diferences can be observed in a controlled setting.</p><p>Common digital settings for sharing pictures (e.g., Facebook and other social networking sites) are largely engaging users in capturing pictures to be shared immediately, like a morning cup of cofee. This use is new to digital settings and distinct from the pictures intended for reminiscence that are captured in one moment to be shared at a later date <ref type="bibr" target="#b32">[32]</ref>. Thus, though available digital tools do engage users over pictures, there is little evidence that reminiscence is signifcantly present or encouraged by these tools.</p><p>It is not necessary that digital picture interactions mimic traditional physical ones. However, social reminiscence should still be accessible digitally due to the importance both of reminiscence and of pictures as prompts. We seek to understand how digital tools prompt memories, not as compared to paper-based interactions, but because paper-based interactions can be strong prompts for social reminiscence and available digital interactions have not yet achieved that. Given that pictures are now prominently viewed in digital form, it is important for digital tools to provide meaningful interactions supporting storytelling or risk losing access to this crucial vector of family reminiscence.</p><p>In this paper, we present a controlled online study assessing the ability of diferent touch-based digital picture interactions to prompt storytelling and reminiscence. Our goal is to explore the relative abilities of diferent digital interactions to prompt memory sharing and reminiscence in order to understand what about digital settings is falling short of the physical alternatives and how to better support reminiscence digitally. Specifcally, we ask: Does the reminiscence prompted from these distinct touch-based digital picture interactions vary signifcantly in terms of the quantity and type of memories?</p><p>We compare the memories shared from three tablet designs: 1) Gallery, which presents a grid of small pictures; 2) Slideshow, which presents pictures individually in a slideshow; and 3) Tabletop, which is based on physical interactions with paper pictures spread across a table. The gallery and slideshow designs mirror the common interactions of available tools. The tabletop design is directly inspired by physical interactions with pictures and by past research into both what is efective about physical interactions and what is limiting about digital ones, namely that browsing should be easy and collaborative, and that pictures should have a consistent visual context between them <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref>.</p><p>Participants interacted with each design, and the resulting memories were compared based on the number and type (i.e., personcentred or external memories). Person-centred memories (including episodic memories) relate to a personal experience, are generally more detailed than external memories, and are central to reminiscence. External memories (including semantic memories) are factual, often less detailed, and are generally based on learned knowledge, but are less important for reminiscence <ref type="bibr" target="#b25">[25]</ref>. We provide detailed defnitions of person-centred and external memories, examples of each, and our motivations for using these defnitions for this work in the next section.</p><p>These controlled comparisons present an understanding of whether the digital display of pictures and interactions with that display afect how diferent types of memories are prompted, which has yet to be explored on existing and available digital interfaces. Digital picture tools are consistently found to provide at best limited support for reminiscence. Despite this, reminiscence is acknowledged as both a central to picture interactions and an import aspect of social connection. Therefore, it is crucial that digital pictures can prompt reminiscence as well as physical pictures. The results highlight the shortcomings of the existing design standards, and show that reminiscence must be actively included as a central aspect of digital picture interactions. In order for reminiscence to continue as a social activity, digital picture tools need to intentionally include these activities through designs that actively prompt reminiscence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">RELATED WORK</head><p>To date, a number of studies have explored interactions with pictures, both digitally and physically, as well as the role of pictures for reminiscence <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b9">10]</ref>. Although many new digital picture interactions have been and are being both proposed and assessed in controlled settings, only a few are centred on reminiscence activities. Here we review the existing research into reminiscence and memory prompting, how people interact with pictures, and other examples of controlled studies of digital picture interactions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Social Reminiscence and Pictures as Memory Prompts</head><p>Reminiscence, the social storytelling and sharing of personal experiences, is a social activity that is central to fostering and maintaining sense of identity within families and broader communities. Reminiscence is linked to reduced social isolation and stronger self-identity, making it particularly important as we age <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b22">22]</ref>. Given the importance of reminiscence for the aging population, much work has explored the reminiscence of people with memory loss, such as Dementia, and how pictures and/or digital tools prompt reminiscence in this population. Research into reminiscence therapy, which uses pictures and other stimuli to prompt reminiscence as a treatment for memory loss, has found that these stimuli are particularly efective prompts for episodic and person-centred memories that are integral to reminiscence <ref type="bibr" target="#b25">[25]</ref>, and that both digital and physical pictures are efective prompts <ref type="bibr" target="#b26">[26]</ref>. This prompting ability, as well as the general accessibility of pictures, has been recognized by participants who describe capturing pictures in order to be displayed and cherished years later <ref type="bibr" target="#b22">[22]</ref>. Further, sharing of pictures and the memories they prompt is often described by participants as building a connection between friends and families <ref type="bibr" target="#b18">[18]</ref>. The characteristics of the picture itself has also shown to be important for reminiscence. For example, a study of people with Dementia compared reminiscence from personal and general pictures and found that general pictures are stronger prompts for reminiscence <ref type="bibr" target="#b2">[3]</ref>. Another study asked older adults to reminisce from physical or digital pictures and measured the time spent looking at each picture. They found that participants spent more time looking at the physical pictures than on the full-screen tablet pictures, but this study did not measure the resulting reminiscence <ref type="bibr" target="#b26">[26]</ref>.</p><p>Other research has explored how we use and interact with personal pictures. Chalfen's work explored how we interact with (largely physical) pictures, focusing on the diferent uses of domestic photography and identifed a key purpose of these pictures to be demonstrating one's place in society <ref type="bibr" target="#b8">[9,</ref><ref type="bibr" target="#b9">10]</ref>. Since the early 2000s, when digital photography surpassed flm, research has been exploring and observing users' needs for digital picture interactions. Other early digital works found that casual handheld formats were important for digital picture interactions, similar to existing physical options <ref type="bibr" target="#b23">[23]</ref> and that reminiscence as an important motivation for using digital pictures is consistent across ages, including teenagers <ref type="bibr" target="#b34">[34]</ref>.</p><p>These works demonstrate the importance of reminiscence, and particularly the importance of episodic and other person-centred memories, across digital and physical settings and across ages of users. Based on this clear need for reminiscence in a digital setting, we study what types of memories are prompted by digital interactions with pictures, which will advance our understanding of how to better support reminiscence activities digitally.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Memories and Memory Prompting</head><p>Memories are often categorized as being either episodic and semantic; episodic being memories that refer to a specifc event (or episode) from a person's past, and semantic being the memories of factual knowledge (e.g., what the Eifel Tower looks like) <ref type="bibr" target="#b25">[25]</ref>.</p><p>Other recent work identifes memories to exist on a spectrum from episodic to semantic <ref type="bibr" target="#b20">[20]</ref>. That is, from more self-related to less self-related or from person-centred to external. These last terms, person-centred and external, are the terms we will use in this paper.</p><p>Person-centred memories, including episodic memories, are a retelling of a personal experience and are therefore linked to memory strength and are central to activities of reminiscence. Where a fully episodic memory would be of a specifc episode, a personcentred memory may be more generally about past experience, such as remembering taking the subway often, but not a specifc instance of taking it. Semantic and other external memories are based in known facts, but are less important for reminiscence as they do not relate a personal story. As person-centred memories are based in past experiences, they often include more detail than external memories <ref type="bibr" target="#b25">[25]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Interactions with Digital Pictures</head><p>Based on actual family picture use, early requirements for digital photoware found that loose pictures prompt memory sharing more frequently than photo albums and emphasize the importance of informal communication and sharing of stories for picture interactions <ref type="bibr" target="#b11">[12]</ref>. Several models of the diferent activities or phases of use of digital pictures, including social reminiscence, have been proposed from qualitative observations of use <ref type="bibr" target="#b6">[7,</ref><ref type="bibr" target="#b19">19]</ref>. Research into the needs for picture interactions on mobile devices found that sharing pictures for reminiscence was mostly a casual and in person activity and that the common slideshow view is limiting and lacks customization <ref type="bibr" target="#b1">[2]</ref>. A recent participatory redesign of diferent digital picture settings and the related needs for collaborative reminiscence found that digital settings primarily lack user-controlled picture curation and access to a larger visual context of pictures <ref type="bibr" target="#b7">[8]</ref>.</p><p>These works show the variety of activities that are currently being done with pictures. From these models of use, we see diferences between analog interactions with physical (or paper-based) pictures and digital interactions with digital pictures. In particular, opportunities for social reminiscence in digital settings are lacking. In this paper, we focus specifcally on the reminiscence aspect of digital picture interactions to assess how that activity is currently supported.</p><p>Controlled studies that assess how users interact with digital pictures have largely focused on the area of searching and browsing for pictures, though some recent work has questioned the use of a directed search task as unrealistic to actual picture interactions <ref type="bibr" target="#b38">[38]</ref>. Browsing and viewing digital pictures has been assessed by measuring time to fnd a specifc picture <ref type="bibr" target="#b27">[27]</ref> or to build a small set based on some criteria, like shared location <ref type="bibr" target="#b17">[17]</ref>. One project included a task to gather a set of pictures with the intent to then share a story from them, but did not assess the memories themselves, and instead analyzed the actions completed to prepare the pictures <ref type="bibr" target="#b10">[11]</ref>. Another project observed searching, browsing, and selecting personal pictures to understand and predict picture preference and intended activity as measured by time spent viewing each picture. They found that participants spent a signifcantly longer time on each picture during browsing than when selecting or searching <ref type="bibr" target="#b4">[5]</ref>. To our knowledge, no work has yet measured reminiscence as prompted by various types of digital interactions with pictures, as we assess with this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">METHODS</head><p>To investigate the potential efects of digital interaction on reminiscence, we compare three distinct touch-based picture display designs (i.e., gallery, slideshow, and tabletop) through a counterbalanced within-participant study. Participants used their own device to look at each of the display designs in turn. Three sets of stock pictures were gathered for participants to browse with each image representing diferent aspects of Paris life and tourism. Pictures were chosen to represent a generally recognizable setting and will be described in detail below. Participants were asked to share any memories that came to mind while browsing the pictures.</p><p>Ethical considerations informed all aspects of this research design. No participant withdrew from the study. This protocol has been developed following national Canadian principles (TCPS2) and is approved by our university's Research Ethics Board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Participants</head><p>Participants were recruited through an online participant recruitment tool as well as through community groups with interests in memory and storytelling. Participants were compensated $20, which is in line with the average part-time hourly rate in our area.</p><p>In total, 38 participants completed the study. Two were excluded, but fully compensated, for technical limitations of their devices: one for an outdated tablet with small screen and low resolution which limited the visibility of pictures and the other for poor internet which was insufcient to load all the images for each condition. The fnal sample of 36 participants were included in the analyses, which covers all counterbalanced cases including orders of conditions and of picture sets, as described below.</p><p>The demographics form collected both age and gender through open text felds, as recommended by Spiel et al. <ref type="bibr" target="#b35">[35]</ref>. Participants were aged from 19 to 62 (M = 36.9, SD = 12.4), and were made up of 11 men and 25 women. The collected demographics also included whether or not the participant had visited Paris, France; 14 participants had previously visited Paris, and 22 had not, though one of those had previously been to France. Additionally, several participants who had not visited Paris had friends or family who had, which acted as a prompt for memories, and of the participants who had visited, those experiences ranged from weekly business trips to a single overnight.</p><p>All participants used their own tablet or touchscreen computer, including 17 Apple iPads, two Windows tablets, 16 Windows touchscreen laptops, and one Amazon Kindle. Familiarity with technology was measured with the Mobile Device Profciency Questionnaire (MDPQ), a self-reported measure of an individual's technical literacy, based on how easily a participant believes they could do various tasks from 1 (Never Tried) to 5 (Very Easily) <ref type="bibr" target="#b29">[29]</ref>. The MDPQ is measured by calculating a sum of the participant's average scores from each questionnaire section, resulting in a possible range of 0 (very inexperienced) to 40 (very experienced). The summed scores in the present study ranged from 23.95 to 40.00 (M = 37.28, SD = 3.54), which is in line with an expected range of ability as found by Roque and Boot <ref type="bibr" target="#b29">[29]</ref>. See Appendix A for detailed participant demographic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Measures and Instruments</head><p>3.2.1 Picture Prompts. We gathered three sets of 50 pictures around a common theme, namely tourism to Paris, France, with each set representing a sub-theme of food, landmarks, or culture. For each of the three digital interactions (described next) participants saw pictures from one of these three subsets. These same pictures were used for each participant and were sourced from stock photo websites (i.e., pixabay.com, unsplash.com, and wikimedia.com) and only pictures with Creative Commons copyright were selected. The distinct sub-themes of pictures were used to minimize fatigue efects on participant storytelling and ensure that there would be diferent Figure <ref type="figure">1</ref>: Screenshot of the gallery study condition. memories prompted by each condition. The reason we chose 50 pictures for each set size is because it is within the range of standard physical photo albums and printed photo books, and will be sufcient to fll a screen (such as in the gallery condition) while providing enough variety to likely present some interesting prompts to all participants.</p><p>As general pictures have been shown to be as good or stronger prompts for memory as personal ones <ref type="bibr" target="#b2">[3]</ref>, the repeated set of stock pictures is expected to prompt memories from a broad range of participants. A consistent theme across all the pictures was chosen in order to provide a consistent visual context between the pictures, and therefore more cohesive prompts. The Paris theme was chosen as it is a common vacation destination and historical site and therefore many participants will likely have either visited themself, plan to visit someday, or will be at least familiar with the sights, so will have some memories prompted regardless of their past experiences. As such, we did not require participants to have previous experiences in Paris or France themselves, but did collect whether or not Figure <ref type="figure">2</ref>: Screenshot of the slideshow study condition. they had been previously. From both participants who had visited Paris and those who had not, the resulting memories included a mix of those related directly to Paris and other memories.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">Digital</head><p>Interactions. This study compares three digital interactions. We do not include a physical, paper-based condition primarily because the controlled setting across conditions (a digital tablet) would be compromised by introducing a separate device (e.g., a physical photo album) for one condition. Digital spaces do not need to be made to match physical ones and there are already aspects of digital interaction that are practically impossible with paper pictures, so such a comparison is outside the scope of this work.</p><p>Of the three digital conditions, two mirror common, available designs: a gallery view (fgure 1) displaying many pictures together and a slideshow view (fgure 2) showing one picture at a time in an ordered list. The third condition, the tabletop (fgure 3), was designed based on past research into how digital and physical pictures Figure <ref type="figure">3</ref>: Screenshots of the tabletop study condition. are used to share stories <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref>. The tabletop uses the metaphor of family or friends gathered around a table with pictures spread out across the surface in order to share memories, such as after a large Past research has found that digital picture interactions need to family dinner or similar event. This common activity prompts ca-include pictures in a broader visual context and emphasize ease of sual storytelling through its ease of access and unstructured layout access for casual and synchronous interactions <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref>. Inspired by as any picture that catches someone's eye can prompt a story.</p><p>these fndings, the tabletop presents all of the pictures in a rough grid, but unlike the gallery view the pictures are intentionally uncropped and large enough to be seen individually. Pictures are also tilted randomly to present the familiar, casual feeling of a haphazard spread of analog pictures across a communal table. Unlike the gallery, which can only be scrolled vertically, the tabletop can be scrolled infnitely in any direction as pictures are repeated. This is designed to encourage easy exploration and browsing so users do not need to scroll back once an edge has been found, which better refects the reality of the large literal tabletop where screen size is not a limitation. As past works have found that reminiscence is not supported by existing digital pictures tools <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8]</ref>, we have chosen to investigate the reminiscence potential of the two primary methods of viewing digital pictures, regardless of whether the intent of the designs includes reminiscence. Despite the lack of access to reminiscence, the slideshow and gallery views are practically the sole methods of accessing digital pictures, and therefore are involved whenever reminiscence is attempted from digital pictures <ref type="bibr" target="#b7">[8]</ref>.</p><p>None of these designs are considered a baseline for this study, and all three are compared to each other equally. Though two of the included designs mirror existing interactions, neither of them is an efective baseline as there is not existing evidence of the types or number of memories prompted by those tools. This study is inspired by previous qualitative works fnding that existing tools limit reminiscence in order to begin to quantify how they compare to each other and to potential digital alternatives.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Prompted Memories.</head><p>In this paper, we categorize these prompted memories as being either person-centred or external, as described by <ref type="bibr" target="#b20">[20]</ref>. We use this distinction between person-centred memories (that recount personal experiences) and external ones (that share known facts) to examine the diferences in the types of memories prompted and particularly to highlight the memories that better support continued reminiscence (i.e., person-centred) versus those that are less important to this space (i.e., external). These terms encompass general aspects about memory and so are unafected by the chosen theme of the pictures (i.e., Paris). That is, a memory shared about Paris, about another location, or with an unspecifed location could be either person-centred or external depending on whether that memory included an experience had by the narrator. Table <ref type="table" target="#tab_0">1</ref> shows examples of person-centred and external memories from our participants both with and without previous experiences in Paris.</p><p>In this study, individual participants shared memories with an individual researcher. Although memory sharing is a personal activity, commonly associated with gatherings of friends and families, people also often connect with strangers through storytelling and sharing memories. Which memories are shared may change depending on the audience, but the quantity and type of memories are not seen to be afected by audience <ref type="bibr" target="#b28">[28]</ref>.</p><p>We measure the count of these memories, as well as the number of words in each type of memory, to quantify the efect of digital picture interactions on reminiscence. There are various measures that could be used including number of "plot" points or how well it follows the expected structure of a story. As this research area has not yet been assessed in a controlled way, we use a simple quantifed measure over a qualifed one in order to understand the general efect of these diferent settings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Hypotheses</head><p>We propose the following hypotheses. Based on the physical interactions and research inspiring the tabletop condition, we expect this design to prompt more reminiscence, and specifcally more person-centred memories.</p><p>H1. The tabletop condition will prompt more person-centred memories than the slideshow (H1a) or gallery (H1b) conditions, and those memories will be longer.</p><p>As the slideshow only displays a single picture at a time, which users see as limiting <ref type="bibr" target="#b1">[2]</ref>, we expect that it will prompt short, targeted memories for each picture, which would be seen in more external memories.</p><p>H2. The slideshow condition will prompt more external memories than the tabletop (H2a) or gallery (H2b) conditions, and those memories will be longer.</p><p>The gallery condition is an overview of all pictures, without a clear or complete view of any individual picture, as they are often cropped to ft the grid format. As such, we expect the gallery to perform the worst in terms of reminiscence generally.</p><p>H3. The gallery will prompt fewer memories generally than the tabletop (H3a) or slideshow (H3b) conditions, and those memories will be shorter.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4">Procedure</head><p>The same researcher (the frst author) completed all the interviews. This research was completed fully remotely, as was required by the COVID-19 pandemic restrictions in place at the time. Participants interacted with a website custom-made for this research, while the researcher conducted the interview via a telephone or Zoom audio call. Each interview lasted approximately one hour. The website consisted of two views. First, a participant view with a custom web address that was only active during the interview, second, a researcher view that worked as a mirror of the participant view. This was designed in this way so that participants would not be required to share their screens at any time during the study, which both protects user privacy and confdentiality and the need for extra technical skills that are not necessary for the study. This website included all questionnaires and conditions, and the view was changed to the next screen by the researcher when the participant said they were ready to continue.</p><p>Audio was recorded through the telephone or Zoom call and the screen interactions were recorded on the researcher's screen. Participants were informed ahead of time that the call and screen would be recorded and were sent a link to the survey website at the time of the interview that was active only for the duration of that session. All data were fully anonymized.</p><p>After the participant reviewed the consent form together with the researcher and signed it electronically, the researcher began the recording the interview. interview began with the MDPQ and demographic questionnaires, including their familiarity and use of various pictures tools, both digital and physical. After the questionnaires, the researcher briefy introduced three tasks, explaining that they would all be pictures of Paris, that the participant should take their time to look at the pictures and talk about what they are reminded of from those pictures, and that each picture display would be followed a brief questionnaire.</p><p>condition was introduced to the participant to explain the functionality, including the possible gestures (e.g., to swipe left and right to change pictures on the slideshow or to scroll for the other conditions) and that they could tap on each picture as they discuss it, but this was not necessary. the non-slideshow conditions, tapping added a border to the picture so that the researcher could easily identify which picture was being discussed. Tapping on the current picture is common practice for physical pictures, but the gesture is often overwritten digital platforms, such as a gallery view which will open a full-screen version of the picture. This border display mirrors the physical tapping gesture by drawing attention to the picture without altering the display.</p><p>The participant was free to say and share anything they wanted to, to include or ignore any pictures, and to stop whenever they felt they were ready. If the participant was silent for more than several seconds, the researcher prompted them with a general question. Of the 36 participants, 21 were prompted the researcher. prompts were mostly general and open-ended (e.g., "Do any of the pictures stand out or remind you of anything?" or "Does anything look familiar to your time in Paris?") or following up on what was just mentioned by the participant, for example:</p><p>Participant: "This looks. . . like some church or something to do with the Roman era time? Yeah. I'm not sure. *pause*" Researcher: "Did you see things like that when you were in Paris?". This type of prompting is common to semi-structured interviews to clarify in the participant has more to say and remind of the topic. Across participants, the response to the prompts included a mix of person-centred memories, external memories, and other statements.</p><p>The presented order of the three conditions (gallery, slideshow, and tabletop) and three photo sets (food, landmarks, and culture) were counterbalanced across participants, resulting in 36 possible orders of the three tasks (6 orders of conditions X 6 orders of photo sets). For example, for the condition order slideshow, gallery, tabletop and the photo set order culture, food, landmarks, the participant would see pictures of culture on a slideshow, followed by pictures of food in a gallery, and fnally pictures of landmarks on the tabletop.</p><p>Each condition was followed by the NASA Task Load Index (TLX) questionnaire <ref type="bibr" target="#b12">[13]</ref>. This questionnaire was designed to assess the work required to use a tool across various dimensions (e.g., mental, physical), and was chosen to collect data on how participants perceived the use of these diferent modes of interaction specifcally for storytelling.</p><p>After the participant completed all three conditions, the study ended with a brief interview about their personal preferences across the three options, improvements they could imagine for those tools, and how these compare to their current use of digital picture tools. Participants were then asked if they had any questions or concluding thoughts, and compensation was provided. We do not report on the TLX questionnaires or closing interviews as they are not directly related our research interest here, namely the observed and quantifed efects of design and interaction on reminiscence. They are included in the description of the procedure to allow for replicability and future extensions of this work. Future work will analyze these additional data as they are the subject of a diferent type of analysis and paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>The interviews were transcribed, and the resulting transcripts were coded by the frst two authors (both with experience in reminiscence and memory-based research) for the types of memories shared. The coding process was deductive and consensus-based. We decided to use multiple coders and to measure agreement because the identifcation of where a particular memory begins and ends within the transcript as well as the type of memory can be subjective, can be mitigated through the use of two separate coders <ref type="bibr" target="#b24">[24]</ref>.</p><p>We frst coded four transcripts independently, identifying each memory shared by the participant across the three conditions and initially using codes for episodic and semantic memories. We also coded the other utterances by participants including comments related to the study or technical difculties, which were excluded from all analyses. Technical utterances were about the interface or interview, "It's a slideshow, got it." And "And you're seeing what I'm seeing?". Other utterances were often comments on the photographs themselves (e.g., "I really like the contrast of the photo. It centralizes on the person and the diferent kinds of books. "), comments about the experience of reminiscence (e.g., "It gives me good memories"), or comments to the researcher/audience about the narration or interaction (e.g., "I'm just seeing what else there is" or "I think that's pretty much it. ").</p><p>We then compared the coded transcripts and refned the defnitions of our codes to be person-centred and external, as discussed above, based on memories that were not specifcally referring to a specifc episode, were refecting on personal experience rather than stating a semantic fact. For example, "I didn't actually have that much in the way of baguettes when I was in Paris, surprisingly. I have them here all the time. I have them here at least once a week".</p><p>this point we coded all remaining transcripts separately and compared the resulting agreement using Krippendorf's alpha. We had acceptably high agreement for person-centred (α = 0.843), external (α = 0.836), and overall which included both person-centred external memories (α = 0.680). A score of at least 0.800 shows strong reliability, and a minimum of 0.667 is acceptable reliability for this measure <ref type="bibr" target="#b13">[14]</ref>.</p><p>We then discussed each of the quotes without agreement and determined upon a fnal code by consensus. Some disagreements were over whether a memory was person-centred or external, like long French loaves ... I still buy them now and then, and make with veggies and stuf like that" which was seen as a general comment on the local bread by one coder and a reference to past experiences cooking with those loaves by the other. After discussion, we agreed that there is sufcient reference to their own experience to code it was "person-centred". Another quote, "Cheese boards are always nice to look at" could be seen as semantic knowledge, but was decided to be a general comment and not a memory, so was coded "other".</p><p>Across the 36 transcripts, the fnal coding identifed 345 personcentred memories, 819 external memories, 203 technical utterances, and 382 "other" utterances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">RESULTS</head><p>We investigated whether the memories shared by our participants varied as function of the diferent design condition (gallery, slideshow, and tabletop). Specifcally, our measures of interest included the number of memories, the number of words said, and the average number of words per memory, collected separately for person-centred and external memories. We also look at these measures for all of the shared memories (both person-centred and external combined) to observe any broader efects on memory sharing. We conducted separate one-way analysis of variance (ANOVA) for each of the measures described that our independent factor, design condition, included 3 levels but the comparison of these levels were planned, and as such this did not require the use of correction for multiple comparisons, as per common practice in behavioural experiments, see <ref type="bibr" target="#b0">[1,</ref><ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b30">30,</ref><ref type="bibr" target="#b33">33]</ref>). As assumptions were not always met, we also conducted non-parametric Friedman's test. The pattern of results remained the same, with the exception of the measure of words said in external memories. The larger implications of these results are discussed in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Memory Summary</head><p>The 36 participants shared an overall average of 32.33 memories per interview (SD = 21.10, min = 4, max = 93). An average of 9.58 average, 10.78 memories were shared the tabletop, 14.08 on the slideshow, and 7.47 on the gallery. Of all the coded utterances, 75% were coded memories (either person-centred episodic) and 25% were coded other. Of the words said by participants, 87% were said in memories and 13% in other comments.</p><p>We frst provide descriptive statistics for our diferent measures and across the diferent design conditions to give an overview summary of the memories shared. As shown in Table <ref type="table" target="#tab_1">2</ref>, all conditions saw more external than person-centred memories. Additionally, more words were said in total for external memories than in personcentred ones. However, person-centred memories seem to be on average longer than external ones, as measured by average number of words said per memory. As person-centred memories are often more detailed than external ones, this is expected and shows that all conditions prompted fewer, but longer person-centred memories as well as more, shorter external ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Efect on Number of Memories</head><p>We conducted separate one-way ANOVAs to explore the efect of design condition on person-centred and external memories. The results showed efect of design condition on person-centred memories (p = .065). There was, however, an efect of condition on external memories: F(2, 70) = 7.16, p = .002. We conducted follow-up analyses using paired t-tests, and report efect size using Cohen's d. The results revealed that the slideshow condition prompted signifcantly more external memories than both the tabletop (t(35) = -2.06, p = .047, d = 0.39,) and gallery (t(35) = 3.49, p = .001, d = 0.74,) conditions (see fgure 4 and fgure 5). From the higher frequency of external memories, we can reject the null hypothesis for hypothesis H2 (slideshow external memories &gt; tabletop, slideshow external memories &gt; gallery), and conclude that the slideshow is a stronger prompt for external memories than the gallery or tabletop conditions. Counts of external memories across conditions.</p><p>Next, we conducted a one-way ANOVA on the overall memories (i.e., all memories regardless of type), which also revealed an efect of design condition, F(2, 70)= 7.28, p = .001. Follow-up pairwise comparisons revealed that both the tabletop and slideshow conditions resulted in signifcantly more memories shared than in the gallery, t(35)= 2.30 p = .028, d = 0.43, and t(35) = 3.58, p = .001, d = 0.72, respectively (see fgure 6). From the signifcantly lower rates of memories in the gallery condition as compared to both the slideshow and tabletop conditions, we can reject the null hypothesis for hypothesis H3 (gallery memories &lt; tabletop, gallery memories &lt; slideshow), and conclude that the gallery condition is a weaker prompt for memory sharing than the other conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Efect on Words Spoken in Memories</head><p>We explored number of words spoken in memories, and found that there was an efect of design condition on overall memories: F(2, 70) = 3.69, p = .030. The slideshow condition prompted signifcantly more words in memories than the gallery condition, t(35) = 2.86, p = .007, d = 0.47 (see fgure 7). This further supports hypothesis H3 (gallery &lt; slideshow).  There were no efects of condition on the average words per memory. See table <ref type="table" target="#tab_2">3</ref> for a summary of all the main statistical fndings and related hypotheses.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4">Exploratory Analyses: Picture Subthemes and Prior Travel Experience</head><p>To see whether the diferent subthemes of pictures had any efect on the resulting memories by any of these measures, we separate one-way ANOVAs and confrmed that there was no signifcant efect by on of the measures; all p's &gt; .05.</p><p>Recall that the pictures were all selected from stock photography of Paris, France, and that we asked participant whether or not they had visited Paris, which allowed us to explore whether this factor infuenced the results of our analyses. This is not the focus on this work, as previous works have shown that generic pictures and travel pictures are strong memory prompts, so we include this exploration as a brief view into any potential efect. This was accomplished by adding visit Paris (yes/no) into the model as a between-subject factor. We repeated all the analyses presented earlier with this additional factor. The results revealed no signifcant efect of this factor or any interaction with the design condition factor; all p's &gt; .05. However, due to the unbalanced sample sizes in the two levels of this factor, we are cautious in interpreting these results and we suggest future research should further explore this with a more balanced sample.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">DISCUSSION AND INTERPRETATION OF RESULTS</head><p>The current study presents an empirical exploration of the efects of the design of digital picture interactions on the type of memories that they prompt. We chose a controlled setting in order observe those efects more directly. are specifcally with regards to the memory-prompting efects of the chosen designs (gallery, slideshow, and tabletop). How we access pictures is an important factor in how we can then access and share our memories, so understanding the connection between picture viewing and reminiscence in a digital space is crucial. This efect of digital design and interaction on memory prompting has not been previously assessed in a controlled setting, as such all these fndings expand our understanding of our interactions with digital pictures.</p><p>In particular, several of our fndings parallel what has been found in qualitative works across the past 20 years of HCI research, such as that a long scrolling gallery of pictures is not an efective memory prompt <ref type="bibr" target="#b7">[8]</ref>, and our motivation is precisely to begin quantify these observations. Our results show that common interactions do not seem to be intended to support reminiscence, unlike traditional physical interactions with paper pictures. The digital tabletop, which is drawn directly from those physical interactions, does not show the same reminiscence shortcomings of the other designs.</p><p>The gallery is signifcantly less efective as a prompt for remi-Both the tabletop and slideshow prompted more memory sharing than the gallery, and the slideshow further prompted more words in memories. This is likely due to the gallery's small picture size and often-cropped display (as all pictures are presented as squares regardless of original picture ratio). This limits how much detail a person is able to see in a picture, and therefore the degree to which memories can be prompted. The slideshow provides a clear display of a single picture, which creates a stronger prompt for memories than the many small icons of the gallery. However, more of the memories prompted by the slideshow are external, as we discuss below. The tabletop shows the full detail of each picture while maintaining the visual context across diferent pictures, providing a strong prompt for memories overall, as compared to the gallery, without prompting more external memories.</p><p>The slideshow condition was seen to prompt more external memories than both the gallery and tabletop conditions. Past research has shown that users see the slideshow as limiting due the lack of user control <ref type="bibr" target="#b1">[2]</ref>. By design, the slideshow presents only a single picture at a time, providing no displayed context between the pictures (as has been found to be an important aspect of sharing memories socially from pictures <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref>). The combined lack of user control and lack of visual context is likely why the format prompts more of the briefer, factual memories, but does not prompt more richer person-centred ones, which may be more easily prompted by seeing several related pictures together. There was no observed efect on number of words shared in external memories specifcally, perhaps because they are generally shorter memories, so the cumulative efect is not as large.</p><p>Of the available designs, the slideshow is the stronger prompt for memories overall. The pictures on the gallery are too small to be efective prompts, whereas the slideshow displays pictures as large as possible making the contents of the picture clear. The strength of the slideshow as it prompts reminiscence (i.e., relating personal experiences) is not clear, as it was seen to prompt more memories external to personal experience, but had no efect on person-centred memories. Future work should further explore these benefts and limitations of the slideshow for memory sharing and particularly how to create a better prompt for person-centred memories from this familiar setting.</p><p>The tabletop prompts fewer external memories than the slideshow, but not fewer memories overall. This is in contrast to the gallery, which compared to the slideshow prompted both fewer memories overall and fewer external memories. This demonstrates that the tabletop can prompt memories generally at least as well as the familiar slideshow, but without an increase in external memories, showing that it can prompt both external and personcentred memories. We suggest that the aspects physical picture interactions that are represented in the digital tabletop design are successful in prompting more memories overall than some digital options (e.g., the gallery), without emphasizing the brief, external, factual memories over the person-centred ones that refect personal episodes and experiences. The tabletop provides a similar level of visual picture detail as the slideshow, which also provides a stronger prompt than the limited detail of the gallery. However, unlike the slideshow, the tabletop always shows other related pictures as well, providing the context across pictures that could provide a richer prompt for person-centred memories, such as a detailed memory from personal experience.</p><p>this, there were no signifcant results with regards to person-centred memories. It is possible that this was due to the controlled setting of this study, including the generic pictures, researcher as the audience, and the relatively short duration. However, past research has shown that generic pictures and researcher as audience does not limit person-centred memory sharing, as compared to personal pictures and family or friends as audience <ref type="bibr" target="#b2">[3,</ref><ref type="bibr" target="#b28">28]</ref>. Person-centred memories are generally longer and more detailed than external memories, so it is possible that longer reminiscence session would be needed to observe a diference between conditions (particularly between the existing slideshow and gallery), either through a longer single interview or repeated interviews to allow participants the time to share more longer stories.</p><p>Overall, how digital pictures are displayed and interacted with clearly has some efect on the number of memories prompted by those interactions as well as the type of memory prompted. Given the essential role of reminiscence within picture interactions and the strength of pictures as a prompt for reminiscence, designers should be intentionally considering how memory sharing will be encouraged, or not, by an interaction. Gallery views, which limit access to detailed pictures and the broader picture context through the small, cropped picture tiles, also limit reminiscence and should not be the only or primary way to browse large sets of pictures. While browsing in a gallery view, pictures often need to be opened to full screen before they can be recognized, the fow of browsing as well as limiting the potential for reminiscence.</p><p>A slideshow is an efective way to prompt brief, factual memories, but showing only one picture at a time without contextualized browsing across a larger set may limit person-centred reminiscence, which is in line with previous work as well <ref type="bibr" target="#b1">[2]</ref>. For example, the pictures are in a hard order that cannot be seen while viewing the slideshow, so the next and previous pictures are often unknown. Slideshow interactions do not support spontaneous reminiscence that pulls up pictures to share without frst curating a subset from a large collection, but in contrast to the gallery is the available option to view a complete picture in detail, providing the strongest available option for reminiscence.</p><p>All of the conditions prompt more, shorter external memories and fewer, longer person-centred ones. However, this is the frst work to assess these diferences directly, and these results do not clearly show an interaction that is better at reminiscence over the others. Both the gallery and slideshow have some limitations in how they prompt memories. The slideshow is the best of the available as the stronger prompt of memories overall. The tabletop did prompt more memories overall than the gallery without prompting more person-centred ones (as the slideshow did). Given this importance of person-centred memories to reminiscence and the strong efect of the slideshow on external memories, we propose that the tabletop is a better digital interaction for reminiscence than common existing options, and is further evidence for the qualitative fndings of past works <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b7">8]</ref> indicating that ease of access to pictures along with broader picture context are key to memory prompting. These features are central to the tabletop design and the physical interactions it draws from, but they are currently lacking from digital tools. Further work is needed to better understand the diferences between the tabletop and slideshow views, particularly as they prompt person-centred For the moment, as slideshow and gallery views are functionally the only two available methods of digital picture interaction, other designs need to be explored implemented in order to bring reminiscence back into picture interactions, as they have been in analog, paper-based settings for 200 years <ref type="bibr" target="#b31">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Limitations and Future Work</head><p>This is, to our knowledge, frst controlled exploration of the potential efects of design and interaction with digital pictures on memory prompting and sharing. As there is not a pre-existing understanding of how interaction afects memory prompting, we have chosen a controlled setting and present interesting fndings that allows for future work to move ahead with a clearer direction for picture interactions.</p><p>Due to the novelty of this work within the feld of HCI, we choose to focus on the quantity and type of memories, and to not include a measure of memory quality, in order to present an overview of the efects of digital design and interaction on reminiscence. Quality of memory is subjective and can be measured in a variety of ways depending on the question being investigated, such as scales applied by either a researcher or the narrator scale <ref type="bibr" target="#b39">[39]</ref>. Future work can build on our fndings to explore this aspect of memory in digital spaces.</p><p>In this study, all participants saw the same stock photography, and there is evidence that generic pictures prompt as well or even better than personal pictures <ref type="bibr" target="#b2">[3]</ref>. As such, we chose this more controlled and counterbalanced approach so that any observed efects would be more clearly due to the design rather than the ability of those pictures to prompt memories over another set. With this frst study completed, our future work will expand on these fndings to explore the efects of memory sharing from personal digital pictures. Additionally, the Paris theme was chosen for the pictures in order to provide a consistent and largely familiar prompt for memories, including a larger visual context across the pictures. We do not see any efect of having visited Paris in this data, though the sample is very unbalanced for that factor and future work can directly investigate those efects on how digital interfaces prompt memory. We did not structure the study to explore this question, as diferent participants had more or less personal experience with Paris, regardless of whether or not they had visited themselves. Although these diferences could afect reminiscence, most people would have had some experience with the scenes in Paris whether directly or indirectly. Future research with a larger and a more balanced sample size could further explore how experience can play a role in the memories prompted by pictures.</p><p>Participants were asked to share memories with a researcher rather than with family or friends, which will have impacted which of their memories they shared. However, quantity of reminiscence and memory sharing, as well as type of memory, are not limited by audience <ref type="bibr" target="#b28">[28]</ref>. People will generally share memories with any audience, and will simply choose which memories are appropriate to share depending on that audience. The researcher, an outsider to the participants' experiences, did not actively engage in storytelling beyond as an attentive audience. As such, this work has not focused on the collaborative aspect of family reminiscence, such as that seen by Jones and Ackerman <ref type="bibr" target="#b15">[16]</ref> and <ref type="bibr">Liaqat et [21]</ref>. This choice was in order to control the setting of this study, and our future work will actively engage with families and communities to include the collaborative nature of reminiscence.</p><p>Finally, we have chosen to focus on a part of the picture and memory sharing processes, excluding in particular the browsing and selection of pictures. Future work will incorporate these fndings into more all-encompassing digital picture tools in order to understand the implications on the process as a whole.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">CONCLUSION</head><p>We present the efects of the designs of digital picture interactions on memory sharing through a controlled study using stock pictures and a within-user design. We fnd that interaction designs afect the quantity and type of memories shared, which has implications for people's interactions with pictures in digital spaces. The results show that the common gallery display of pictures is not conducive to memory sharing, and the slideshow, though it is a better prompt than the gallery, prompts more external memories without prompting more of the person-centred memories that are important to reminiscence. The novel tabletop design prompts more memories overall than the gallery and fewer external memories than the slideshow, but also does not have any efect on personcentred memories. It is not clear what type of digital interaction would best prompt person-centred memories, and therefore support reminiscence. Drawing from the limitations of the gallery and slideshow, there is some indication that the tabletop, directly inspired by traditional interactions with paper-based pictures, could be a better source of memory prompts overall, including personcentred memories, than either of the other conditions.</p><p>Our results here suggest that available tools need to be augmented to include designs that intentionally support and prompt reminiscence. Common, available options are not supporting these activities and our future work will continue to explore what better supports these crucial interactions. The implications of these results will improve the overall usability of digital picture interactions by including reminiscence activities alongside the broad range of picture activities already available in digital spaces. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 4 :</head><label>4</label><figDesc>Figure 4: Counts of person-centred memories across conditions.</figDesc><graphic url="image-4.png" coords="7,355.39,83.69,165.38,187.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 6 :</head><label>6</label><figDesc>Figure 6: Counts of memories across conditions.</figDesc><graphic url="image-7.png" coords="8,355.39,470.80,165.38,187.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Examples of person-centred and external memories</figDesc><table><row><cell>Type of Memory</cell><cell>Memory Examples with Paris Experience</cell><cell>Memory Examples without Paris Experience</cell></row><row><cell>Person-Centred</cell><cell>"The building itself reminds me of when I was</cell><cell>"Reminds me of a time I was in Chicago with the good</cell></row><row><cell></cell><cell>walking through at night to go back to my hotel"</cell><cell>little bike stalls and rent bikes and go around the city with</cell></row><row><cell></cell><cell>"That one, with the tower lit up, that actually reminds</cell><cell>them. The hard part was trying to fnd where to put the</cell></row><row><cell></cell><cell>me more of when we took the pictures because it was</cell><cell>bike back afterwards"</cell></row><row><cell></cell><cell>in the night time. "</cell><cell>"I would say this market just shopping in it reminds me of</cell></row><row><cell></cell><cell></cell><cell>just shopping in my country where I grew up, all the</cell></row><row><cell></cell><cell></cell><cell>buying from the local farmers"</cell></row><row><cell>External</cell><cell>"This is the view from underneath the base of the</cell><cell>"A statue. Just like in Ottawa or something. "</cell></row><row><cell></cell><cell>Eifel Tower. "</cell><cell>"It's a very nice winter morning. It's not a lot of snow, but</cell></row><row><cell></cell><cell>"This is the Mona Lisa. There it is. "</cell><cell>on the outsides, you can see people walking. "</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>Means (and SDs) of counts, words, and average words per memory overall, and by person-centered external memories, across conditions</figDesc><table><row><cell>Measure</cell><cell>Overall</cell><cell>Tabletop</cell><cell>Slideshow</cell><cell>Gallery</cell></row><row><cell>Memories</cell><cell>32.33 (21.10)</cell><cell>10.78 (9.36)</cell><cell>14.08 (11.81)</cell><cell>7.47 (5.16)</cell></row><row><cell>Person-Centred</cell><cell>9.58 (9.65)</cell><cell>3.50 (4.22)</cell><cell>3.72 (4.63)</cell><cell>2.36 (2.23)</cell></row><row><cell>External</cell><cell>22.75 (14.99)</cell><cell>7.28 (6.61)</cell><cell>10.36 (8.79)</cell><cell>5.11 (4.70)</cell></row><row><cell>Words</cell><cell>1092.92 (1226.58)</cell><cell>377.81 (575.68)</cell><cell>460.00 (552.14)</cell><cell>255.11 (259.04)</cell></row><row><cell>Person-Centred</cell><cell>450.31 (631.01)</cell><cell>154.42 (239.17)</cell><cell>192.97 (324.51)</cell><cell>102.92 (130.01)</cell></row><row><cell>External</cell><cell>642.61 (771.98)</cell><cell>223.39 (416.49)</cell><cell>267.03 (322.59)</cell><cell>152.19 (198.71)</cell></row><row><cell>Average Words per</cell><cell>29.02 (15.92)</cell><cell>29.10 (16.66)</cell><cell>27.93 (17.67)</cell><cell>32.26 (21.66)</cell></row><row><cell>Person-Centred</cell><cell>(21.95)</cell><cell>31.46 (27.71)</cell><cell>31.27 (28.43)</cell><cell>27.83 (25.66)</cell></row><row><cell>External</cell><cell>24.60 (14.16)</cell><cell>23.25 (14.66)</cell><cell>23.63 (14.65)</cell><cell>27.18 (23.17)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 :</head><label>3</label><figDesc>Summary of statistical fndings and related hypotheses</figDesc><table><row><cell>Measure</cell><cell>Finding</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 :</head><label>4</label><figDesc>Participant demographic information</figDesc><table><row><cell>Age</cell><cell>Gender</cell><cell>Device</cell><cell>MDPQ Score</cell></row><row><cell>38</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>33.76</cell></row><row><cell>35</cell><cell>Man</cell><cell>Apple iPad</cell><cell>39.50</cell></row><row><cell>27</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>40.00</cell></row><row><cell>29</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>38.89</cell></row><row><cell>40</cell><cell>Woman</cell><cell>Windows tablet</cell><cell>40.00</cell></row><row><cell>28</cell><cell>Man</cell><cell>Apple iPad</cell><cell>37.61</cell></row><row><cell>19</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>39.33</cell></row><row><cell>37</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>40.00</cell></row><row><cell>24</cell><cell>Man</cell><cell>Windows laptop</cell><cell>39.65</cell></row><row><cell>23</cell><cell>Man</cell><cell>Apple iPad</cell><cell>38.54</cell></row><row><cell>39</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>36.82</cell></row><row><cell>28</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>39.63</cell></row><row><cell>24</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>40.00</cell></row><row><cell>37</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>37.54</cell></row><row><cell>21</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>33.12</cell></row><row><cell>26</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>39.44</cell></row><row><cell>22</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>37.10</cell></row><row><cell>62</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>28.00</cell></row><row><cell>24</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>31.87</cell></row><row><cell>61</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>39.25</cell></row><row><cell>51</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>37.75</cell></row><row><cell>28</cell><cell>Man</cell><cell>Apple iPad</cell><cell>37.64</cell></row><row><cell>36</cell><cell>Man</cell><cell>Apple iPad</cell><cell>39.33</cell></row><row><cell>22</cell><cell>Man</cell><cell>Apple iPad</cell><cell>40.00</cell></row><row><cell>40</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>36.23</cell></row><row><cell>56</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>39.00</cell></row><row><cell>29</cell><cell>Man</cell><cell>Windows laptop</cell><cell>39.88</cell></row><row><cell>34</cell><cell>Man</cell><cell>Windows laptop</cell><cell>40.00</cell></row><row><cell>42</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>40.00</cell></row><row><cell>49</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>34.23</cell></row><row><cell>42</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>33.50</cell></row><row><cell>50</cell><cell>Man</cell><cell>Windows tablet</cell><cell>37.79</cell></row><row><cell>40</cell><cell>Woman</cell><cell>Apple iPad</cell><cell>38.96</cell></row><row><cell>59</cell><cell>Man</cell><cell>Apple iPad</cell><cell>36.14</cell></row><row><cell>58</cell><cell>Woman</cell><cell>Kindle tablet</cell><cell>37.80</cell></row><row><cell>47</cell><cell>Woman</cell><cell>Windows laptop</cell><cell>23.95</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACKNOWLEDGMENTS</head><p>This work was supported by AGE-WELL NCE Inc., a member of the Networks of Centres of Excellence (NCE), a Government of Canada program supporting research, networking, commercialization, knowledge mobilization and capacity activities in technology and ageing to improve the quality of lives of Canadians. The authors also wish to acknowledge the sacred on which the University of Toronto operates. These lands are the traditional territories of the Huron-Wendat and Petun First Nations, the Seneca, the Haudenosaunee, and most recently, the Mississaugas of the Credit River. Today, the meeting place of Tkaronto is still the home to many Indigenous people from across Turtle Island, and we are grateful to have the opportunity to work in the community, on this territory.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Adjust for multiple comparisons? It&apos;s not that simple. The Annals of thoracic surgery</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">D</forename><surname>Althouse</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.athoracsur.2015.11.024</idno>
		<ptr target="https://doi.org/10.1016/j.athoracsur.2015.11.024" />
		<imprint>
			<date type="published" when="2016">2016. 2016</date>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="1644" to="1645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Requirements for mobile photoware. and Ubiquitous Computing</title>
		<author>
			<persName><forename type="first">Morgan</forename><surname>Ames</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dean</forename><surname>Eckles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mor</forename><surname>Naaman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mirjana</forename><surname>Spasojevic</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nancy</forename><surname>House</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00779-009-0237-4</idno>
		<ptr target="https://doi.org/10.1007/s00779-009-0237-4" />
		<imprint>
			<date type="published" when="2010">2010. 2010</date>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="95" to="109" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Stimulating people with dementia to reminisce using personal and generic photographs</title>
		<author>
			<persName><forename type="first">Arlene</forename><forename type="middle">J</forename><surname>Astell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Maggie</forename><forename type="middle">P</forename><surname>Ellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Norman</forename><surname>Alm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><surname>Dye</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gary</forename><surname>Gowans</surname></persName>
		</author>
		<idno type="DOI">10.1504/IJCIH.2010.037461</idno>
		<ptr target="https://doi.org/10.1504/IJCIH.2010.037461" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Computers in Healthcare</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2010-01">2010. January 177-198</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">PhotoFlow Action: Picture-Mediated Reminiscence Supporting Family Socio-Connectivity</title>
		<author>
			<persName><forename type="first">Benett</forename><surname>Axtell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmin</forename><surname>Munteanu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290607.3313272</idno>
		<ptr target="https://doi.org/10.1145/3290607.3313272" />
	</analytic>
	<monogr>
		<title level="m">Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems, ACM, INT050</title>
				<imprint>
			<date type="published" when="2019">2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A personal perspective on photowork: implicit human-computer interaction for photo collection management. Personal and ubiquitous computing</title>
		<author>
			<persName><forename type="first">Bojan</forename><surname>Blažica</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Vladušič</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Dunja</forename><surname>Mladenić</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00779-013-0650-6</idno>
		<ptr target="https://doi.org/10.1007/s00779-013-0650-6" />
		<imprint>
			<date type="published" when="2013">2013. 2013</date>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="1787" to="1795" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Tell It Like It Really Is&quot;: A Case of Online Creation and Sharing Among Older Adult</title>
		<author>
			<persName><forename type="first">Robin</forename><surname>Brewer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anne</forename><forename type="middle">Marie</forename><surname>Piper</surname></persName>
		</author>
		<idno type="DOI">10.1145/2858036.2858379</idno>
		<ptr target="https://doi.org/10.1145/2858036.2858379" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems (CHI &apos;16)</title>
				<meeting>the 2016 CHI Conference on Human Factors in Computing Systems (CHI &apos;16)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2016">2016</date>
			<biblScope unit="page" from="5529" to="5542" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">From PhotoWork PhotoUse: exploring personal digital photo activities</title>
		<author>
			<persName><forename type="first">Mendel</forename><surname>Broekhuijsen</surname></persName>
		</author>
		<idno type="DOI">10.1080/0144929X.2017.1288266</idno>
		<ptr target="https://doi.org/10.1080/0144929X.2017.1288266" />
	</analytic>
	<monogr>
		<title level="j">Behaviour &amp; Information Technology</title>
		<imprint>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
	<note>Elise van den Hoven, and Panos Markopoulos</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Design Directions for Media-Supported Collocated Remembering Practices</title>
		<author>
			<persName><forename type="first">Mendel</forename><surname>Broekhuijsen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elise</forename><surname>Van Den Hoven</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Panos</forename><surname>Markopoulos</surname></persName>
		</author>
		<idno type="DOI">10.1145/3024969.3024996</idno>
		<ptr target="https://doi.org/10.1145/3024969.3024996" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction (TEI &apos;17)</title>
				<meeting>the Eleventh International Conference on Tangible, Embedded, and Embodied Interaction (TEI &apos;17)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2017">2017</date>
			<biblScope unit="page" from="21" to="30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Snapshot versions of life</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Chalfen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1987">1987</date>
			<publisher>University of Wisconsin Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Interpreting family photography as pictorial communication. Image-based research: A sourcebook qualitative researchers</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Chalfen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998">1998. 1998</date>
			<biblScope unit="page" from="214" to="234" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">PhotoMagnets: Supporting Flexible Browsing and Searching in Photo Collections</title>
		<author>
			<persName><forename type="first">Ya-Xi</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Reiter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andreas</forename><surname>Butz</surname></persName>
		</author>
		<idno type="DOI">10.1145/1891903.1891936</idno>
		<ptr target="https://doi.org/10.1145/1891903.1891936" />
	</analytic>
	<monogr>
		<title level="m">International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010">2010</date>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1" to="25" />
		</imprint>
	</monogr>
	<note type="report_type">ICMI-MLMI &apos;10</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Abbe Don, and Steven Ariss</title>
		<author>
			<persName><forename type="first">David</forename><surname>Frohlich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allan</forename><surname>Kuchinsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Celine</forename><surname>Pering</surname></persName>
		</author>
		<idno type="DOI">10.1145/587078.587102</idno>
		<ptr target="https://doi.org/10.1145/587078.587102" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2002 ACM conference on Computer supported cooperative work</title>
				<meeting>the 2002 ACM conference on Computer supported cooperative work</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2002">2002</date>
			<biblScope unit="page" from="166" to="175" />
		</imprint>
	</monogr>
	<note>Requirements for photoware</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research</title>
		<author>
			<persName><forename type="first">Sandra</forename><forename type="middle">G</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Lowell</forename><forename type="middle">E</forename><surname>Staveland</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0166-4115(08)62386-9</idno>
		<idno>S0166-4115(08)62386-9</idno>
		<ptr target="https://doi.org/10.1016/" />
	</analytic>
	<monogr>
		<title level="m">Advances in psychology</title>
				<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="1988">1988</date>
			<biblScope unit="page" from="139" to="183" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Answering the Call for a Standard Reliability Measure for Coding Data</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">F</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Klaus</forename><surname>Krippendorf</surname></persName>
		</author>
		<idno type="DOI">10.1080/19312450709336664</idno>
		<ptr target="https://doi.org/10.1080/19312450709336664" />
	</analytic>
	<monogr>
		<title level="j">Communication Methods and Measures</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="77" to="89" />
			<date type="published" when="2007-04">2007. April 2007</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">1 Error Rates</title>
		<author>
			<persName><forename type="first">C</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Howell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistical methods for psychology. Cengage Learning</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="volume">12</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Co-constructing Family Memory: Understanding the Intergenerational Practices of Passing on Family Stories</title>
		<author>
			<persName><forename type="first">Jasmine</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><forename type="middle">S</forename><surname>Ackerman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018">2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<idno type="DOI">10.1145/3173574.3173998</idno>
		<ptr target="https://doi.org/10.1145/3173574.3173998" />
		<title level="m">Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems -CHI &apos;18</title>
				<meeting>the 2018 CHI Conference on Human Factors in Computing Systems -CHI &apos;18<address><addrLine>Montreal QC, Canada</addrLine></address></meeting>
		<imprint>
			<publisher>ACM Press</publisher>
			<biblScope unit="page" from="1" to="13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Multi-Dimensional Model for Personal Photo Browsing</title>
		<author>
			<persName><forename type="first">Grímur</forename><surname>Björn Þór Jónsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hlynur</forename><surname>Tómasson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Áslaug</forename><surname>Sigurþórsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Eiríksdóttir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marta</forename><forename type="middle">Kristín</forename><surname>Amsaleg</surname></persName>
		</author>
		<author>
			<persName><surname>Lárusdóttir</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-14442-9_41</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-14442-9_41" />
	</analytic>
	<monogr>
		<title level="m">MultiMedia Modeling</title>
		<title level="s">Lecture Notes in Computer Science</title>
		<meeting><address><addrLine>Cham</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015">2015</date>
			<biblScope unit="page" from="345" to="356" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName><forename type="first">Emily</forename><surname>Keightley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Pickering</surname></persName>
		</author>
		<idno type="DOI">10.1177/1461444814532062</idno>
		<ptr target="https://doi.org/10.1177/1461444814532062" />
		<title level="m">Technologies of memory: Practices of remembering in analogue and digital photography. new media &amp; society</title>
				<imprint>
			<date type="published" when="2014">2014. 2014</date>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="576" to="593" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Understanding photowork</title>
		<author>
			<persName><forename type="first">David</forename><surname>Kirk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Abigail</forename><surname>Sellen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carsten</forename><surname>Rother</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ken</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1145/1124772.1124885</idno>
		<ptr target="https://doi.org/10.1145/1124772.1124885" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the SIGCHI conference on Human Factors in computing systems</title>
				<meeting>the SIGCHI conference on Human Factors in computing systems</meeting>
		<imprint>
			<publisher>ACM</publisher>
			<biblScope unit="page" from="761" to="770" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Aging and autobiographical memory: Dissociating episodic from semantic retrieval</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eva</forename><surname>Svoboda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Janine</forename><forename type="middle">F</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gordon</forename><surname>Winocur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morris</forename><surname>Moscovitch</surname></persName>
		</author>
		<idno type="DOI">10.1037/0882-7974.17.4.677</idno>
		<ptr target="https://doi.org/10.1037/0882-7974.17.4.677" />
	</analytic>
	<monogr>
		<title level="j">Psychology and Aging</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="677" to="689" />
			<date type="published" when="2002">2002. 2002</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Participatory Design for Intergenerational Culture Exchange in Immigrant Families: How Collaborative Narration and Creation Fosters Democratic Engagement</title>
		<author>
			<persName><forename type="first">Amna</forename><surname>Liaqat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Benett</forename><surname>Axtell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Cosmin</forename><surname>Munteanu</surname></persName>
		</author>
		<idno type="DOI">10.1145/3449172</idno>
		<ptr target="https://doi.org/10.1145/3449172" />
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">40</biblScope>
			<date type="published" when="2021-04">2021. April 2021</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Before I forget: From personal memory to family history</title>
		<author>
			<persName><forename type="first">E</forename><surname>Siân</surname></persName>
		</author>
		<author>
			<persName><surname>Lindley</surname></persName>
		</author>
		<idno type="DOI">10.1080/07370024.2012.656065</idno>
		<ptr target="https://doi.org/10.1080/07370024.2012.656065" />
	</analytic>
	<monogr>
		<title level="j">Interaction</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="13" to="36" />
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Designing Appropriate Afordances for Electronic Photo Sharing Media</title>
		<author>
			<persName><forename type="first">Siân</forename><surname>Lindley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrew</forename></persName>
		</author>
		<idno type="DOI">10.1145/1125451.1125648</idno>
		<ptr target="https://doi.org/10.1145/1125451.1125648" />
	</analytic>
	<monogr>
		<title level="m">CHI &apos;06 Extended Abstracts on Human Factors in Computing Systems (CHI EA &apos;06)</title>
				<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006">2006</date>
			<biblScope unit="page" from="1031" to="1036" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reliability and Inter-rater Reliability in Qualitative Research: Norms and Guidelines for CSCW and HCI Practice</title>
		<author>
			<persName><forename type="first">Nora</forename><surname>Mcdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sarita</forename><surname>Schoenebeck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Andrea</forename><surname>Forte</surname></persName>
		</author>
		<idno type="DOI">10.1145/3359174</idno>
		<ptr target="https://doi.org/10.1145/3359174" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer</title>
		<imprint>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Efectiveness of follow-up reminiscence therapy on autobiographical memory in pathological ageing</title>
		<author>
			<persName><forename type="first">Juan</forename><forename type="middle">C</forename><surname>Melendez</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rita</forename><surname>Torres</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Teresa</forename><surname>Redondo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alicia</forename><surname>Mayordomo</surname></persName>
		</author>
		<author>
			<persName><surname>Sales</surname></persName>
		</author>
		<idno type="DOI">10.1002/ijop.12217</idno>
		<ptr target="https://doi.org/10.1002/ijop.12217" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Psychology</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="283" to="290" />
			<date type="published" when="2017">2017. 2017</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Evaluation of card-based versus device-based reminiscing using photographic images</title>
		<author>
			<persName><forename type="first">Maurice</forename><surname>Mulvenna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laura</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terence</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Topping</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Karl</forename><surname>Boyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Suzanne</forename><surname>Martin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-03">2011. March 2011</date>
			<biblScope unit="page" from="57" to="66" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Intelligent Photo Management System Enhancing Browsing Experience</title>
		<author>
			<persName><forename type="first">Yuki</forename><surname>Orii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Takayuki</forename><surname>Nozawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Toshiyuki</forename><surname>Kondo</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-642-02559-4_48</idno>
		<ptr target="https://doi.org/10.1007/978-3-642-02559-4_48" />
	</analytic>
	<monogr>
		<title level="m">Symposium on Human Interface</title>
				<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009">2009</date>
			<biblScope unit="page" from="439" to="447" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">11 Beyond Aging: The Practice of Narrative Care in Gerontology</title>
		<author>
			<persName><forename type="first">Bill</forename><surname>Randall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adult education and health</title>
		<imprint>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A new tool for assessing mobile device profciency in older adults: the mobile device profciency questionnaire</title>
		<author>
			<persName><forename type="first">A</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Walter</forename><forename type="middle">R</forename><surname>Roque</surname></persName>
		</author>
		<author>
			<persName><surname>Boot</surname></persName>
		</author>
		<idno type="DOI">10.1177/0733464816642582</idno>
		<ptr target="https://doi.org/10.1177/0733464816642582" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Gerontology</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="131" to="156" />
			<date type="published" when="2018">2018. 2018</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">No adjustments are needed for multiple comparisons</title>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">J</forename><surname>Rothman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Epidemiology</title>
		<imprint>
			<biblScope unit="page" from="43" to="46" />
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">From Snapshots to Social Media -The Changing Picture of Domestic Photography</title>
		<author>
			<persName><forename type="first">Risto</forename><surname>Sarvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Frohlich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The Future of Domestic Photography. In From Snapshots to Social Media -The Changing Picture of Domestic Photography</title>
		<author>
			<persName><forename type="first">Risto</forename><surname>Sarvas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Frohlich</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011">2011</date>
			<publisher>Springer</publisher>
			<biblScope unit="page" from="139" to="177" />
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Multiple comparison procedures: the practical solution</title>
		<author>
			<persName><forename type="first">Dave</forename><forename type="middle">J</forename><surname>Saville</surname></persName>
		</author>
		<idno type="DOI">10.1080/00031305.1990.10475712</idno>
		<ptr target="https://doi.org/10.1080/00031305.1990.10475712" />
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="174" to="180" />
			<date type="published" when="1990">1990. 1990</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">How teens take, view, share, and store photos</title>
		<author>
			<persName><forename type="first">Diane</forename><forename type="middle">J</forename><surname>Schiano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Coreena</forename><forename type="middle">P</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ellen</forename><surname>Isaacs</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002">2002. 2002</date>
			<publisher>CSCW Interactive Poster</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">How to do better with gender on surveys: a guide for HCI researchers</title>
		<author>
			<persName><forename type="first">Katta</forename><surname>Spiel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Oliver</forename><forename type="middle">L</forename><surname>Haimson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Danielle</forename><surname>Lottridge</surname></persName>
		</author>
		<idno type="DOI">10.1145/3338283</idno>
		<ptr target="https://doi.org/10.1145/3338283" />
	</analytic>
	<monogr>
		<title level="j">Interactions</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="62" to="65" />
			<date type="published" when="2019">2019. 2019</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Camera Phone Sales Surge to 257 Million Units Worldwide in 2004</title>
		<ptr target="https://www4.strategyanalytics.com/default.aspx?mod=pressreleaseviewer&amp;a0=2354" />
	</analytic>
	<monogr>
		<title level="m">Strategy Analytics</title>
				<imprint>
			<date type="published" when="2005-08-27">2005. August 27</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Unearthing the family gems: design requirements for a digital reminiscing system for older adults</title>
		<author>
			<persName><forename type="first">Elizabeth</forename><surname>Thiry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><forename type="middle">Beth</forename><surname>Rosson</surname></persName>
		</author>
		<idno type="DOI">10.1145/2212776.2223698</idno>
		<ptr target="https://doi.org/10.1145/2212776.2223698" />
	</analytic>
	<monogr>
		<title level="m">CHI&apos;12 Extended Abstracts on Human Factors in Computing Systems, ACM</title>
				<imprint>
			<date type="published" when="2012">2012</date>
			<biblScope unit="page" from="1715" to="1720" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Easy on that dad: a study of long term family photo retrieval</title>
		<author>
			<persName><forename type="first">Steve</forename><surname>Whittaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ofer</forename><surname>Bergman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><surname>Clough</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00779-009-0218-7</idno>
		<ptr target="https://doi.org/10.1007/s00779-009-0218-7" />
	</analytic>
	<monogr>
		<title level="j">Personal and Ubiquitous Computing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="31" to="43" />
			<date type="published" when="2010">2010. 2010</date>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Episodic and Semantic Autobiographical Memory and Everyday Memory during Late Childhood and Early Adolescence</title>
		<author>
			<persName><forename type="first">Karen</forename><surname>Willoughby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mary</forename><surname>Desrocher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Brian</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Joanne</forename><surname>Rovet</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2012.00053</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2012.00053" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">53</biblScope>
			<date type="published" when="2012">2012. 2012</date>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
