{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a54d2c62-72a7-4b49-87c6-25be69dbe9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f59ab9-014b-4cc9-b5f8-f7df4cf638d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_path = \"data/labels.json\"\n",
    "\n",
    "with open(quotes_path) as f :\n",
    "    \n",
    "    quotes_dict = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cd99425-3f3d-49ab-8876-5ee461605eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest_timestamp_limit = 1332375612 # 22/3/2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67e0cd05-f81a-412d-aebd-74e500b7a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(start_time, end_time, output_dir) : \n",
    "\n",
    "\tstart_time = time.strftime(\"%Y%m%d%H%M%S\",  time.localtime(start_time))\n",
    "\tend_time = time.strftime(\"%Y%m%d%H%M%S\",  time.localtime(end_time))\n",
    "\treturn os.path.join(output_dir , \"{}_{}.json\".format(start_time, end_time))\n",
    "\n",
    "def save_to_file(start_time, end_time, string_list, output_dir='data') : \n",
    "\n",
    "\tfilename = get_filename(start_time, end_time, output_dir)\n",
    "\n",
    "\twith open(filename, 'w') as f : \n",
    "\t\tjson.dump(string_list, f)\n",
    "\n",
    "\treturn True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b638bd8c-53c9-43e4-ae7b-eb0fa2c1a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_submission(submission) :\n",
    "\tattributes = ('url', 'upvote_ratio', 'title', 'subreddit', 'selftext', 'score', 'num_comments', 'created', 'created_utc', 'author', 'full_link')\n",
    "\tparsed = {}\n",
    "\n",
    "\tfor attribute in attributes :\n",
    "\t\tif attribute in submission :  \n",
    "\t\t\tif type(submission[attribute]) in [float] :  \n",
    "\t\t\t\tparsed[attribute] = str(submission[attribute])\n",
    "\t\t\telse : \n",
    "\t\t\t\tparsed[attribute] = submission[attribute]\n",
    "\n",
    "\t\telse : \n",
    "\t\t\tparsed[attribute] = None\n",
    "\n",
    "\t# parsed['bert_title'] = get_string_representation(submission['title'])\n",
    "\tparsed_str = json.dumps(parsed)\n",
    "\treturn parsed_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eac74bb-2b8f-4bf8-a640-9d63f530e768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/quotes_matcher/fitness\n",
      "data/quotes_matcher/loseit\n",
      "data/quotes_matcher/fat_acceptance\n",
      "data/quotes_matcher/calorie_count\n",
      "data/quotes_matcher/airbnb_hosts\n",
      "data/quotes_matcher/gaming\n",
      "data/quotes_matcher/truegaming\n"
     ]
    }
   ],
   "source": [
    "for quotes in quotes_dict : \n",
    "    \n",
    "    sleep_time = 0.5\n",
    "    time_filter = int(time.time())\n",
    "    oldest_encountered_timestamp = time_filter\n",
    "    posts_per_file = 1000\n",
    "    output_dir = 'data/quotes_matcher'\n",
    "\n",
    "    url = \"https://api.pushshift.io/reddit/search/submission/\"\n",
    "    \n",
    "    \n",
    "    for subreddit in quotes['subreddits'] : \n",
    "        \n",
    "    \n",
    "        save_dir = os.path.join(output_dir, subreddit)\n",
    "        \n",
    "        if not os.path.exists(save_dir) :\n",
    "            os.mkdir(save_dir)\n",
    "            \n",
    "            \n",
    "        while True   : \n",
    "\n",
    "            response = requests.get(url, params={\n",
    "                'subreddit' : subreddit, \n",
    "                'before' : time_filter, \n",
    "                'limit' : posts_per_file\n",
    "            })\n",
    "\n",
    "            parsed_results = []\n",
    "            num_submissions = 0\n",
    "\n",
    "            for submission in response.json()['data'] : \n",
    "\n",
    "                parsed_results.append(parse_submission(submission))\n",
    "\n",
    "                if int(submission['created_utc']) < oldest_encountered_timestamp:\n",
    "                    oldest_encountered_timestamp = int(submission['created_utc'])\n",
    "\n",
    "                num_submissions += 1\n",
    "\n",
    "            if num_submissions == 0 : # we have run out of submissions\n",
    "                break\n",
    "            elif oldest_encountered_timestamp <= oldest_timestamp_limit: # not interested in posts before a certain year\n",
    "                break\n",
    "            else :\n",
    "                save_to_file(oldest_encountered_timestamp, time_filter, parsed_results, output_dir=save_dir)\n",
    "                time_filter = oldest_encountered_timestamp\n",
    "\n",
    "            print('Working on : ' , subreddit)\n",
    "            print('Saving to : ' , save_dir)\n",
    "            print('Finished processing from {}'.format(time.strftime(\"%Y-%m-%d | %H:%M:%S\",  time.localtime(time_filter))))\n",
    "            print(\"There are {} submissions in this file.\".format(num_submissions))\n",
    "\n",
    "            time.sleep(sleep_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fcbf58-ca6e-4c30-b16b-cd35bc9558cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
